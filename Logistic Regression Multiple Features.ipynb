{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1_points = []\n",
    "x2_points = []\n",
    "y_points = []\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    # We need to normalize X values to ensure that our obj function doesn't blow up in value \n",
    "    x1_points.append(float(i)/100)\n",
    "    x2_points.append(sin((i/30)*torch.pi))\n",
    "\n",
    "    if x1_points[-1] * x2_points[-1] < 0:\n",
    "        y_points.append(0)\n",
    "    else:\n",
    "        y_points.append(1)\n",
    "\n",
    "\n",
    "plt.plot(x2_points, y_points, \"o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a new joint x_points list\n",
    "\n",
    "x_points = []\n",
    "\n",
    "for i in range(len(x1_points)):\n",
    "    x_points.append([x1_points[i], x2_points[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_points, y_points, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we've generated some points at random, its time to use torch \n",
    "# to execute linear regression\n",
    "\n",
    "X_train = torch.tensor(X_train)\n",
    "y_train = torch.tensor(y_train)\n",
    "\n",
    "X_test = torch.tensor(X_test)\n",
    "y_test = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1100, 0.4700, 0.8500, 0.2800, 0.9300, 0.0500, 0.6600, 0.6500, 0.3500,\n",
       "        0.1600, 0.4900, 0.3400, 0.0700, 0.9500, 0.2700, 0.1900, 0.8100, 0.2500,\n",
       "        0.6200, 0.1300, 0.2400, 0.0300, 0.1700, 0.3800, 0.0800, 0.7800, 0.0600,\n",
       "        0.6400, 0.3600, 0.8900, 0.5600, 0.9900, 0.5400, 0.4300, 0.5000, 0.6700,\n",
       "        0.4600, 0.6800, 0.6100, 0.9700, 0.7900, 0.4100, 0.5800, 0.4800, 0.9800,\n",
       "        0.5700, 0.7500, 0.3200, 0.9400, 0.5900, 0.6300, 0.8400, 0.3700, 0.2900,\n",
       "        0.0100, 0.5200, 0.2100, 0.0200, 0.2300, 0.8700, 0.9100, 0.7400, 0.8600,\n",
       "        0.8200, 0.2000, 0.6000, 0.7100, 0.1400, 0.9200, 0.5100])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.4072471857070923\n",
      "Iteration 1: b = tensor([0.5981, 0.8299, 0.6117], grad_fn=<SubBackward0>), Loss = 1.4072471857070923\n",
      "tensor([0.4019, 0.1701, 0.3883])\n",
      "loss = 1.0868630409240723\n",
      "Iteration 2: b = tensor([0.2720, 0.6955, 0.2456], grad_fn=<SubBackward0>), Loss = 1.0868630409240723\n",
      "tensor([0.3261, 0.1343, 0.3661])\n",
      "loss = 0.850359320640564\n",
      "Iteration 3: b = tensor([ 0.0305,  0.6013, -0.0847], grad_fn=<SubBackward0>), Loss = 0.850359320640564\n",
      "tensor([0.2415, 0.0943, 0.3303])\n",
      "loss = 0.6912296414375305\n",
      "Iteration 4: b = tensor([-0.1352,  0.5431, -0.3746], grad_fn=<SubBackward0>), Loss = 0.6912296414375305\n",
      "tensor([0.1657, 0.0581, 0.2899])\n",
      "loss = 0.5870205163955688\n",
      "Iteration 5: b = tensor([-0.2445,  0.5118, -0.6283], grad_fn=<SubBackward0>), Loss = 0.5870205163955688\n",
      "tensor([0.1094, 0.0314, 0.2537])\n",
      "loss = 0.5158469080924988\n",
      "Iteration 6: b = tensor([-0.3164,  0.4979, -0.8524], grad_fn=<SubBackward0>), Loss = 0.5158469080924988\n",
      "tensor([0.0718, 0.0139, 0.2241])\n",
      "loss = 0.4639216959476471\n",
      "Iteration 7: b = tensor([-0.3643,  0.4948, -1.0527], grad_fn=<SubBackward0>), Loss = 0.4639216959476471\n",
      "tensor([0.0479, 0.0031, 0.2003])\n",
      "loss = 0.42384061217308044\n",
      "Iteration 8: b = tensor([-0.3971,  0.4981, -1.2336], grad_fn=<SubBackward0>), Loss = 0.42384061217308044\n",
      "tensor([ 0.0328, -0.0034,  0.1809])\n",
      "loss = 0.3916385769844055\n",
      "Iteration 9: b = tensor([-0.4202,  0.5053, -1.3986], grad_fn=<SubBackward0>), Loss = 0.3916385769844055\n",
      "tensor([ 0.0231, -0.0071,  0.1649])\n",
      "loss = 0.3650442957878113\n",
      "Iteration 10: b = tensor([-0.4371,  0.5146, -1.5500], grad_fn=<SubBackward0>), Loss = 0.3650442957878113\n",
      "tensor([ 0.0169, -0.0093,  0.1515])\n",
      "loss = 0.3426439166069031\n",
      "Iteration 11: b = tensor([-0.4498,  0.5250, -1.6900], grad_fn=<SubBackward0>), Loss = 0.3426439166069031\n",
      "tensor([ 0.0128, -0.0104,  0.1400])\n",
      "loss = 0.3234907388687134\n",
      "Iteration 12: b = tensor([-0.4599,  0.5360, -1.8201], grad_fn=<SubBackward0>), Loss = 0.3234907388687134\n",
      "tensor([ 0.0100, -0.0110,  0.1301])\n",
      "loss = 0.3069148361682892\n",
      "Iteration 13: b = tensor([-0.4680,  0.5472, -1.9416], grad_fn=<SubBackward0>), Loss = 0.3069148361682892\n",
      "tensor([ 0.0082, -0.0112,  0.1215])\n",
      "loss = 0.29242295026779175\n",
      "Iteration 14: b = tensor([-0.4749,  0.5584, -2.0556], grad_fn=<SubBackward0>), Loss = 0.29242295026779175\n",
      "tensor([ 0.0069, -0.0112,  0.1140])\n",
      "loss = 0.2796413004398346\n",
      "Iteration 15: b = tensor([-0.4808,  0.5695, -2.1630], grad_fn=<SubBackward0>), Loss = 0.2796413004398346\n",
      "tensor([ 0.0059, -0.0111,  0.1074])\n",
      "loss = 0.2682805061340332\n",
      "Iteration 16: b = tensor([-0.4861,  0.5803, -2.2644], grad_fn=<SubBackward0>), Loss = 0.2682805061340332\n",
      "tensor([ 0.0053, -0.0108,  0.1015])\n",
      "loss = 0.25811275839805603\n",
      "Iteration 17: b = tensor([-0.4909,  0.5909, -2.3606], grad_fn=<SubBackward0>), Loss = 0.25811275839805603\n",
      "tensor([ 0.0048, -0.0106,  0.0962])\n",
      "loss = 0.24895618855953217\n",
      "Iteration 18: b = tensor([-0.4954,  0.6012, -2.4521], grad_fn=<SubBackward0>), Loss = 0.24895618855953217\n",
      "tensor([ 0.0045, -0.0103,  0.0915])\n",
      "loss = 0.2406638264656067\n",
      "Iteration 19: b = tensor([-0.4996,  0.6113, -2.5393], grad_fn=<SubBackward0>), Loss = 0.2406638264656067\n",
      "tensor([ 0.0042, -0.0100,  0.0872])\n",
      "loss = 0.23311574757099152\n",
      "Iteration 20: b = tensor([-0.5035,  0.6210, -2.6226], grad_fn=<SubBackward0>), Loss = 0.23311574757099152\n",
      "tensor([ 0.0040, -0.0098,  0.0833])\n",
      "loss = 0.2262132167816162\n",
      "Iteration 21: b = tensor([-0.5073,  0.6305, -2.7024], grad_fn=<SubBackward0>), Loss = 0.2262132167816162\n",
      "tensor([ 0.0038, -0.0095,  0.0798])\n",
      "loss = 0.21987399458885193\n",
      "Iteration 22: b = tensor([-0.5110,  0.6398, -2.7789], grad_fn=<SubBackward0>), Loss = 0.21987399458885193\n",
      "tensor([ 0.0037, -0.0092,  0.0766])\n",
      "loss = 0.214029461145401\n",
      "Iteration 23: b = tensor([-0.5145,  0.6487, -2.8525], grad_fn=<SubBackward0>), Loss = 0.214029461145401\n",
      "tensor([ 0.0035, -0.0090,  0.0736])\n",
      "loss = 0.2086215317249298\n",
      "Iteration 24: b = tensor([-0.5180,  0.6575, -2.9234], grad_fn=<SubBackward0>), Loss = 0.2086215317249298\n",
      "tensor([ 0.0035, -0.0088,  0.0709])\n",
      "loss = 0.20360097289085388\n",
      "Iteration 25: b = tensor([-0.5214,  0.6660, -2.9918], grad_fn=<SubBackward0>), Loss = 0.20360097289085388\n",
      "tensor([ 0.0034, -0.0085,  0.0684])\n",
      "loss = 0.19892574846744537\n",
      "Iteration 26: b = tensor([-0.5246,  0.6743, -3.0578], grad_fn=<SubBackward0>), Loss = 0.19892574846744537\n",
      "tensor([ 0.0033, -0.0083,  0.0660])\n",
      "loss = 0.19455966353416443\n",
      "Iteration 27: b = tensor([-0.5279,  0.6825, -3.1216], grad_fn=<SubBackward0>), Loss = 0.19455966353416443\n",
      "tensor([ 0.0032, -0.0081,  0.0639])\n",
      "loss = 0.19047144055366516\n",
      "Iteration 28: b = tensor([-0.5310,  0.6904, -3.1835], grad_fn=<SubBackward0>), Loss = 0.19047144055366516\n",
      "tensor([ 0.0032, -0.0079,  0.0618])\n",
      "loss = 0.18663404881954193\n",
      "Iteration 29: b = tensor([-0.5342,  0.6982, -3.2434], grad_fn=<SubBackward0>), Loss = 0.18663404881954193\n",
      "tensor([ 0.0031, -0.0078,  0.0600])\n",
      "loss = 0.18302372097969055\n",
      "Iteration 30: b = tensor([-0.5372,  0.7057, -3.3016], grad_fn=<SubBackward0>), Loss = 0.18302372097969055\n",
      "tensor([ 0.0031, -0.0076,  0.0582])\n",
      "loss = 0.17961975932121277\n",
      "Iteration 31: b = tensor([-0.5402,  0.7132, -3.3582], grad_fn=<SubBackward0>), Loss = 0.17961975932121277\n",
      "tensor([ 0.0030, -0.0074,  0.0565])\n",
      "loss = 0.17640389502048492\n",
      "Iteration 32: b = tensor([-0.5432,  0.7204, -3.4131], grad_fn=<SubBackward0>), Loss = 0.17640389502048492\n",
      "tensor([ 0.0030, -0.0073,  0.0550])\n",
      "loss = 0.17335990071296692\n",
      "Iteration 33: b = tensor([-0.5461,  0.7276, -3.4667], grad_fn=<SubBackward0>), Loss = 0.17335990071296692\n",
      "tensor([ 0.0029, -0.0071,  0.0535])\n",
      "loss = 0.1704735904932022\n",
      "Iteration 34: b = tensor([-0.5490,  0.7346, -3.5188], grad_fn=<SubBackward0>), Loss = 0.1704735904932022\n",
      "tensor([ 0.0029, -0.0070,  0.0521])\n",
      "loss = 0.1677321493625641\n",
      "Iteration 35: b = tensor([-0.5519,  0.7414, -3.5696], grad_fn=<SubBackward0>), Loss = 0.1677321493625641\n",
      "tensor([ 0.0028, -0.0069,  0.0508])\n",
      "loss = 0.16512420773506165\n",
      "Iteration 36: b = tensor([-0.5547,  0.7482, -3.6193], grad_fn=<SubBackward0>), Loss = 0.16512420773506165\n",
      "tensor([ 0.0028, -0.0067,  0.0496])\n",
      "loss = 0.1626395583152771\n",
      "Iteration 37: b = tensor([-0.5575,  0.7548, -3.6677], grad_fn=<SubBackward0>), Loss = 0.1626395583152771\n",
      "tensor([ 0.0028, -0.0066,  0.0484])\n",
      "loss = 0.160269096493721\n",
      "Iteration 38: b = tensor([-0.5602,  0.7613, -3.7150], grad_fn=<SubBackward0>), Loss = 0.160269096493721\n",
      "tensor([ 0.0027, -0.0065,  0.0473])\n",
      "loss = 0.15800447762012482\n",
      "Iteration 39: b = tensor([-0.5629,  0.7677, -3.7613], grad_fn=<SubBackward0>), Loss = 0.15800447762012482\n",
      "tensor([ 0.0027, -0.0064,  0.0463])\n",
      "loss = 0.1558382511138916\n",
      "Iteration 40: b = tensor([-0.5656,  0.7740, -3.8066], grad_fn=<SubBackward0>), Loss = 0.1558382511138916\n",
      "tensor([ 0.0027, -0.0063,  0.0453])\n",
      "loss = 0.15376369655132294\n",
      "Iteration 41: b = tensor([-0.5682,  0.7802, -3.8509], grad_fn=<SubBackward0>), Loss = 0.15376369655132294\n",
      "tensor([ 0.0026, -0.0062,  0.0443])\n",
      "loss = 0.15177464485168457\n",
      "Iteration 42: b = tensor([-0.5708,  0.7863, -3.8943], grad_fn=<SubBackward0>), Loss = 0.15177464485168457\n",
      "tensor([ 0.0026, -0.0061,  0.0434])\n",
      "loss = 0.14986546337604523\n",
      "Iteration 43: b = tensor([-0.5734,  0.7923, -3.9368], grad_fn=<SubBackward0>), Loss = 0.14986546337604523\n",
      "tensor([ 0.0026, -0.0060,  0.0425])\n",
      "loss = 0.14803114533424377\n",
      "Iteration 44: b = tensor([-0.5760,  0.7983, -3.9786], grad_fn=<SubBackward0>), Loss = 0.14803114533424377\n",
      "tensor([ 0.0026, -0.0059,  0.0417])\n",
      "loss = 0.1462668925523758\n",
      "Iteration 45: b = tensor([-0.5785,  0.8041, -4.0195], grad_fn=<SubBackward0>), Loss = 0.1462668925523758\n",
      "tensor([ 0.0025, -0.0058,  0.0409])\n",
      "loss = 0.144568532705307\n",
      "Iteration 46: b = tensor([-0.5810,  0.8099, -4.0596], grad_fn=<SubBackward0>), Loss = 0.144568532705307\n",
      "tensor([ 0.0025, -0.0058,  0.0402])\n",
      "loss = 0.14293213188648224\n",
      "Iteration 47: b = tensor([-0.5835,  0.8155, -4.0990], grad_fn=<SubBackward0>), Loss = 0.14293213188648224\n",
      "tensor([ 0.0025, -0.0057,  0.0394])\n",
      "loss = 0.1413540095090866\n",
      "Iteration 48: b = tensor([-0.5859,  0.8211, -4.1378], grad_fn=<SubBackward0>), Loss = 0.1413540095090866\n",
      "tensor([ 0.0024, -0.0056,  0.0387])\n",
      "loss = 0.13983087241649628\n",
      "Iteration 49: b = tensor([-0.5883,  0.8267, -4.1758], grad_fn=<SubBackward0>), Loss = 0.13983087241649628\n",
      "tensor([ 0.0024, -0.0055,  0.0380])\n",
      "loss = 0.1383596807718277\n",
      "Iteration 50: b = tensor([-0.5907,  0.8321, -4.2132], grad_fn=<SubBackward0>), Loss = 0.1383596807718277\n",
      "tensor([ 0.0024, -0.0055,  0.0374])\n",
      "loss = 0.13693754374980927\n",
      "Iteration 51: b = tensor([-0.5931,  0.8375, -4.2500], grad_fn=<SubBackward0>), Loss = 0.13693754374980927\n",
      "tensor([ 0.0024, -0.0054,  0.0368])\n",
      "loss = 0.13556185364723206\n",
      "Iteration 52: b = tensor([-0.5954,  0.8428, -4.2861], grad_fn=<SubBackward0>), Loss = 0.13556185364723206\n",
      "tensor([ 0.0023, -0.0053,  0.0362])\n",
      "loss = 0.13423015177249908\n",
      "Iteration 53: b = tensor([-0.5978,  0.8481, -4.3217], grad_fn=<SubBackward0>), Loss = 0.13423015177249908\n",
      "tensor([ 0.0023, -0.0053,  0.0356])\n",
      "loss = 0.13294018805027008\n",
      "Iteration 54: b = tensor([-0.6001,  0.8533, -4.3568], grad_fn=<SubBackward0>), Loss = 0.13294018805027008\n",
      "tensor([ 0.0023, -0.0052,  0.0350])\n",
      "loss = 0.13168980181217194\n",
      "Iteration 55: b = tensor([-0.6023,  0.8584, -4.3913], grad_fn=<SubBackward0>), Loss = 0.13168980181217194\n",
      "tensor([ 0.0023, -0.0051,  0.0345])\n",
      "loss = 0.13047711551189423\n",
      "Iteration 56: b = tensor([-0.6046,  0.8635, -4.4253], grad_fn=<SubBackward0>), Loss = 0.13047711551189423\n",
      "tensor([ 0.0023, -0.0051,  0.0340])\n",
      "loss = 0.12930022180080414\n",
      "Iteration 57: b = tensor([-0.6068,  0.8685, -4.4587], grad_fn=<SubBackward0>), Loss = 0.12930022180080414\n",
      "tensor([ 0.0022, -0.0050,  0.0335])\n",
      "loss = 0.12815743684768677\n",
      "Iteration 58: b = tensor([-0.6090,  0.8735, -4.4917], grad_fn=<SubBackward0>), Loss = 0.12815743684768677\n",
      "tensor([ 0.0022, -0.0050,  0.0330])\n",
      "loss = 0.12704715132713318\n",
      "Iteration 59: b = tensor([-0.6112,  0.8784, -4.5243], grad_fn=<SubBackward0>), Loss = 0.12704715132713318\n",
      "tensor([ 0.0022, -0.0049,  0.0325])\n",
      "loss = 0.125967875123024\n",
      "Iteration 60: b = tensor([-0.6134,  0.8832, -4.5563], grad_fn=<SubBackward0>), Loss = 0.125967875123024\n",
      "tensor([ 0.0022, -0.0049,  0.0321])\n",
      "loss = 0.12491817772388458\n",
      "Iteration 61: b = tensor([-0.6156,  0.8880, -4.5880], grad_fn=<SubBackward0>), Loss = 0.12491817772388458\n",
      "tensor([ 0.0022, -0.0048,  0.0316])\n",
      "loss = 0.12389679253101349\n",
      "Iteration 62: b = tensor([-0.6177,  0.8928, -4.6192], grad_fn=<SubBackward0>), Loss = 0.12389679253101349\n",
      "tensor([ 0.0021, -0.0048,  0.0312])\n",
      "loss = 0.12290244549512863\n",
      "Iteration 63: b = tensor([-0.6198,  0.8975, -4.6500], grad_fn=<SubBackward0>), Loss = 0.12290244549512863\n",
      "tensor([ 0.0021, -0.0047,  0.0308])\n",
      "loss = 0.1219339370727539\n",
      "Iteration 64: b = tensor([-0.6219,  0.9021, -4.6804], grad_fn=<SubBackward0>), Loss = 0.1219339370727539\n",
      "tensor([ 0.0021, -0.0047,  0.0304])\n",
      "loss = 0.12099022418260574\n",
      "Iteration 65: b = tensor([-0.6240,  0.9067, -4.7104], grad_fn=<SubBackward0>), Loss = 0.12099022418260574\n",
      "tensor([ 0.0021, -0.0046,  0.0300])\n",
      "loss = 0.12007027864456177\n",
      "Iteration 66: b = tensor([-0.6261,  0.9113, -4.7400], grad_fn=<SubBackward0>), Loss = 0.12007027864456177\n",
      "tensor([ 0.0021, -0.0046,  0.0296])\n",
      "loss = 0.1191730797290802\n",
      "Iteration 67: b = tensor([-0.6281,  0.9158, -4.7692], grad_fn=<SubBackward0>), Loss = 0.1191730797290802\n",
      "tensor([ 0.0020, -0.0045,  0.0293])\n",
      "loss = 0.11829774081707001\n",
      "Iteration 68: b = tensor([-0.6301,  0.9203, -4.7982], grad_fn=<SubBackward0>), Loss = 0.11829774081707001\n",
      "tensor([ 0.0020, -0.0045,  0.0289])\n",
      "loss = 0.11744336783885956\n",
      "Iteration 69: b = tensor([-0.6321,  0.9247, -4.8267], grad_fn=<SubBackward0>), Loss = 0.11744336783885956\n",
      "tensor([ 0.0020, -0.0044,  0.0286])\n",
      "loss = 0.11660916358232498\n",
      "Iteration 70: b = tensor([-0.6341,  0.9291, -4.8549], grad_fn=<SubBackward0>), Loss = 0.11660916358232498\n",
      "tensor([ 0.0020, -0.0044,  0.0282])\n",
      "loss = 0.11579431593418121\n",
      "Iteration 71: b = tensor([-0.6361,  0.9334, -4.8828], grad_fn=<SubBackward0>), Loss = 0.11579431593418121\n",
      "tensor([ 0.0020, -0.0043,  0.0279])\n",
      "loss = 0.11499813944101334\n",
      "Iteration 72: b = tensor([-0.6381,  0.9378, -4.9104], grad_fn=<SubBackward0>), Loss = 0.11499813944101334\n",
      "tensor([ 0.0020, -0.0043,  0.0276])\n",
      "loss = 0.11421988159418106\n",
      "Iteration 73: b = tensor([-0.6400,  0.9420, -4.9377], grad_fn=<SubBackward0>), Loss = 0.11421988159418106\n",
      "tensor([ 0.0019, -0.0043,  0.0273])\n",
      "loss = 0.11345891654491425\n",
      "Iteration 74: b = tensor([-0.6419,  0.9463, -4.9646], grad_fn=<SubBackward0>), Loss = 0.11345891654491425\n",
      "tensor([ 0.0019, -0.0042,  0.0270])\n",
      "loss = 0.11271458864212036\n",
      "Iteration 75: b = tensor([-0.6439,  0.9505, -4.9913], grad_fn=<SubBackward0>), Loss = 0.11271458864212036\n",
      "tensor([ 0.0019, -0.0042,  0.0267])\n",
      "loss = 0.11198633164167404\n",
      "Iteration 76: b = tensor([-0.6458,  0.9546, -5.0177], grad_fn=<SubBackward0>), Loss = 0.11198633164167404\n",
      "tensor([ 0.0019, -0.0042,  0.0264])\n",
      "loss = 0.11127354949712753\n",
      "Iteration 77: b = tensor([-0.6476,  0.9587, -5.0437], grad_fn=<SubBackward0>), Loss = 0.11127354949712753\n",
      "tensor([ 0.0019, -0.0041,  0.0261])\n",
      "loss = 0.11057569831609726\n",
      "Iteration 78: b = tensor([-0.6495,  0.9628, -5.0696], grad_fn=<SubBackward0>), Loss = 0.11057569831609726\n",
      "tensor([ 0.0019, -0.0041,  0.0258])\n",
      "loss = 0.10989227145910263\n",
      "Iteration 79: b = tensor([-0.6514,  0.9669, -5.0951], grad_fn=<SubBackward0>), Loss = 0.10989227145910263\n",
      "tensor([ 0.0019, -0.0041,  0.0256])\n",
      "loss = 0.10922279208898544\n",
      "Iteration 80: b = tensor([-0.6532,  0.9709, -5.1204], grad_fn=<SubBackward0>), Loss = 0.10922279208898544\n",
      "tensor([ 0.0018, -0.0040,  0.0253])\n",
      "loss = 0.1085667833685875\n",
      "Iteration 81: b = tensor([-0.6550,  0.9749, -5.1455], grad_fn=<SubBackward0>), Loss = 0.1085667833685875\n",
      "tensor([ 0.0018, -0.0040,  0.0250])\n",
      "loss = 0.10792379826307297\n",
      "Iteration 82: b = tensor([-0.6569,  0.9788, -5.1702], grad_fn=<SubBackward0>), Loss = 0.10792379826307297\n",
      "tensor([ 0.0018, -0.0040,  0.0248])\n",
      "loss = 0.10729340463876724\n",
      "Iteration 83: b = tensor([-0.6587,  0.9828, -5.1948], grad_fn=<SubBackward0>), Loss = 0.10729340463876724\n",
      "tensor([ 0.0018, -0.0039,  0.0245])\n",
      "loss = 0.10667518526315689\n",
      "Iteration 84: b = tensor([-0.6604,  0.9867, -5.2191], grad_fn=<SubBackward0>), Loss = 0.10667518526315689\n",
      "tensor([ 0.0018, -0.0039,  0.0243])\n",
      "loss = 0.10606878995895386\n",
      "Iteration 85: b = tensor([-0.6622,  0.9905, -5.2432], grad_fn=<SubBackward0>), Loss = 0.10606878995895386\n",
      "tensor([ 0.0018, -0.0039,  0.0241])\n",
      "loss = 0.10547380894422531\n",
      "Iteration 86: b = tensor([-0.6640,  0.9944, -5.2670], grad_fn=<SubBackward0>), Loss = 0.10547380894422531\n",
      "tensor([ 0.0018, -0.0038,  0.0239])\n",
      "loss = 0.10488990694284439\n",
      "Iteration 87: b = tensor([-0.6657,  0.9982, -5.2907], grad_fn=<SubBackward0>), Loss = 0.10488990694284439\n",
      "tensor([ 0.0018, -0.0038,  0.0236])\n",
      "loss = 0.10431673377752304\n",
      "Iteration 88: b = tensor([-0.6675,  1.0019, -5.3141], grad_fn=<SubBackward0>), Loss = 0.10431673377752304\n",
      "tensor([ 0.0017, -0.0038,  0.0234])\n",
      "loss = 0.10375397652387619\n",
      "Iteration 89: b = tensor([-0.6692,  1.0057, -5.3373], grad_fn=<SubBackward0>), Loss = 0.10375397652387619\n",
      "tensor([ 0.0017, -0.0037,  0.0232])\n",
      "loss = 0.10320129245519638\n",
      "Iteration 90: b = tensor([-0.6709,  1.0094, -5.3603], grad_fn=<SubBackward0>), Loss = 0.10320129245519638\n",
      "tensor([ 0.0017, -0.0037,  0.0230])\n",
      "loss = 0.10265842825174332\n",
      "Iteration 91: b = tensor([-0.6726,  1.0131, -5.3830], grad_fn=<SubBackward0>), Loss = 0.10265842825174332\n",
      "tensor([ 0.0017, -0.0037,  0.0228])\n",
      "loss = 0.10212507098913193\n",
      "Iteration 92: b = tensor([-0.6743,  1.0167, -5.4056], grad_fn=<SubBackward0>), Loss = 0.10212507098913193\n",
      "tensor([ 0.0017, -0.0037,  0.0226])\n",
      "loss = 0.10160091519355774\n",
      "Iteration 93: b = tensor([-0.6760,  1.0204, -5.4280], grad_fn=<SubBackward0>), Loss = 0.10160091519355774\n",
      "tensor([ 0.0017, -0.0036,  0.0224])\n",
      "loss = 0.10108576714992523\n",
      "Iteration 94: b = tensor([-0.6777,  1.0240, -5.4502], grad_fn=<SubBackward0>), Loss = 0.10108576714992523\n",
      "tensor([ 0.0017, -0.0036,  0.0222])\n",
      "loss = 0.10057931393384933\n",
      "Iteration 95: b = tensor([-0.6793,  1.0276, -5.4722], grad_fn=<SubBackward0>), Loss = 0.10057931393384933\n",
      "tensor([ 0.0017, -0.0036,  0.0220])\n",
      "loss = 0.10008133947849274\n",
      "Iteration 96: b = tensor([-0.6810,  1.0311, -5.4941], grad_fn=<SubBackward0>), Loss = 0.10008133947849274\n",
      "tensor([ 0.0016, -0.0036,  0.0218])\n",
      "loss = 0.09959157556295395\n",
      "Iteration 97: b = tensor([-0.6826,  1.0347, -5.5157], grad_fn=<SubBackward0>), Loss = 0.09959157556295395\n",
      "tensor([ 0.0016, -0.0035,  0.0216])\n",
      "loss = 0.09910985082387924\n",
      "Iteration 98: b = tensor([-0.6842,  1.0382, -5.5372], grad_fn=<SubBackward0>), Loss = 0.09910985082387924\n",
      "tensor([ 0.0016, -0.0035,  0.0215])\n",
      "loss = 0.09863589704036713\n",
      "Iteration 99: b = tensor([-0.6858,  1.0417, -5.5585], grad_fn=<SubBackward0>), Loss = 0.09863589704036713\n",
      "tensor([ 0.0016, -0.0035,  0.0213])\n",
      "loss = 0.09816952794790268\n",
      "Iteration 100: b = tensor([-0.6874,  1.0451, -5.5796], grad_fn=<SubBackward0>), Loss = 0.09816952794790268\n",
      "tensor([ 0.0016, -0.0035,  0.0211])\n",
      "loss = 0.09771054238080978\n",
      "Iteration 101: b = tensor([-0.6890,  1.0486, -5.6005], grad_fn=<SubBackward0>), Loss = 0.09771054238080978\n",
      "tensor([ 0.0016, -0.0034,  0.0210])\n",
      "loss = 0.09725874662399292\n",
      "Iteration 102: b = tensor([-0.6906,  1.0520, -5.6213], grad_fn=<SubBackward0>), Loss = 0.09725874662399292\n",
      "tensor([ 0.0016, -0.0034,  0.0208])\n",
      "loss = 0.09681395441293716\n",
      "Iteration 103: b = tensor([-0.6922,  1.0554, -5.6420], grad_fn=<SubBackward0>), Loss = 0.09681395441293716\n",
      "tensor([ 0.0016, -0.0034,  0.0206])\n",
      "loss = 0.0963759571313858\n",
      "Iteration 104: b = tensor([-0.6937,  1.0587, -5.6624], grad_fn=<SubBackward0>), Loss = 0.0963759571313858\n",
      "tensor([ 0.0016, -0.0034,  0.0205])\n",
      "loss = 0.09594462811946869\n",
      "Iteration 105: b = tensor([-0.6953,  1.0621, -5.6828], grad_fn=<SubBackward0>), Loss = 0.09594462811946869\n",
      "tensor([ 0.0016, -0.0033,  0.0203])\n",
      "loss = 0.0955197736620903\n",
      "Iteration 106: b = tensor([-0.6968,  1.0654, -5.7029], grad_fn=<SubBackward0>), Loss = 0.0955197736620903\n",
      "tensor([ 0.0015, -0.0033,  0.0202])\n",
      "loss = 0.0951012372970581\n",
      "Iteration 107: b = tensor([-0.6984,  1.0687, -5.7229], grad_fn=<SubBackward0>), Loss = 0.0951012372970581\n",
      "tensor([ 0.0015, -0.0033,  0.0200])\n",
      "loss = 0.09468885511159897\n",
      "Iteration 108: b = tensor([-0.6999,  1.0720, -5.7428], grad_fn=<SubBackward0>), Loss = 0.09468885511159897\n",
      "tensor([ 0.0015, -0.0033,  0.0199])\n",
      "loss = 0.09428248554468155\n",
      "Iteration 109: b = tensor([-0.7014,  1.0752, -5.7625], grad_fn=<SubBackward0>), Loss = 0.09428248554468155\n",
      "tensor([ 0.0015, -0.0033,  0.0197])\n",
      "loss = 0.09388196468353271\n",
      "Iteration 110: b = tensor([-0.7029,  1.0785, -5.7821], grad_fn=<SubBackward0>), Loss = 0.09388196468353271\n",
      "tensor([ 0.0015, -0.0032,  0.0196])\n",
      "loss = 0.09348718822002411\n",
      "Iteration 111: b = tensor([-0.7044,  1.0817, -5.8016], grad_fn=<SubBackward0>), Loss = 0.09348718822002411\n",
      "tensor([ 0.0015, -0.0032,  0.0194])\n",
      "loss = 0.0930979773402214\n",
      "Iteration 112: b = tensor([-0.7059,  1.0849, -5.8209], grad_fn=<SubBackward0>), Loss = 0.0930979773402214\n",
      "tensor([ 0.0015, -0.0032,  0.0193])\n",
      "loss = 0.09271424263715744\n",
      "Iteration 113: b = tensor([-0.7074,  1.0881, -5.8400], grad_fn=<SubBackward0>), Loss = 0.09271424263715744\n",
      "tensor([ 0.0015, -0.0032,  0.0192])\n",
      "loss = 0.09233582019805908\n",
      "Iteration 114: b = tensor([-0.7089,  1.0912, -5.8591], grad_fn=<SubBackward0>), Loss = 0.09233582019805908\n",
      "tensor([ 0.0015, -0.0032,  0.0190])\n",
      "loss = 0.09196261316537857\n",
      "Iteration 115: b = tensor([-0.7103,  1.0944, -5.8780], grad_fn=<SubBackward0>), Loss = 0.09196261316537857\n",
      "tensor([ 0.0015, -0.0031,  0.0189])\n",
      "loss = 0.09159449487924576\n",
      "Iteration 116: b = tensor([-0.7118,  1.0975, -5.8967], grad_fn=<SubBackward0>), Loss = 0.09159449487924576\n",
      "tensor([ 0.0015, -0.0031,  0.0188])\n",
      "loss = 0.0912313312292099\n",
      "Iteration 117: b = tensor([-0.7132,  1.1006, -5.9154], grad_fn=<SubBackward0>), Loss = 0.0912313312292099\n",
      "tensor([ 0.0014, -0.0031,  0.0186])\n",
      "loss = 0.09087304025888443\n",
      "Iteration 118: b = tensor([-0.7147,  1.1037, -5.9339], grad_fn=<SubBackward0>), Loss = 0.09087304025888443\n",
      "tensor([ 0.0014, -0.0031,  0.0185])\n",
      "loss = 0.090519480407238\n",
      "Iteration 119: b = tensor([-0.7161,  1.1067, -5.9523], grad_fn=<SubBackward0>), Loss = 0.090519480407238\n",
      "tensor([ 0.0014, -0.0031,  0.0184])\n",
      "loss = 0.09017058461904526\n",
      "Iteration 120: b = tensor([-0.7175,  1.1098, -5.9706], grad_fn=<SubBackward0>), Loss = 0.09017058461904526\n",
      "tensor([ 0.0014, -0.0030,  0.0183])\n",
      "loss = 0.08982621133327484\n",
      "Iteration 121: b = tensor([-0.7189,  1.1128, -5.9888], grad_fn=<SubBackward0>), Loss = 0.08982621133327484\n",
      "tensor([ 0.0014, -0.0030,  0.0182])\n",
      "loss = 0.08948630094528198\n",
      "Iteration 122: b = tensor([-0.7203,  1.1158, -6.0068], grad_fn=<SubBackward0>), Loss = 0.08948630094528198\n",
      "tensor([ 0.0014, -0.0030,  0.0180])\n",
      "loss = 0.08915071934461594\n",
      "Iteration 123: b = tensor([-0.7217,  1.1188, -6.0247], grad_fn=<SubBackward0>), Loss = 0.08915071934461594\n",
      "tensor([ 0.0014, -0.0030,  0.0179])\n",
      "loss = 0.08881941437721252\n",
      "Iteration 124: b = tensor([-0.7231,  1.1218, -6.0426], grad_fn=<SubBackward0>), Loss = 0.08881941437721252\n",
      "tensor([ 0.0014, -0.0030,  0.0178])\n",
      "loss = 0.0884922593832016\n",
      "Iteration 125: b = tensor([-0.7245,  1.1248, -6.0603], grad_fn=<SubBackward0>), Loss = 0.0884922593832016\n",
      "tensor([ 0.0014, -0.0030,  0.0177])\n",
      "loss = 0.08816919475793839\n",
      "Iteration 126: b = tensor([-0.7259,  1.1277, -6.0779], grad_fn=<SubBackward0>), Loss = 0.08816919475793839\n",
      "tensor([ 0.0014, -0.0029,  0.0176])\n",
      "loss = 0.08785011619329453\n",
      "Iteration 127: b = tensor([-0.7272,  1.1306, -6.0953], grad_fn=<SubBackward0>), Loss = 0.08785011619329453\n",
      "tensor([ 0.0014, -0.0029,  0.0175])\n",
      "loss = 0.08753493428230286\n",
      "Iteration 128: b = tensor([-0.7286,  1.1335, -6.1127], grad_fn=<SubBackward0>), Loss = 0.08753493428230286\n",
      "tensor([ 0.0014, -0.0029,  0.0174])\n",
      "loss = 0.0872235894203186\n",
      "Iteration 129: b = tensor([-0.7299,  1.1364, -6.1300], grad_fn=<SubBackward0>), Loss = 0.0872235894203186\n",
      "tensor([ 0.0014, -0.0029,  0.0173])\n",
      "loss = 0.0869160071015358\n",
      "Iteration 130: b = tensor([-0.7313,  1.1393, -6.1472], grad_fn=<SubBackward0>), Loss = 0.0869160071015358\n",
      "tensor([ 0.0013, -0.0029,  0.0172])\n",
      "loss = 0.08661210536956787\n",
      "Iteration 131: b = tensor([-0.7326,  1.1422, -6.1642], grad_fn=<SubBackward0>), Loss = 0.08661210536956787\n",
      "tensor([ 0.0013, -0.0029,  0.0171])\n",
      "loss = 0.08631177991628647\n",
      "Iteration 132: b = tensor([-0.7340,  1.1450, -6.1812], grad_fn=<SubBackward0>), Loss = 0.08631177991628647\n",
      "tensor([ 0.0013, -0.0028,  0.0170])\n",
      "loss = 0.0860150083899498\n",
      "Iteration 133: b = tensor([-0.7353,  1.1478, -6.1981], grad_fn=<SubBackward0>), Loss = 0.0860150083899498\n",
      "tensor([ 0.0013, -0.0028,  0.0169])\n",
      "loss = 0.0857216939330101\n",
      "Iteration 134: b = tensor([-0.7366,  1.1507, -6.2148], grad_fn=<SubBackward0>), Loss = 0.0857216939330101\n",
      "tensor([ 0.0013, -0.0028,  0.0168])\n",
      "loss = 0.0854317769408226\n",
      "Iteration 135: b = tensor([-0.7379,  1.1535, -6.2315], grad_fn=<SubBackward0>), Loss = 0.0854317769408226\n",
      "tensor([ 0.0013, -0.0028,  0.0167])\n",
      "loss = 0.08514516055583954\n",
      "Iteration 136: b = tensor([-0.7392,  1.1562, -6.2481], grad_fn=<SubBackward0>), Loss = 0.08514516055583954\n",
      "tensor([ 0.0013, -0.0028,  0.0166])\n",
      "loss = 0.08486184477806091\n",
      "Iteration 137: b = tensor([-0.7405,  1.1590, -6.2645], grad_fn=<SubBackward0>), Loss = 0.08486184477806091\n",
      "tensor([ 0.0013, -0.0028,  0.0165])\n",
      "loss = 0.08458172529935837\n",
      "Iteration 138: b = tensor([-0.7418,  1.1618, -6.2809], grad_fn=<SubBackward0>), Loss = 0.08458172529935837\n",
      "tensor([ 0.0013, -0.0028,  0.0164])\n",
      "loss = 0.08430472761392593\n",
      "Iteration 139: b = tensor([-0.7431,  1.1645, -6.2972], grad_fn=<SubBackward0>), Loss = 0.08430472761392593\n",
      "tensor([ 0.0013, -0.0027,  0.0163])\n",
      "loss = 0.08403083682060242\n",
      "Iteration 140: b = tensor([-0.7443,  1.1672, -6.3134], grad_fn=<SubBackward0>), Loss = 0.08403083682060242\n",
      "tensor([ 0.0013, -0.0027,  0.0162])\n",
      "loss = 0.08375995606184006\n",
      "Iteration 141: b = tensor([-0.7456,  1.1699, -6.3295], grad_fn=<SubBackward0>), Loss = 0.08375995606184006\n",
      "tensor([ 0.0013, -0.0027,  0.0161])\n",
      "loss = 0.08349204063415527\n",
      "Iteration 142: b = tensor([-0.7469,  1.1726, -6.3456], grad_fn=<SubBackward0>), Loss = 0.08349204063415527\n",
      "tensor([ 0.0013, -0.0027,  0.0160])\n",
      "loss = 0.08322706073522568\n",
      "Iteration 143: b = tensor([-0.7481,  1.1753, -6.3615], grad_fn=<SubBackward0>), Loss = 0.08322706073522568\n",
      "tensor([ 0.0013, -0.0027,  0.0159])\n",
      "loss = 0.0829649344086647\n",
      "Iteration 144: b = tensor([-0.7494,  1.1780, -6.3774], grad_fn=<SubBackward0>), Loss = 0.0829649344086647\n",
      "tensor([ 0.0012, -0.0027,  0.0159])\n",
      "loss = 0.08270560950040817\n",
      "Iteration 145: b = tensor([-0.7506,  1.1806, -6.3931], grad_fn=<SubBackward0>), Loss = 0.08270560950040817\n",
      "tensor([ 0.0012, -0.0027,  0.0158])\n",
      "loss = 0.0824490487575531\n",
      "Iteration 146: b = tensor([-0.7518,  1.1833, -6.4088], grad_fn=<SubBackward0>), Loss = 0.0824490487575531\n",
      "tensor([ 0.0012, -0.0026,  0.0157])\n",
      "loss = 0.0821952074766159\n",
      "Iteration 147: b = tensor([-0.7531,  1.1859, -6.4244], grad_fn=<SubBackward0>), Loss = 0.0821952074766159\n",
      "tensor([ 0.0012, -0.0026,  0.0156])\n",
      "loss = 0.08194401115179062\n",
      "Iteration 148: b = tensor([-0.7543,  1.1885, -6.4399], grad_fn=<SubBackward0>), Loss = 0.08194401115179062\n",
      "tensor([ 0.0012, -0.0026,  0.0155])\n",
      "loss = 0.08169544488191605\n",
      "Iteration 149: b = tensor([-0.7555,  1.1911, -6.4554], grad_fn=<SubBackward0>), Loss = 0.08169544488191605\n",
      "tensor([ 0.0012, -0.0026,  0.0154])\n",
      "loss = 0.08144944161176682\n",
      "Iteration 150: b = tensor([-0.7567,  1.1937, -6.4707], grad_fn=<SubBackward0>), Loss = 0.08144944161176682\n",
      "tensor([ 0.0012, -0.0026,  0.0154])\n",
      "loss = 0.08120596408843994\n",
      "Iteration 151: b = tensor([-0.7579,  1.1963, -6.4860], grad_fn=<SubBackward0>), Loss = 0.08120596408843994\n",
      "tensor([ 0.0012, -0.0026,  0.0153])\n",
      "loss = 0.08096496015787125\n",
      "Iteration 152: b = tensor([-0.7591,  1.1988, -6.5012], grad_fn=<SubBackward0>), Loss = 0.08096496015787125\n",
      "tensor([ 0.0012, -0.0026,  0.0152])\n",
      "loss = 0.08072640001773834\n",
      "Iteration 153: b = tensor([-0.7603,  1.2014, -6.5164], grad_fn=<SubBackward0>), Loss = 0.08072640001773834\n",
      "tensor([ 0.0012, -0.0025,  0.0151])\n",
      "loss = 0.08049023896455765\n",
      "Iteration 154: b = tensor([-0.7615,  1.2039, -6.5314], grad_fn=<SubBackward0>), Loss = 0.08049023896455765\n",
      "tensor([ 0.0012, -0.0025,  0.0151])\n",
      "loss = 0.08025644719600677\n",
      "Iteration 155: b = tensor([-0.7627,  1.2065, -6.5464], grad_fn=<SubBackward0>), Loss = 0.08025644719600677\n",
      "tensor([ 0.0012, -0.0025,  0.0150])\n",
      "loss = 0.08002497255802155\n",
      "Iteration 156: b = tensor([-0.7639,  1.2090, -6.5613], grad_fn=<SubBackward0>), Loss = 0.08002497255802155\n",
      "tensor([ 0.0012, -0.0025,  0.0149])\n",
      "loss = 0.07979576289653778\n",
      "Iteration 157: b = tensor([-0.7650,  1.2115, -6.5761], grad_fn=<SubBackward0>), Loss = 0.07979576289653778\n",
      "tensor([ 0.0012, -0.0025,  0.0148])\n",
      "loss = 0.07956880331039429\n",
      "Iteration 158: b = tensor([-0.7662,  1.2140, -6.5909], grad_fn=<SubBackward0>), Loss = 0.07956880331039429\n",
      "tensor([ 0.0012, -0.0025,  0.0148])\n",
      "loss = 0.07934404164552689\n",
      "Iteration 159: b = tensor([-0.7674,  1.2164, -6.6055], grad_fn=<SubBackward0>), Loss = 0.07934404164552689\n",
      "tensor([ 0.0012, -0.0025,  0.0147])\n",
      "loss = 0.07912145555019379\n",
      "Iteration 160: b = tensor([-0.7685,  1.2189, -6.6202], grad_fn=<SubBackward0>), Loss = 0.07912145555019379\n",
      "tensor([ 0.0012, -0.0025,  0.0146])\n",
      "loss = 0.078901007771492\n",
      "Iteration 161: b = tensor([-0.7697,  1.2214, -6.6347], grad_fn=<SubBackward0>), Loss = 0.078901007771492\n",
      "tensor([ 0.0011, -0.0025,  0.0145])\n",
      "loss = 0.07868264615535736\n",
      "Iteration 162: b = tensor([-0.7708,  1.2238, -6.6492], grad_fn=<SubBackward0>), Loss = 0.07868264615535736\n",
      "tensor([ 0.0011, -0.0024,  0.0145])\n",
      "loss = 0.07846636325120926\n",
      "Iteration 163: b = tensor([-0.7720,  1.2262, -6.6636], grad_fn=<SubBackward0>), Loss = 0.07846636325120926\n",
      "tensor([ 0.0011, -0.0024,  0.0144])\n",
      "loss = 0.07825209200382233\n",
      "Iteration 164: b = tensor([-0.7731,  1.2286, -6.6779], grad_fn=<SubBackward0>), Loss = 0.07825209200382233\n",
      "tensor([ 0.0011, -0.0024,  0.0143])\n",
      "loss = 0.07803983986377716\n",
      "Iteration 165: b = tensor([-0.7742,  1.2310, -6.6922], grad_fn=<SubBackward0>), Loss = 0.07803983986377716\n",
      "tensor([ 0.0011, -0.0024,  0.0143])\n",
      "loss = 0.07782955467700958\n",
      "Iteration 166: b = tensor([-0.7753,  1.2334, -6.7064], grad_fn=<SubBackward0>), Loss = 0.07782955467700958\n",
      "tensor([ 0.0011, -0.0024,  0.0142])\n",
      "loss = 0.0776212066411972\n",
      "Iteration 167: b = tensor([-0.7765,  1.2358, -6.7206], grad_fn=<SubBackward0>), Loss = 0.0776212066411972\n",
      "tensor([ 0.0011, -0.0024,  0.0141])\n",
      "loss = 0.07741476595401764\n",
      "Iteration 168: b = tensor([-0.7776,  1.2382, -6.7346], grad_fn=<SubBackward0>), Loss = 0.07741476595401764\n",
      "tensor([ 0.0011, -0.0024,  0.0141])\n",
      "loss = 0.0772102102637291\n",
      "Iteration 169: b = tensor([-0.7787,  1.2406, -6.7486], grad_fn=<SubBackward0>), Loss = 0.0772102102637291\n",
      "tensor([ 0.0011, -0.0024,  0.0140])\n",
      "loss = 0.07700750231742859\n",
      "Iteration 170: b = tensor([-0.7798,  1.2429, -6.7626], grad_fn=<SubBackward0>), Loss = 0.07700750231742859\n",
      "tensor([ 0.0011, -0.0024,  0.0139])\n",
      "loss = 0.07680659741163254\n",
      "Iteration 171: b = tensor([-0.7809,  1.2453, -6.7765], grad_fn=<SubBackward0>), Loss = 0.07680659741163254\n",
      "tensor([ 0.0011, -0.0023,  0.0139])\n",
      "loss = 0.07660752534866333\n",
      "Iteration 172: b = tensor([-0.7820,  1.2476, -6.7903], grad_fn=<SubBackward0>), Loss = 0.07660752534866333\n",
      "tensor([ 0.0011, -0.0023,  0.0138])\n",
      "loss = 0.0764101892709732\n",
      "Iteration 173: b = tensor([-0.7830,  1.2499, -6.8041], grad_fn=<SubBackward0>), Loss = 0.0764101892709732\n",
      "tensor([ 0.0011, -0.0023,  0.0138])\n",
      "loss = 0.07621461153030396\n",
      "Iteration 174: b = tensor([-0.7841,  1.2522, -6.8178], grad_fn=<SubBackward0>), Loss = 0.07621461153030396\n",
      "tensor([ 0.0011, -0.0023,  0.0137])\n",
      "loss = 0.0760207548737526\n",
      "Iteration 175: b = tensor([-0.7852,  1.2545, -6.8314], grad_fn=<SubBackward0>), Loss = 0.0760207548737526\n",
      "tensor([ 0.0011, -0.0023,  0.0136])\n",
      "loss = 0.07582857459783554\n",
      "Iteration 176: b = tensor([-0.7863,  1.2568, -6.8450], grad_fn=<SubBackward0>), Loss = 0.07582857459783554\n",
      "tensor([ 0.0011, -0.0023,  0.0136])\n",
      "loss = 0.0756380707025528\n",
      "Iteration 177: b = tensor([-0.7873,  1.2591, -6.8585], grad_fn=<SubBackward0>), Loss = 0.0756380707025528\n",
      "tensor([ 0.0011, -0.0023,  0.0135])\n",
      "loss = 0.07544920593500137\n",
      "Iteration 178: b = tensor([-0.7884,  1.2614, -6.8720], grad_fn=<SubBackward0>), Loss = 0.07544920593500137\n",
      "tensor([ 0.0011, -0.0023,  0.0135])\n",
      "loss = 0.07526195049285889\n",
      "Iteration 179: b = tensor([-0.7895,  1.2636, -6.8854], grad_fn=<SubBackward0>), Loss = 0.07526195049285889\n",
      "tensor([ 0.0011, -0.0023,  0.0134])\n",
      "loss = 0.07507629692554474\n",
      "Iteration 180: b = tensor([-0.7905,  1.2659, -6.8988], grad_fn=<SubBackward0>), Loss = 0.07507629692554474\n",
      "tensor([ 0.0011, -0.0022,  0.0134])\n",
      "loss = 0.07489220798015594\n",
      "Iteration 181: b = tensor([-0.7916,  1.2681, -6.9121], grad_fn=<SubBackward0>), Loss = 0.07489220798015594\n",
      "tensor([ 0.0010, -0.0022,  0.0133])\n",
      "loss = 0.07470967620611191\n",
      "Iteration 182: b = tensor([-0.7926,  1.2703, -6.9253], grad_fn=<SubBackward0>), Loss = 0.07470967620611191\n",
      "tensor([ 0.0010, -0.0022,  0.0132])\n",
      "loss = 0.07452865689992905\n",
      "Iteration 183: b = tensor([-0.7936,  1.2725, -6.9385], grad_fn=<SubBackward0>), Loss = 0.07452865689992905\n",
      "tensor([ 0.0010, -0.0022,  0.0132])\n",
      "loss = 0.07434915751218796\n",
      "Iteration 184: b = tensor([-0.7947,  1.2748, -6.9516], grad_fn=<SubBackward0>), Loss = 0.07434915751218796\n",
      "tensor([ 0.0010, -0.0022,  0.0131])\n",
      "loss = 0.07417113333940506\n",
      "Iteration 185: b = tensor([-0.7957,  1.2770, -6.9647], grad_fn=<SubBackward0>), Loss = 0.07417113333940506\n",
      "tensor([ 0.0010, -0.0022,  0.0131])\n",
      "loss = 0.07399457693099976\n",
      "Iteration 186: b = tensor([-0.7967,  1.2792, -6.9777], grad_fn=<SubBackward0>), Loss = 0.07399457693099976\n",
      "tensor([ 0.0010, -0.0022,  0.0130])\n",
      "loss = 0.07381947338581085\n",
      "Iteration 187: b = tensor([-0.7978,  1.2813, -6.9907], grad_fn=<SubBackward0>), Loss = 0.07381947338581085\n",
      "tensor([ 0.0010, -0.0022,  0.0130])\n",
      "loss = 0.07364578545093536\n",
      "Iteration 188: b = tensor([-0.7988,  1.2835, -7.0036], grad_fn=<SubBackward0>), Loss = 0.07364578545093536\n",
      "tensor([ 0.0010, -0.0022,  0.0129])\n",
      "loss = 0.0734734907746315\n",
      "Iteration 189: b = tensor([-0.7998,  1.2857, -7.0165], grad_fn=<SubBackward0>), Loss = 0.0734734907746315\n",
      "tensor([ 0.0010, -0.0022,  0.0129])\n",
      "loss = 0.07330260425806046\n",
      "Iteration 190: b = tensor([-0.8008,  1.2878, -7.0293], grad_fn=<SubBackward0>), Loss = 0.07330260425806046\n",
      "tensor([ 0.0010, -0.0022,  0.0128])\n",
      "loss = 0.07313305884599686\n",
      "Iteration 191: b = tensor([-0.8018,  1.2900, -7.0420], grad_fn=<SubBackward0>), Loss = 0.07313305884599686\n",
      "tensor([ 0.0010, -0.0021,  0.0128])\n",
      "loss = 0.07296488434076309\n",
      "Iteration 192: b = tensor([-0.8028,  1.2921, -7.0548], grad_fn=<SubBackward0>), Loss = 0.07296488434076309\n",
      "tensor([ 0.0010, -0.0021,  0.0127])\n",
      "loss = 0.07279804348945618\n",
      "Iteration 193: b = tensor([-0.8038,  1.2942, -7.0674], grad_fn=<SubBackward0>), Loss = 0.07279804348945618\n",
      "tensor([ 0.0010, -0.0021,  0.0127])\n",
      "loss = 0.07263249903917313\n",
      "Iteration 194: b = tensor([-0.8048,  1.2963, -7.0800], grad_fn=<SubBackward0>), Loss = 0.07263249903917313\n",
      "tensor([ 0.0010, -0.0021,  0.0126])\n",
      "loss = 0.07246825098991394\n",
      "Iteration 195: b = tensor([-0.8058,  1.2985, -7.0926], grad_fn=<SubBackward0>), Loss = 0.07246825098991394\n",
      "tensor([ 0.0010, -0.0021,  0.0126])\n",
      "loss = 0.07230526953935623\n",
      "Iteration 196: b = tensor([-0.8068,  1.3006, -7.1051], grad_fn=<SubBackward0>), Loss = 0.07230526953935623\n",
      "tensor([ 0.0010, -0.0021,  0.0125])\n",
      "loss = 0.07214357703924179\n",
      "Iteration 197: b = tensor([-0.8077,  1.3026, -7.1176], grad_fn=<SubBackward0>), Loss = 0.07214357703924179\n",
      "tensor([ 0.0010, -0.0021,  0.0125])\n",
      "loss = 0.07198311388492584\n",
      "Iteration 198: b = tensor([-0.8087,  1.3047, -7.1300], grad_fn=<SubBackward0>), Loss = 0.07198311388492584\n",
      "tensor([ 0.0010, -0.0021,  0.0124])\n",
      "loss = 0.07182388007640839\n",
      "Iteration 199: b = tensor([-0.8097,  1.3068, -7.1424], grad_fn=<SubBackward0>), Loss = 0.07182388007640839\n",
      "tensor([ 0.0010, -0.0021,  0.0124])\n",
      "loss = 0.07166585326194763\n",
      "Iteration 200: b = tensor([-0.8106,  1.3089, -7.1547], grad_fn=<SubBackward0>), Loss = 0.07166585326194763\n",
      "tensor([ 0.0010, -0.0021,  0.0123])\n",
      "loss = 0.07150902599096298\n",
      "Iteration 201: b = tensor([-0.8116,  1.3109, -7.1670], grad_fn=<SubBackward0>), Loss = 0.07150902599096298\n",
      "tensor([ 0.0010, -0.0021,  0.0123])\n",
      "loss = 0.07135338336229324\n",
      "Iteration 202: b = tensor([-0.8126,  1.3130, -7.1792], grad_fn=<SubBackward0>), Loss = 0.07135338336229324\n",
      "tensor([ 0.0010, -0.0020,  0.0122])\n",
      "loss = 0.07119890302419662\n",
      "Iteration 203: b = tensor([-0.8135,  1.3150, -7.1914], grad_fn=<SubBackward0>), Loss = 0.07119890302419662\n",
      "tensor([ 0.0010, -0.0020,  0.0122])\n",
      "loss = 0.07104557007551193\n",
      "Iteration 204: b = tensor([-0.8145,  1.3171, -7.2035], grad_fn=<SubBackward0>), Loss = 0.07104557007551193\n",
      "tensor([ 0.0010, -0.0020,  0.0121])\n",
      "loss = 0.07089339196681976\n",
      "Iteration 205: b = tensor([-0.8154,  1.3191, -7.2156], grad_fn=<SubBackward0>), Loss = 0.07089339196681976\n",
      "tensor([ 0.0009, -0.0020,  0.0121])\n",
      "loss = 0.07074232399463654\n",
      "Iteration 206: b = tensor([-0.8164,  1.3211, -7.2277], grad_fn=<SubBackward0>), Loss = 0.07074232399463654\n",
      "tensor([ 0.0009, -0.0020,  0.0121])\n",
      "loss = 0.07059236615896225\n",
      "Iteration 207: b = tensor([-0.8173,  1.3231, -7.2397], grad_fn=<SubBackward0>), Loss = 0.07059236615896225\n",
      "tensor([ 0.0009, -0.0020,  0.0120])\n",
      "loss = 0.07044351100921631\n",
      "Iteration 208: b = tensor([-0.8182,  1.3251, -7.2517], grad_fn=<SubBackward0>), Loss = 0.07044351100921631\n",
      "tensor([ 0.0009, -0.0020,  0.0120])\n",
      "loss = 0.07029573619365692\n",
      "Iteration 209: b = tensor([-0.8192,  1.3271, -7.2636], grad_fn=<SubBackward0>), Loss = 0.07029573619365692\n",
      "tensor([ 0.0009, -0.0020,  0.0119])\n",
      "loss = 0.0701490193605423\n",
      "Iteration 210: b = tensor([-0.8201,  1.3291, -7.2755], grad_fn=<SubBackward0>), Loss = 0.0701490193605423\n",
      "tensor([ 0.0009, -0.0020,  0.0119])\n",
      "loss = 0.07000338286161423\n",
      "Iteration 211: b = tensor([-0.8210,  1.3311, -7.2873], grad_fn=<SubBackward0>), Loss = 0.07000338286161423\n",
      "tensor([ 0.0009, -0.0020,  0.0118])\n",
      "loss = 0.06985875219106674\n",
      "Iteration 212: b = tensor([-0.8219,  1.3330, -7.2991], grad_fn=<SubBackward0>), Loss = 0.06985875219106674\n",
      "tensor([ 0.0009, -0.0020,  0.0118])\n",
      "loss = 0.06971517205238342\n",
      "Iteration 213: b = tensor([-0.8229,  1.3350, -7.3109], grad_fn=<SubBackward0>), Loss = 0.06971517205238342\n",
      "tensor([ 0.0009, -0.0020,  0.0118])\n",
      "loss = 0.06957262754440308\n",
      "Iteration 214: b = tensor([-0.8238,  1.3369, -7.3226], grad_fn=<SubBackward0>), Loss = 0.06957262754440308\n",
      "tensor([ 0.0009, -0.0020,  0.0117])\n",
      "loss = 0.06943108886480331\n",
      "Iteration 215: b = tensor([-0.8247,  1.3389, -7.3342], grad_fn=<SubBackward0>), Loss = 0.06943108886480331\n",
      "tensor([ 0.0009, -0.0019,  0.0117])\n",
      "loss = 0.06929050385951996\n",
      "Iteration 216: b = tensor([-0.8256,  1.3408, -7.3459], grad_fn=<SubBackward0>), Loss = 0.06929050385951996\n",
      "tensor([ 0.0009, -0.0019,  0.0116])\n",
      "loss = 0.06915092468261719\n",
      "Iteration 217: b = tensor([-0.8265,  1.3428, -7.3575], grad_fn=<SubBackward0>), Loss = 0.06915092468261719\n",
      "tensor([ 0.0009, -0.0019,  0.0116])\n",
      "loss = 0.06901232153177261\n",
      "Iteration 218: b = tensor([-0.8274,  1.3447, -7.3690], grad_fn=<SubBackward0>), Loss = 0.06901232153177261\n",
      "tensor([ 0.0009, -0.0019,  0.0115])\n",
      "loss = 0.06887466460466385\n",
      "Iteration 219: b = tensor([-0.8283,  1.3466, -7.3805], grad_fn=<SubBackward0>), Loss = 0.06887466460466385\n",
      "tensor([ 0.0009, -0.0019,  0.0115])\n",
      "loss = 0.06873796880245209\n",
      "Iteration 220: b = tensor([-0.8292,  1.3485, -7.3920], grad_fn=<SubBackward0>), Loss = 0.06873796880245209\n",
      "tensor([ 0.0009, -0.0019,  0.0115])\n",
      "loss = 0.06860220432281494\n",
      "Iteration 221: b = tensor([-0.8301,  1.3504, -7.4034], grad_fn=<SubBackward0>), Loss = 0.06860220432281494\n",
      "tensor([ 0.0009, -0.0019,  0.0114])\n",
      "loss = 0.06846734881401062\n",
      "Iteration 222: b = tensor([-0.8309,  1.3523, -7.4148], grad_fn=<SubBackward0>), Loss = 0.06846734881401062\n",
      "tensor([ 0.0009, -0.0019,  0.0114])\n",
      "loss = 0.06833343207836151\n",
      "Iteration 223: b = tensor([-0.8318,  1.3542, -7.4262], grad_fn=<SubBackward0>), Loss = 0.06833343207836151\n",
      "tensor([ 0.0009, -0.0019,  0.0114])\n",
      "loss = 0.06820041686296463\n",
      "Iteration 224: b = tensor([-0.8327,  1.3561, -7.4375], grad_fn=<SubBackward0>), Loss = 0.06820041686296463\n",
      "tensor([ 0.0009, -0.0019,  0.0113])\n",
      "loss = 0.06806829571723938\n",
      "Iteration 225: b = tensor([-0.8336,  1.3580, -7.4487], grad_fn=<SubBackward0>), Loss = 0.06806829571723938\n",
      "tensor([ 0.0009, -0.0019,  0.0113])\n",
      "loss = 0.06793704628944397\n",
      "Iteration 226: b = tensor([-0.8344,  1.3598, -7.4600], grad_fn=<SubBackward0>), Loss = 0.06793704628944397\n",
      "tensor([ 0.0009, -0.0019,  0.0112])\n",
      "loss = 0.06780669093132019\n",
      "Iteration 227: b = tensor([-0.8353,  1.3617, -7.4712], grad_fn=<SubBackward0>), Loss = 0.06780669093132019\n",
      "tensor([ 0.0009, -0.0019,  0.0112])\n",
      "loss = 0.06767719238996506\n",
      "Iteration 228: b = tensor([-0.8362,  1.3635, -7.4824], grad_fn=<SubBackward0>), Loss = 0.06767719238996506\n",
      "tensor([ 0.0009, -0.0019,  0.0112])\n",
      "loss = 0.06754854321479797\n",
      "Iteration 229: b = tensor([-0.8370,  1.3654, -7.4935], grad_fn=<SubBackward0>), Loss = 0.06754854321479797\n",
      "tensor([ 0.0009, -0.0018,  0.0111])\n",
      "loss = 0.06742073595523834\n",
      "Iteration 230: b = tensor([-0.8379,  1.3672, -7.5046], grad_fn=<SubBackward0>), Loss = 0.06742073595523834\n",
      "tensor([ 0.0009, -0.0018,  0.0111])\n",
      "loss = 0.06729377806186676\n",
      "Iteration 231: b = tensor([-0.8388,  1.3690, -7.5156], grad_fn=<SubBackward0>), Loss = 0.06729377806186676\n",
      "tensor([ 0.0009, -0.0018,  0.0111])\n",
      "loss = 0.06716763973236084\n",
      "Iteration 232: b = tensor([-0.8396,  1.3709, -7.5267], grad_fn=<SubBackward0>), Loss = 0.06716763973236084\n",
      "tensor([ 0.0009, -0.0018,  0.0110])\n",
      "loss = 0.06704232096672058\n",
      "Iteration 233: b = tensor([-0.8405,  1.3727, -7.5376], grad_fn=<SubBackward0>), Loss = 0.06704232096672058\n",
      "tensor([ 0.0008, -0.0018,  0.0110])\n",
      "loss = 0.06691781431436539\n",
      "Iteration 234: b = tensor([-0.8413,  1.3745, -7.5486], grad_fn=<SubBackward0>), Loss = 0.06691781431436539\n",
      "tensor([ 0.0008, -0.0018,  0.0110])\n",
      "loss = 0.06679410487413406\n",
      "Iteration 235: b = tensor([-0.8421,  1.3763, -7.5595], grad_fn=<SubBackward0>), Loss = 0.06679410487413406\n",
      "tensor([ 0.0008, -0.0018,  0.0109])\n",
      "loss = 0.06667117774486542\n",
      "Iteration 236: b = tensor([-0.8430,  1.3781, -7.5704], grad_fn=<SubBackward0>), Loss = 0.06667117774486542\n",
      "tensor([ 0.0008, -0.0018,  0.0109])\n",
      "loss = 0.06654904037714005\n",
      "Iteration 237: b = tensor([-0.8438,  1.3799, -7.5812], grad_fn=<SubBackward0>), Loss = 0.06654904037714005\n",
      "tensor([ 0.0008, -0.0018,  0.0108])\n",
      "loss = 0.06642767041921616\n",
      "Iteration 238: b = tensor([-0.8446,  1.3817, -7.5920], grad_fn=<SubBackward0>), Loss = 0.06642767041921616\n",
      "tensor([ 0.0008, -0.0018,  0.0108])\n",
      "loss = 0.06630708277225494\n",
      "Iteration 239: b = tensor([-0.8455,  1.3835, -7.6028], grad_fn=<SubBackward0>), Loss = 0.06630708277225494\n",
      "tensor([ 0.0008, -0.0018,  0.0108])\n",
      "loss = 0.06618724018335342\n",
      "Iteration 240: b = tensor([-0.8463,  1.3852, -7.6136], grad_fn=<SubBackward0>), Loss = 0.06618724018335342\n",
      "tensor([ 0.0008, -0.0018,  0.0107])\n",
      "loss = 0.0660681501030922\n",
      "Iteration 241: b = tensor([-0.8471,  1.3870, -7.6243], grad_fn=<SubBackward0>), Loss = 0.0660681501030922\n",
      "tensor([ 0.0008, -0.0018,  0.0107])\n",
      "loss = 0.06594979763031006\n",
      "Iteration 242: b = tensor([-0.8479,  1.3888, -7.6350], grad_fn=<SubBackward0>), Loss = 0.06594979763031006\n",
      "tensor([ 0.0008, -0.0018,  0.0107])\n",
      "loss = 0.06583219021558762\n",
      "Iteration 243: b = tensor([-0.8488,  1.3905, -7.6456], grad_fn=<SubBackward0>), Loss = 0.06583219021558762\n",
      "tensor([ 0.0008, -0.0018,  0.0106])\n",
      "loss = 0.06571530550718307\n",
      "Iteration 244: b = tensor([-0.8496,  1.3923, -7.6562], grad_fn=<SubBackward0>), Loss = 0.06571530550718307\n",
      "tensor([ 0.0008, -0.0017,  0.0106])\n",
      "loss = 0.06559914350509644\n",
      "Iteration 245: b = tensor([-0.8504,  1.3940, -7.6668], grad_fn=<SubBackward0>), Loss = 0.06559914350509644\n",
      "tensor([ 0.0008, -0.0017,  0.0106])\n",
      "loss = 0.06548367440700531\n",
      "Iteration 246: b = tensor([-0.8512,  1.3957, -7.6773], grad_fn=<SubBackward0>), Loss = 0.06548367440700531\n",
      "tensor([ 0.0008, -0.0017,  0.0105])\n",
      "loss = 0.06536892801523209\n",
      "Iteration 247: b = tensor([-0.8520,  1.3975, -7.6879], grad_fn=<SubBackward0>), Loss = 0.06536892801523209\n",
      "tensor([ 0.0008, -0.0017,  0.0105])\n",
      "loss = 0.06525487452745438\n",
      "Iteration 248: b = tensor([-0.8528,  1.3992, -7.6984], grad_fn=<SubBackward0>), Loss = 0.06525487452745438\n",
      "tensor([ 0.0008, -0.0017,  0.0105])\n",
      "loss = 0.06514150649309158\n",
      "Iteration 249: b = tensor([-0.8536,  1.4009, -7.7088], grad_fn=<SubBackward0>), Loss = 0.06514150649309158\n",
      "tensor([ 0.0008, -0.0017,  0.0105])\n",
      "loss = 0.06502882391214371\n",
      "Iteration 250: b = tensor([-0.8544,  1.4026, -7.7192], grad_fn=<SubBackward0>), Loss = 0.06502882391214371\n",
      "tensor([ 0.0008, -0.0017,  0.0104])\n",
      "loss = 0.06491681188344955\n",
      "Iteration 251: b = tensor([-0.8552,  1.4043, -7.7296], grad_fn=<SubBackward0>), Loss = 0.06491681188344955\n",
      "tensor([ 0.0008, -0.0017,  0.0104])\n",
      "loss = 0.06480547040700912\n",
      "Iteration 252: b = tensor([-0.8560,  1.4060, -7.7400], grad_fn=<SubBackward0>), Loss = 0.06480547040700912\n",
      "tensor([ 0.0008, -0.0017,  0.0104])\n",
      "loss = 0.06469479948282242\n",
      "Iteration 253: b = tensor([-0.8568,  1.4077, -7.7503], grad_fn=<SubBackward0>), Loss = 0.06469479948282242\n",
      "tensor([ 0.0008, -0.0017,  0.0103])\n",
      "loss = 0.06458476930856705\n",
      "Iteration 254: b = tensor([-0.8575,  1.4094, -7.7606], grad_fn=<SubBackward0>), Loss = 0.06458476930856705\n",
      "tensor([ 0.0008, -0.0017,  0.0103])\n",
      "loss = 0.0644754096865654\n",
      "Iteration 255: b = tensor([-0.8583,  1.4111, -7.7709], grad_fn=<SubBackward0>), Loss = 0.0644754096865654\n",
      "tensor([ 0.0008, -0.0017,  0.0103])\n",
      "loss = 0.0643666684627533\n",
      "Iteration 256: b = tensor([-0.8591,  1.4128, -7.7811], grad_fn=<SubBackward0>), Loss = 0.0643666684627533\n",
      "tensor([ 0.0008, -0.0017,  0.0102])\n",
      "loss = 0.06425857543945312\n",
      "Iteration 257: b = tensor([-0.8599,  1.4144, -7.7913], grad_fn=<SubBackward0>), Loss = 0.06425857543945312\n",
      "tensor([ 0.0008, -0.0017,  0.0102])\n",
      "loss = 0.0641511082649231\n",
      "Iteration 258: b = tensor([-0.8606,  1.4161, -7.8015], grad_fn=<SubBackward0>), Loss = 0.0641511082649231\n",
      "tensor([ 0.0008, -0.0017,  0.0102])\n",
      "loss = 0.0640442743897438\n",
      "Iteration 259: b = tensor([-0.8614,  1.4177, -7.8117], grad_fn=<SubBackward0>), Loss = 0.0640442743897438\n",
      "tensor([ 0.0008, -0.0017,  0.0102])\n",
      "loss = 0.06393804401159286\n",
      "Iteration 260: b = tensor([-0.8622,  1.4194, -7.8218], grad_fn=<SubBackward0>), Loss = 0.06393804401159286\n",
      "tensor([ 0.0008, -0.0017,  0.0101])\n",
      "loss = 0.06383243948221207\n",
      "Iteration 261: b = tensor([-0.8630,  1.4210, -7.8319], grad_fn=<SubBackward0>), Loss = 0.06383243948221207\n",
      "tensor([ 0.0008, -0.0016,  0.0101])\n",
      "loss = 0.06372743099927902\n",
      "Iteration 262: b = tensor([-0.8637,  1.4227, -7.8419], grad_fn=<SubBackward0>), Loss = 0.06372743099927902\n",
      "tensor([ 0.0008, -0.0016,  0.0101])\n",
      "loss = 0.06362301856279373\n",
      "Iteration 263: b = tensor([-0.8645,  1.4243, -7.8520], grad_fn=<SubBackward0>), Loss = 0.06362301856279373\n",
      "tensor([ 0.0008, -0.0016,  0.0100])\n",
      "loss = 0.06351920962333679\n",
      "Iteration 264: b = tensor([-0.8652,  1.4259, -7.8620], grad_fn=<SubBackward0>), Loss = 0.06351920962333679\n",
      "tensor([ 0.0008, -0.0016,  0.0100])\n",
      "loss = 0.06341598182916641\n",
      "Iteration 265: b = tensor([-0.8660,  1.4276, -7.8720], grad_fn=<SubBackward0>), Loss = 0.06341598182916641\n",
      "tensor([ 0.0008, -0.0016,  0.0100])\n",
      "loss = 0.06331334263086319\n",
      "Iteration 266: b = tensor([-0.8667,  1.4292, -7.8819], grad_fn=<SubBackward0>), Loss = 0.06331334263086319\n",
      "tensor([ 0.0008, -0.0016,  0.0100])\n",
      "loss = 0.06321126967668533\n",
      "Iteration 267: b = tensor([-0.8675,  1.4308, -7.8918], grad_fn=<SubBackward0>), Loss = 0.06321126967668533\n",
      "tensor([ 0.0007, -0.0016,  0.0099])\n",
      "loss = 0.06310979276895523\n",
      "Iteration 268: b = tensor([-0.8682,  1.4324, -7.9017], grad_fn=<SubBackward0>), Loss = 0.06310979276895523\n",
      "tensor([ 0.0007, -0.0016,  0.0099])\n",
      "loss = 0.0630088597536087\n",
      "Iteration 269: b = tensor([-0.8690,  1.4340, -7.9116], grad_fn=<SubBackward0>), Loss = 0.0630088597536087\n",
      "tensor([ 0.0007, -0.0016,  0.0099])\n",
      "loss = 0.06290847808122635\n",
      "Iteration 270: b = tensor([-0.8697,  1.4356, -7.9214], grad_fn=<SubBackward0>), Loss = 0.06290847808122635\n",
      "tensor([ 0.0007, -0.0016,  0.0098])\n",
      "loss = 0.06280866265296936\n",
      "Iteration 271: b = tensor([-0.8704,  1.4372, -7.9312], grad_fn=<SubBackward0>), Loss = 0.06280866265296936\n",
      "tensor([ 0.0007, -0.0016,  0.0098])\n",
      "loss = 0.06270939856767654\n",
      "Iteration 272: b = tensor([-0.8712,  1.4388, -7.9410], grad_fn=<SubBackward0>), Loss = 0.06270939856767654\n",
      "tensor([ 0.0007, -0.0016,  0.0098])\n",
      "loss = 0.0626106858253479\n",
      "Iteration 273: b = tensor([-0.8719,  1.4404, -7.9508], grad_fn=<SubBackward0>), Loss = 0.0626106858253479\n",
      "tensor([ 0.0007, -0.0016,  0.0098])\n",
      "loss = 0.06251251697540283\n",
      "Iteration 274: b = tensor([-0.8726,  1.4419, -7.9605], grad_fn=<SubBackward0>), Loss = 0.06251251697540283\n",
      "tensor([ 0.0007, -0.0016,  0.0097])\n",
      "loss = 0.06241486966609955\n",
      "Iteration 275: b = tensor([-0.8734,  1.4435, -7.9702], grad_fn=<SubBackward0>), Loss = 0.06241486966609955\n",
      "tensor([ 0.0007, -0.0016,  0.0097])\n",
      "loss = 0.062317751348018646\n",
      "Iteration 276: b = tensor([-0.8741,  1.4451, -7.9799], grad_fn=<SubBackward0>), Loss = 0.062317751348018646\n",
      "tensor([ 0.0007, -0.0016,  0.0097])\n",
      "loss = 0.06222117319703102\n",
      "Iteration 277: b = tensor([-0.8748,  1.4466, -7.9896], grad_fn=<SubBackward0>), Loss = 0.06222117319703102\n",
      "tensor([ 0.0007, -0.0016,  0.0097])\n",
      "loss = 0.062125109136104584\n",
      "Iteration 278: b = tensor([-0.8755,  1.4482, -7.9992], grad_fn=<SubBackward0>), Loss = 0.062125109136104584\n",
      "tensor([ 0.0007, -0.0016,  0.0096])\n",
      "loss = 0.06202955171465874\n",
      "Iteration 279: b = tensor([-0.8763,  1.4498, -8.0088], grad_fn=<SubBackward0>), Loss = 0.06202955171465874\n",
      "tensor([ 0.0007, -0.0016,  0.0096])\n",
      "loss = 0.06193450465798378\n",
      "Iteration 280: b = tensor([-0.8770,  1.4513, -8.0184], grad_fn=<SubBackward0>), Loss = 0.06193450465798378\n",
      "tensor([ 0.0007, -0.0015,  0.0096])\n",
      "loss = 0.06183997541666031\n",
      "Iteration 281: b = tensor([-0.8777,  1.4528, -8.0279], grad_fn=<SubBackward0>), Loss = 0.06183997541666031\n",
      "tensor([ 0.0007, -0.0015,  0.0096])\n",
      "loss = 0.06174594908952713\n",
      "Iteration 282: b = tensor([-0.8784,  1.4544, -8.0375], grad_fn=<SubBackward0>), Loss = 0.06174594908952713\n",
      "tensor([ 0.0007, -0.0015,  0.0095])\n",
      "loss = 0.06165241450071335\n",
      "Iteration 283: b = tensor([-0.8791,  1.4559, -8.0470], grad_fn=<SubBackward0>), Loss = 0.06165241450071335\n",
      "tensor([ 0.0007, -0.0015,  0.0095])\n",
      "loss = 0.061559371650218964\n",
      "Iteration 284: b = tensor([-0.8798,  1.4574, -8.0565], grad_fn=<SubBackward0>), Loss = 0.061559371650218964\n",
      "tensor([ 0.0007, -0.0015,  0.0095])\n",
      "loss = 0.061466824263334274\n",
      "Iteration 285: b = tensor([-0.8805,  1.4590, -8.0659], grad_fn=<SubBackward0>), Loss = 0.061466824263334274\n",
      "tensor([ 0.0007, -0.0015,  0.0095])\n",
      "loss = 0.06137475371360779\n",
      "Iteration 286: b = tensor([-0.8812,  1.4605, -8.0753], grad_fn=<SubBackward0>), Loss = 0.06137475371360779\n",
      "tensor([ 0.0007, -0.0015,  0.0094])\n",
      "loss = 0.06128315255045891\n",
      "Iteration 287: b = tensor([-0.8819,  1.4620, -8.0847], grad_fn=<SubBackward0>), Loss = 0.06128315255045891\n",
      "tensor([ 0.0007, -0.0015,  0.0094])\n",
      "loss = 0.06119205057621002\n",
      "Iteration 288: b = tensor([-0.8826,  1.4635, -8.0941], grad_fn=<SubBackward0>), Loss = 0.06119205057621002\n",
      "tensor([ 0.0007, -0.0015,  0.0094])\n",
      "loss = 0.061101410537958145\n",
      "Iteration 289: b = tensor([-0.8833,  1.4650, -8.1035], grad_fn=<SubBackward0>), Loss = 0.061101410537958145\n",
      "tensor([ 0.0007, -0.0015,  0.0094])\n",
      "loss = 0.061011217534542084\n",
      "Iteration 290: b = tensor([-0.8840,  1.4665, -8.1128], grad_fn=<SubBackward0>), Loss = 0.061011217534542084\n",
      "tensor([ 0.0007, -0.0015,  0.0093])\n",
      "loss = 0.06092151999473572\n",
      "Iteration 291: b = tensor([-0.8847,  1.4680, -8.1221], grad_fn=<SubBackward0>), Loss = 0.06092151999473572\n",
      "tensor([ 0.0007, -0.0015,  0.0093])\n",
      "loss = 0.06083225458860397\n",
      "Iteration 292: b = tensor([-0.8854,  1.4695, -8.1314], grad_fn=<SubBackward0>), Loss = 0.06083225458860397\n",
      "tensor([ 0.0007, -0.0015,  0.0093])\n",
      "loss = 0.06074346974492073\n",
      "Iteration 293: b = tensor([-0.8861,  1.4709, -8.1407], grad_fn=<SubBackward0>), Loss = 0.06074346974492073\n",
      "tensor([ 0.0007, -0.0015,  0.0093])\n",
      "loss = 0.06065511703491211\n",
      "Iteration 294: b = tensor([-0.8867,  1.4724, -8.1499], grad_fn=<SubBackward0>), Loss = 0.06065511703491211\n",
      "tensor([ 0.0007, -0.0015,  0.0092])\n",
      "loss = 0.0605672225356102\n",
      "Iteration 295: b = tensor([-0.8874,  1.4739, -8.1591], grad_fn=<SubBackward0>), Loss = 0.0605672225356102\n",
      "tensor([ 0.0007, -0.0015,  0.0092])\n",
      "loss = 0.06047975644469261\n",
      "Iteration 296: b = tensor([-0.8881,  1.4754, -8.1683], grad_fn=<SubBackward0>), Loss = 0.06047975644469261\n",
      "tensor([ 0.0007, -0.0015,  0.0092])\n",
      "loss = 0.06039274111390114\n",
      "Iteration 297: b = tensor([-0.8888,  1.4768, -8.1775], grad_fn=<SubBackward0>), Loss = 0.06039274111390114\n",
      "tensor([ 0.0007, -0.0015,  0.0092])\n",
      "loss = 0.060306161642074585\n",
      "Iteration 298: b = tensor([-0.8894,  1.4783, -8.1866], grad_fn=<SubBackward0>), Loss = 0.060306161642074585\n",
      "tensor([ 0.0007, -0.0015,  0.0091])\n",
      "loss = 0.06021999567747116\n",
      "Iteration 299: b = tensor([-0.8901,  1.4797, -8.1958], grad_fn=<SubBackward0>), Loss = 0.06021999567747116\n",
      "tensor([ 0.0007, -0.0015,  0.0091])\n",
      "loss = 0.06013428792357445\n",
      "Iteration 300: b = tensor([-0.8908,  1.4812, -8.2049], grad_fn=<SubBackward0>), Loss = 0.06013428792357445\n",
      "tensor([ 0.0007, -0.0014,  0.0091])\n",
      "loss = 0.06004900112748146\n",
      "Iteration 301: b = tensor([-0.8915,  1.4826, -8.2139], grad_fn=<SubBackward0>), Loss = 0.06004900112748146\n",
      "tensor([ 0.0007, -0.0014,  0.0091])\n",
      "loss = 0.059964124113321304\n",
      "Iteration 302: b = tensor([-0.8921,  1.4841, -8.2230], grad_fn=<SubBackward0>), Loss = 0.059964124113321304\n",
      "tensor([ 0.0007, -0.0014,  0.0091])\n",
      "loss = 0.05987965688109398\n",
      "Iteration 303: b = tensor([-0.8928,  1.4855, -8.2320], grad_fn=<SubBackward0>), Loss = 0.05987965688109398\n",
      "tensor([ 0.0007, -0.0014,  0.0090])\n",
      "loss = 0.05979563295841217\n",
      "Iteration 304: b = tensor([-0.8934,  1.4869, -8.2411], grad_fn=<SubBackward0>), Loss = 0.05979563295841217\n",
      "tensor([ 0.0007, -0.0014,  0.0090])\n",
      "loss = 0.0597120076417923\n",
      "Iteration 305: b = tensor([-0.8941,  1.4884, -8.2500], grad_fn=<SubBackward0>), Loss = 0.0597120076417923\n",
      "tensor([ 0.0007, -0.0014,  0.0090])\n",
      "loss = 0.05962878093123436\n",
      "Iteration 306: b = tensor([-0.8947,  1.4898, -8.2590], grad_fn=<SubBackward0>), Loss = 0.05962878093123436\n",
      "tensor([ 0.0007, -0.0014,  0.0090])\n",
      "loss = 0.05954596772789955\n",
      "Iteration 307: b = tensor([-0.8954,  1.4912, -8.2680], grad_fn=<SubBackward0>), Loss = 0.05954596772789955\n",
      "tensor([ 0.0007, -0.0014,  0.0089])\n",
      "loss = 0.05946355685591698\n",
      "Iteration 308: b = tensor([-0.8961,  1.4926, -8.2769], grad_fn=<SubBackward0>), Loss = 0.05946355685591698\n",
      "tensor([ 0.0007, -0.0014,  0.0089])\n",
      "loss = 0.05938154086470604\n",
      "Iteration 309: b = tensor([-0.8967,  1.4940, -8.2858], grad_fn=<SubBackward0>), Loss = 0.05938154086470604\n",
      "tensor([ 0.0006, -0.0014,  0.0089])\n",
      "loss = 0.05929991975426674\n",
      "Iteration 310: b = tensor([-0.8973,  1.4954, -8.2947], grad_fn=<SubBackward0>), Loss = 0.05929991975426674\n",
      "tensor([ 0.0006, -0.0014,  0.0089])\n",
      "loss = 0.05921867862343788\n",
      "Iteration 311: b = tensor([-0.8980,  1.4968, -8.3035], grad_fn=<SubBackward0>), Loss = 0.05921867862343788\n",
      "tensor([ 0.0006, -0.0014,  0.0089])\n",
      "loss = 0.05913783609867096\n",
      "Iteration 312: b = tensor([-0.8986,  1.4982, -8.3124], grad_fn=<SubBackward0>), Loss = 0.05913783609867096\n",
      "tensor([ 0.0006, -0.0014,  0.0088])\n",
      "loss = 0.05905737355351448\n",
      "Iteration 313: b = tensor([-0.8993,  1.4996, -8.3212], grad_fn=<SubBackward0>), Loss = 0.05905737355351448\n",
      "tensor([ 0.0006, -0.0014,  0.0088])\n",
      "loss = 0.05897729843854904\n",
      "Iteration 314: b = tensor([-0.8999,  1.5010, -8.3300], grad_fn=<SubBackward0>), Loss = 0.05897729843854904\n",
      "tensor([ 0.0006, -0.0014,  0.0088])\n",
      "loss = 0.05889761075377464\n",
      "Iteration 315: b = tensor([-0.9006,  1.5024, -8.3388], grad_fn=<SubBackward0>), Loss = 0.05889761075377464\n",
      "tensor([ 0.0006, -0.0014,  0.0088])\n",
      "loss = 0.058818280696868896\n",
      "Iteration 316: b = tensor([-0.9012,  1.5038, -8.3476], grad_fn=<SubBackward0>), Loss = 0.058818280696868896\n",
      "tensor([ 0.0006, -0.0014,  0.0088])\n",
      "loss = 0.05873933434486389\n",
      "Iteration 317: b = tensor([-0.9018,  1.5052, -8.3563], grad_fn=<SubBackward0>), Loss = 0.05873933434486389\n",
      "tensor([ 0.0006, -0.0014,  0.0087])\n",
      "loss = 0.05866076052188873\n",
      "Iteration 318: b = tensor([-0.9024,  1.5065, -8.3650], grad_fn=<SubBackward0>), Loss = 0.05866076052188873\n",
      "tensor([ 0.0006, -0.0014,  0.0087])\n",
      "loss = 0.05858253687620163\n",
      "Iteration 319: b = tensor([-0.9031,  1.5079, -8.3737], grad_fn=<SubBackward0>), Loss = 0.05858253687620163\n",
      "tensor([ 0.0006, -0.0014,  0.0087])\n",
      "loss = 0.05850468948483467\n",
      "Iteration 320: b = tensor([-0.9037,  1.5093, -8.3824], grad_fn=<SubBackward0>), Loss = 0.05850468948483467\n",
      "tensor([ 0.0006, -0.0014,  0.0087])\n",
      "loss = 0.058427195996046066\n",
      "Iteration 321: b = tensor([-0.9043,  1.5106, -8.3910], grad_fn=<SubBackward0>), Loss = 0.058427195996046066\n",
      "tensor([ 0.0006, -0.0014,  0.0087])\n",
      "loss = 0.05835006758570671\n",
      "Iteration 322: b = tensor([-0.9049,  1.5120, -8.3997], grad_fn=<SubBackward0>), Loss = 0.05835006758570671\n",
      "tensor([ 0.0006, -0.0014,  0.0086])\n",
      "loss = 0.05827329680323601\n",
      "Iteration 323: b = tensor([-0.9056,  1.5133, -8.4083], grad_fn=<SubBackward0>), Loss = 0.05827329680323601\n",
      "tensor([ 0.0006, -0.0014,  0.0086])\n",
      "loss = 0.05819687247276306\n",
      "Iteration 324: b = tensor([-0.9062,  1.5147, -8.4169], grad_fn=<SubBackward0>), Loss = 0.05819687247276306\n",
      "tensor([ 0.0006, -0.0013,  0.0086])\n",
      "loss = 0.05812079459428787\n",
      "Iteration 325: b = tensor([-0.9068,  1.5160, -8.4255], grad_fn=<SubBackward0>), Loss = 0.05812079459428787\n",
      "tensor([ 0.0006, -0.0013,  0.0086])\n",
      "loss = 0.058045074343681335\n",
      "Iteration 326: b = tensor([-0.9074,  1.5174, -8.4340], grad_fn=<SubBackward0>), Loss = 0.058045074343681335\n",
      "tensor([ 0.0006, -0.0013,  0.0086])\n",
      "loss = 0.057969700545072556\n",
      "Iteration 327: b = tensor([-0.9080,  1.5187, -8.4426], grad_fn=<SubBackward0>), Loss = 0.057969700545072556\n",
      "tensor([ 0.0006, -0.0013,  0.0085])\n",
      "loss = 0.05789464712142944\n",
      "Iteration 328: b = tensor([-0.9086,  1.5200, -8.4511], grad_fn=<SubBackward0>), Loss = 0.05789464712142944\n",
      "tensor([ 0.0006, -0.0013,  0.0085])\n",
      "loss = 0.05781994387507439\n",
      "Iteration 329: b = tensor([-0.9092,  1.5214, -8.4596], grad_fn=<SubBackward0>), Loss = 0.05781994387507439\n",
      "tensor([ 0.0006, -0.0013,  0.0085])\n",
      "loss = 0.05774558708071709\n",
      "Iteration 330: b = tensor([-0.9099,  1.5227, -8.4681], grad_fn=<SubBackward0>), Loss = 0.05774558708071709\n",
      "tensor([ 0.0006, -0.0013,  0.0085])\n",
      "loss = 0.057671546936035156\n",
      "Iteration 331: b = tensor([-0.9105,  1.5240, -8.4766], grad_fn=<SubBackward0>), Loss = 0.057671546936035156\n",
      "tensor([ 0.0006, -0.0013,  0.0085])\n",
      "loss = 0.05759785696864128\n",
      "Iteration 332: b = tensor([-0.9111,  1.5253, -8.4850], grad_fn=<SubBackward0>), Loss = 0.05759785696864128\n",
      "tensor([ 0.0006, -0.0013,  0.0084])\n",
      "loss = 0.057524483650922775\n",
      "Iteration 333: b = tensor([-0.9117,  1.5266, -8.4934], grad_fn=<SubBackward0>), Loss = 0.057524483650922775\n",
      "tensor([ 0.0006, -0.0013,  0.0084])\n",
      "loss = 0.057451438158750534\n",
      "Iteration 334: b = tensor([-0.9123,  1.5279, -8.5019], grad_fn=<SubBackward0>), Loss = 0.057451438158750534\n",
      "tensor([ 0.0006, -0.0013,  0.0084])\n",
      "loss = 0.05737872049212456\n",
      "Iteration 335: b = tensor([-0.9129,  1.5292, -8.5102], grad_fn=<SubBackward0>), Loss = 0.05737872049212456\n",
      "tensor([ 0.0006, -0.0013,  0.0084])\n",
      "loss = 0.05730631574988365\n",
      "Iteration 336: b = tensor([-0.9135,  1.5305, -8.5186], grad_fn=<SubBackward0>), Loss = 0.05730631574988365\n",
      "tensor([ 0.0006, -0.0013,  0.0084])\n",
      "loss = 0.05723423883318901\n",
      "Iteration 337: b = tensor([-0.9140,  1.5318, -8.5270], grad_fn=<SubBackward0>), Loss = 0.05723423883318901\n",
      "tensor([ 0.0006, -0.0013,  0.0084])\n",
      "loss = 0.05716248229146004\n",
      "Iteration 338: b = tensor([-0.9146,  1.5331, -8.5353], grad_fn=<SubBackward0>), Loss = 0.05716248229146004\n",
      "tensor([ 0.0006, -0.0013,  0.0083])\n",
      "loss = 0.057091034948825836\n",
      "Iteration 339: b = tensor([-0.9152,  1.5344, -8.5436], grad_fn=<SubBackward0>), Loss = 0.057091034948825836\n",
      "tensor([ 0.0006, -0.0013,  0.0083])\n",
      "loss = 0.05701989307999611\n",
      "Iteration 340: b = tensor([-0.9158,  1.5357, -8.5519], grad_fn=<SubBackward0>), Loss = 0.05701989307999611\n",
      "tensor([ 0.0006, -0.0013,  0.0083])\n",
      "loss = 0.05694907531142235\n",
      "Iteration 341: b = tensor([-0.9164,  1.5370, -8.5602], grad_fn=<SubBackward0>), Loss = 0.05694907531142235\n",
      "tensor([ 0.0006, -0.0013,  0.0083])\n",
      "loss = 0.056878555566072464\n",
      "Iteration 342: b = tensor([-0.9170,  1.5383, -8.5685], grad_fn=<SubBackward0>), Loss = 0.056878555566072464\n",
      "tensor([ 0.0006, -0.0013,  0.0083])\n",
      "loss = 0.05680833384394646\n",
      "Iteration 343: b = tensor([-0.9176,  1.5395, -8.5767], grad_fn=<SubBackward0>), Loss = 0.05680833384394646\n",
      "tensor([ 0.0006, -0.0013,  0.0082])\n",
      "loss = 0.056738436222076416\n",
      "Iteration 344: b = tensor([-0.9182,  1.5408, -8.5850], grad_fn=<SubBackward0>), Loss = 0.056738436222076416\n",
      "tensor([ 0.0006, -0.0013,  0.0082])\n",
      "loss = 0.05666882172226906\n",
      "Iteration 345: b = tensor([-0.9187,  1.5421, -8.5932], grad_fn=<SubBackward0>), Loss = 0.05666882172226906\n",
      "tensor([ 0.0006, -0.0013,  0.0082])\n",
      "loss = 0.05659951642155647\n",
      "Iteration 346: b = tensor([-0.9193,  1.5433, -8.6014], grad_fn=<SubBackward0>), Loss = 0.05659951642155647\n",
      "tensor([ 0.0006, -0.0013,  0.0082])\n",
      "loss = 0.05653049051761627\n",
      "Iteration 347: b = tensor([-0.9199,  1.5446, -8.6095], grad_fn=<SubBackward0>), Loss = 0.05653049051761627\n",
      "tensor([ 0.0006, -0.0013,  0.0082])\n",
      "loss = 0.05646178126335144\n",
      "Iteration 348: b = tensor([-0.9205,  1.5459, -8.6177], grad_fn=<SubBackward0>), Loss = 0.05646178126335144\n",
      "tensor([ 0.0006, -0.0013,  0.0082])\n",
      "loss = 0.05639335513114929\n",
      "Iteration 349: b = tensor([-0.9210,  1.5471, -8.6258], grad_fn=<SubBackward0>), Loss = 0.05639335513114929\n",
      "tensor([ 0.0006, -0.0013,  0.0081])\n",
      "loss = 0.056325215846300125\n",
      "Iteration 350: b = tensor([-0.9216,  1.5484, -8.6340], grad_fn=<SubBackward0>), Loss = 0.056325215846300125\n",
      "tensor([ 0.0006, -0.0012,  0.0081])\n",
      "loss = 0.05625736340880394\n",
      "Iteration 351: b = tensor([-0.9222,  1.5496, -8.6421], grad_fn=<SubBackward0>), Loss = 0.05625736340880394\n",
      "tensor([ 0.0006, -0.0012,  0.0081])\n",
      "loss = 0.056189797818660736\n",
      "Iteration 352: b = tensor([-0.9227,  1.5509, -8.6502], grad_fn=<SubBackward0>), Loss = 0.056189797818660736\n",
      "tensor([ 0.0006, -0.0012,  0.0081])\n",
      "loss = 0.05612252280116081\n",
      "Iteration 353: b = tensor([-0.9233,  1.5521, -8.6582], grad_fn=<SubBackward0>), Loss = 0.05612252280116081\n",
      "tensor([ 0.0006, -0.0012,  0.0081])\n",
      "loss = 0.05605552718043327\n",
      "Iteration 354: b = tensor([-0.9239,  1.5533, -8.6663], grad_fn=<SubBackward0>), Loss = 0.05605552718043327\n",
      "tensor([ 0.0006, -0.0012,  0.0081])\n",
      "loss = 0.05598880723118782\n",
      "Iteration 355: b = tensor([-0.9244,  1.5546, -8.6743], grad_fn=<SubBackward0>), Loss = 0.05598880723118782\n",
      "tensor([ 0.0006, -0.0012,  0.0080])\n",
      "loss = 0.055922362953424454\n",
      "Iteration 356: b = tensor([-0.9250,  1.5558, -8.6824], grad_fn=<SubBackward0>), Loss = 0.055922362953424454\n",
      "tensor([ 0.0006, -0.0012,  0.0080])\n",
      "loss = 0.05585622042417526\n",
      "Iteration 357: b = tensor([-0.9255,  1.5570, -8.6904], grad_fn=<SubBackward0>), Loss = 0.05585622042417526\n",
      "tensor([ 0.0006, -0.0012,  0.0080])\n",
      "loss = 0.05579031631350517\n",
      "Iteration 358: b = tensor([-0.9261,  1.5582, -8.6984], grad_fn=<SubBackward0>), Loss = 0.05579031631350517\n",
      "tensor([ 0.0006, -0.0012,  0.0080])\n",
      "loss = 0.05572470277547836\n",
      "Iteration 359: b = tensor([-0.9266,  1.5595, -8.7064], grad_fn=<SubBackward0>), Loss = 0.05572470277547836\n",
      "tensor([ 0.0006, -0.0012,  0.0080])\n",
      "loss = 0.055659350007772446\n",
      "Iteration 360: b = tensor([-0.9272,  1.5607, -8.7143], grad_fn=<SubBackward0>), Loss = 0.055659350007772446\n",
      "tensor([ 0.0006, -0.0012,  0.0080])\n",
      "loss = 0.05559426546096802\n",
      "Iteration 361: b = tensor([-0.9278,  1.5619, -8.7223], grad_fn=<SubBackward0>), Loss = 0.05559426546096802\n",
      "tensor([ 0.0006, -0.0012,  0.0079])\n",
      "loss = 0.055529456585645676\n",
      "Iteration 362: b = tensor([-0.9283,  1.5631, -8.7302], grad_fn=<SubBackward0>), Loss = 0.055529456585645676\n",
      "tensor([ 0.0005, -0.0012,  0.0079])\n",
      "loss = 0.055464908480644226\n",
      "Iteration 363: b = tensor([-0.9288,  1.5643, -8.7381], grad_fn=<SubBackward0>), Loss = 0.055464908480644226\n",
      "tensor([ 0.0005, -0.0012,  0.0079])\n",
      "loss = 0.05540062487125397\n",
      "Iteration 364: b = tensor([-0.9294,  1.5655, -8.7460], grad_fn=<SubBackward0>), Loss = 0.05540062487125397\n",
      "tensor([ 0.0005, -0.0012,  0.0079])\n",
      "loss = 0.0553365983068943\n",
      "Iteration 365: b = tensor([-0.9299,  1.5667, -8.7539], grad_fn=<SubBackward0>), Loss = 0.0553365983068943\n",
      "tensor([ 0.0005, -0.0012,  0.0079])\n",
      "loss = 0.05527283251285553\n",
      "Iteration 366: b = tensor([-0.9305,  1.5679, -8.7617], grad_fn=<SubBackward0>), Loss = 0.05527283251285553\n",
      "tensor([ 0.0005, -0.0012,  0.0079])\n",
      "loss = 0.05520932376384735\n",
      "Iteration 367: b = tensor([-0.9310,  1.5691, -8.7696], grad_fn=<SubBackward0>), Loss = 0.05520932376384735\n",
      "tensor([ 0.0005, -0.0012,  0.0078])\n",
      "loss = 0.05514606460928917\n",
      "Iteration 368: b = tensor([-0.9316,  1.5703, -8.7774], grad_fn=<SubBackward0>), Loss = 0.05514606460928917\n",
      "tensor([ 0.0005, -0.0012,  0.0078])\n",
      "loss = 0.055083055049180984\n",
      "Iteration 369: b = tensor([-0.9321,  1.5715, -8.7852], grad_fn=<SubBackward0>), Loss = 0.055083055049180984\n",
      "tensor([ 0.0005, -0.0012,  0.0078])\n",
      "loss = 0.05502031370997429\n",
      "Iteration 370: b = tensor([-0.9326,  1.5726, -8.7930], grad_fn=<SubBackward0>), Loss = 0.05502031370997429\n",
      "tensor([ 0.0005, -0.0012,  0.0078])\n",
      "loss = 0.054957810789346695\n",
      "Iteration 371: b = tensor([-0.9332,  1.5738, -8.8008], grad_fn=<SubBackward0>), Loss = 0.054957810789346695\n",
      "tensor([ 0.0005, -0.0012,  0.0078])\n",
      "loss = 0.054895564913749695\n",
      "Iteration 372: b = tensor([-0.9337,  1.5750, -8.8086], grad_fn=<SubBackward0>), Loss = 0.054895564913749695\n",
      "tensor([ 0.0005, -0.0012,  0.0078])\n",
      "loss = 0.05483357235789299\n",
      "Iteration 373: b = tensor([-0.9342,  1.5762, -8.8164], grad_fn=<SubBackward0>), Loss = 0.05483357235789299\n",
      "tensor([ 0.0005, -0.0012,  0.0078])\n",
      "loss = 0.05477181449532509\n",
      "Iteration 374: b = tensor([-0.9348,  1.5773, -8.8241], grad_fn=<SubBackward0>), Loss = 0.05477181449532509\n",
      "tensor([ 0.0005, -0.0012,  0.0077])\n",
      "loss = 0.05471029877662659\n",
      "Iteration 375: b = tensor([-0.9353,  1.5785, -8.8318], grad_fn=<SubBackward0>), Loss = 0.05471029877662659\n",
      "tensor([ 0.0005, -0.0012,  0.0077])\n",
      "loss = 0.05464903637766838\n",
      "Iteration 376: b = tensor([-0.9358,  1.5797, -8.8395], grad_fn=<SubBackward0>), Loss = 0.05464903637766838\n",
      "tensor([ 0.0005, -0.0012,  0.0077])\n",
      "loss = 0.05458799749612808\n",
      "Iteration 377: b = tensor([-0.9363,  1.5808, -8.8472], grad_fn=<SubBackward0>), Loss = 0.05458799749612808\n",
      "tensor([ 0.0005, -0.0012,  0.0077])\n",
      "loss = 0.05452721193432808\n",
      "Iteration 378: b = tensor([-0.9369,  1.5820, -8.8549], grad_fn=<SubBackward0>), Loss = 0.05452721193432808\n",
      "tensor([ 0.0005, -0.0012,  0.0077])\n",
      "loss = 0.05446665734052658\n",
      "Iteration 379: b = tensor([-0.9374,  1.5831, -8.8626], grad_fn=<SubBackward0>), Loss = 0.05446665734052658\n",
      "tensor([ 0.0005, -0.0012,  0.0077])\n",
      "loss = 0.05440632998943329\n",
      "Iteration 380: b = tensor([-0.9379,  1.5843, -8.8702], grad_fn=<SubBackward0>), Loss = 0.05440632998943329\n",
      "tensor([ 0.0005, -0.0012,  0.0077])\n",
      "loss = 0.05434625595808029\n",
      "Iteration 381: b = tensor([-0.9384,  1.5854, -8.8779], grad_fn=<SubBackward0>), Loss = 0.05434625595808029\n",
      "tensor([ 0.0005, -0.0011,  0.0076])\n",
      "loss = 0.054286401718854904\n",
      "Iteration 382: b = tensor([-0.9389,  1.5866, -8.8855], grad_fn=<SubBackward0>), Loss = 0.054286401718854904\n",
      "tensor([ 0.0005, -0.0011,  0.0076])\n",
      "loss = 0.05422677844762802\n",
      "Iteration 383: b = tensor([-0.9395,  1.5877, -8.8931], grad_fn=<SubBackward0>), Loss = 0.05422677844762802\n",
      "tensor([ 0.0005, -0.0011,  0.0076])\n",
      "loss = 0.054167382419109344\n",
      "Iteration 384: b = tensor([-0.9400,  1.5888, -8.9007], grad_fn=<SubBackward0>), Loss = 0.054167382419109344\n",
      "tensor([ 0.0005, -0.0011,  0.0076])\n",
      "loss = 0.05410822480916977\n",
      "Iteration 385: b = tensor([-0.9405,  1.5900, -8.9083], grad_fn=<SubBackward0>), Loss = 0.05410822480916977\n",
      "tensor([ 0.0005, -0.0011,  0.0076])\n",
      "loss = 0.0540492907166481\n",
      "Iteration 386: b = tensor([-0.9410,  1.5911, -8.9158], grad_fn=<SubBackward0>), Loss = 0.0540492907166481\n",
      "tensor([ 0.0005, -0.0011,  0.0076])\n",
      "loss = 0.053990576416254044\n",
      "Iteration 387: b = tensor([-0.9415,  1.5922, -8.9234], grad_fn=<SubBackward0>), Loss = 0.053990576416254044\n",
      "tensor([ 0.0005, -0.0011,  0.0076])\n",
      "loss = 0.053932081907987595\n",
      "Iteration 388: b = tensor([-0.9420,  1.5934, -8.9309], grad_fn=<SubBackward0>), Loss = 0.053932081907987595\n",
      "tensor([ 0.0005, -0.0011,  0.0075])\n",
      "loss = 0.053873829543590546\n",
      "Iteration 389: b = tensor([-0.9425,  1.5945, -8.9384], grad_fn=<SubBackward0>), Loss = 0.053873829543590546\n",
      "tensor([ 0.0005, -0.0011,  0.0075])\n",
      "loss = 0.053815774619579315\n",
      "Iteration 390: b = tensor([-0.9430,  1.5956, -8.9460], grad_fn=<SubBackward0>), Loss = 0.053815774619579315\n",
      "tensor([ 0.0005, -0.0011,  0.0075])\n",
      "loss = 0.05375795066356659\n",
      "Iteration 391: b = tensor([-0.9435,  1.5967, -8.9534], grad_fn=<SubBackward0>), Loss = 0.05375795066356659\n",
      "tensor([ 0.0005, -0.0011,  0.0075])\n",
      "loss = 0.05370034649968147\n",
      "Iteration 392: b = tensor([-0.9440,  1.5978, -8.9609], grad_fn=<SubBackward0>), Loss = 0.05370034649968147\n",
      "tensor([ 0.0005, -0.0011,  0.0075])\n",
      "loss = 0.053642939776182175\n",
      "Iteration 393: b = tensor([-0.9445,  1.5990, -8.9684], grad_fn=<SubBackward0>), Loss = 0.053642939776182175\n",
      "tensor([ 0.0005, -0.0011,  0.0075])\n",
      "loss = 0.053585782647132874\n",
      "Iteration 394: b = tensor([-0.9450,  1.6001, -8.9758], grad_fn=<SubBackward0>), Loss = 0.053585782647132874\n",
      "tensor([ 0.0005, -0.0011,  0.0075])\n",
      "loss = 0.0535288043320179\n",
      "Iteration 395: b = tensor([-0.9455,  1.6012, -8.9833], grad_fn=<SubBackward0>), Loss = 0.0535288043320179\n",
      "tensor([ 0.0005, -0.0011,  0.0074])\n",
      "loss = 0.053472068160772324\n",
      "Iteration 396: b = tensor([-0.9460,  1.6023, -8.9907], grad_fn=<SubBackward0>), Loss = 0.053472068160772324\n",
      "tensor([ 0.0005, -0.0011,  0.0074])\n",
      "loss = 0.05341551825404167\n",
      "Iteration 397: b = tensor([-0.9465,  1.6034, -8.9981], grad_fn=<SubBackward0>), Loss = 0.05341551825404167\n",
      "tensor([ 0.0005, -0.0011,  0.0074])\n",
      "loss = 0.05335920676589012\n",
      "Iteration 398: b = tensor([-0.9470,  1.6045, -9.0055], grad_fn=<SubBackward0>), Loss = 0.05335920676589012\n",
      "tensor([ 0.0005, -0.0011,  0.0074])\n",
      "loss = 0.0533030740916729\n",
      "Iteration 399: b = tensor([-0.9475,  1.6056, -9.0129], grad_fn=<SubBackward0>), Loss = 0.0533030740916729\n",
      "tensor([ 0.0005, -0.0011,  0.0074])\n",
      "loss = 0.053247153759002686\n",
      "Iteration 400: b = tensor([-0.9480,  1.6066, -9.0203], grad_fn=<SubBackward0>), Loss = 0.053247153759002686\n",
      "tensor([ 0.0005, -0.0011,  0.0074])\n",
      "loss = 0.05319145321846008\n",
      "Iteration 401: b = tensor([-0.9485,  1.6077, -9.0276], grad_fn=<SubBackward0>), Loss = 0.05319145321846008\n",
      "tensor([ 0.0005, -0.0011,  0.0074])\n",
      "loss = 0.0531359426677227\n",
      "Iteration 402: b = tensor([-0.9490,  1.6088, -9.0350], grad_fn=<SubBackward0>), Loss = 0.0531359426677227\n",
      "tensor([ 0.0005, -0.0011,  0.0073])\n",
      "loss = 0.053080637007951736\n",
      "Iteration 403: b = tensor([-0.9495,  1.6099, -9.0423], grad_fn=<SubBackward0>), Loss = 0.053080637007951736\n",
      "tensor([ 0.0005, -0.0011,  0.0073])\n",
      "loss = 0.05302554368972778\n",
      "Iteration 404: b = tensor([-0.9500,  1.6110, -9.0496], grad_fn=<SubBackward0>), Loss = 0.05302554368972778\n",
      "tensor([ 0.0005, -0.0011,  0.0073])\n",
      "loss = 0.05297064408659935\n",
      "Iteration 405: b = tensor([-0.9504,  1.6121, -9.0569], grad_fn=<SubBackward0>), Loss = 0.05297064408659935\n",
      "tensor([ 0.0005, -0.0011,  0.0073])\n",
      "loss = 0.05291594937443733\n",
      "Iteration 406: b = tensor([-0.9509,  1.6131, -9.0642], grad_fn=<SubBackward0>), Loss = 0.05291594937443733\n",
      "tensor([ 0.0005, -0.0011,  0.0073])\n",
      "loss = 0.05286143720149994\n",
      "Iteration 407: b = tensor([-0.9514,  1.6142, -9.0715], grad_fn=<SubBackward0>), Loss = 0.05286143720149994\n",
      "tensor([ 0.0005, -0.0011,  0.0073])\n",
      "loss = 0.05280713364481926\n",
      "Iteration 408: b = tensor([-0.9519,  1.6153, -9.0788], grad_fn=<SubBackward0>), Loss = 0.05280713364481926\n",
      "tensor([ 0.0005, -0.0011,  0.0073])\n",
      "loss = 0.0527530312538147\n",
      "Iteration 409: b = tensor([-0.9524,  1.6163, -9.0860], grad_fn=<SubBackward0>), Loss = 0.0527530312538147\n",
      "tensor([ 0.0005, -0.0011,  0.0073])\n",
      "loss = 0.05269911140203476\n",
      "Iteration 410: b = tensor([-0.9528,  1.6174, -9.0933], grad_fn=<SubBackward0>), Loss = 0.05269911140203476\n",
      "tensor([ 0.0005, -0.0011,  0.0072])\n",
      "loss = 0.05264539271593094\n",
      "Iteration 411: b = tensor([-0.9533,  1.6185, -9.1005], grad_fn=<SubBackward0>), Loss = 0.05264539271593094\n",
      "tensor([ 0.0005, -0.0011,  0.0072])\n",
      "loss = 0.05259188264608383\n",
      "Iteration 412: b = tensor([-0.9538,  1.6195, -9.1077], grad_fn=<SubBackward0>), Loss = 0.05259188264608383\n",
      "tensor([ 0.0005, -0.0011,  0.0072])\n",
      "loss = 0.05253853648900986\n",
      "Iteration 413: b = tensor([-0.9543,  1.6206, -9.1149], grad_fn=<SubBackward0>), Loss = 0.05253853648900986\n",
      "tensor([ 0.0005, -0.0011,  0.0072])\n",
      "loss = 0.0524853840470314\n",
      "Iteration 414: b = tensor([-0.9547,  1.6216, -9.1221], grad_fn=<SubBackward0>), Loss = 0.0524853840470314\n",
      "tensor([ 0.0005, -0.0011,  0.0072])\n",
      "loss = 0.052432432770729065\n",
      "Iteration 415: b = tensor([-0.9552,  1.6227, -9.1293], grad_fn=<SubBackward0>), Loss = 0.052432432770729065\n",
      "tensor([ 0.0005, -0.0010,  0.0072])\n",
      "loss = 0.05237966030836105\n",
      "Iteration 416: b = tensor([-0.9557,  1.6237, -9.1364], grad_fn=<SubBackward0>), Loss = 0.05237966030836105\n",
      "tensor([ 0.0005, -0.0010,  0.0072])\n",
      "loss = 0.052327074110507965\n",
      "Iteration 417: b = tensor([-0.9561,  1.6248, -9.1436], grad_fn=<SubBackward0>), Loss = 0.052327074110507965\n",
      "tensor([ 0.0005, -0.0010,  0.0072])\n",
      "loss = 0.052274685353040695\n",
      "Iteration 418: b = tensor([-0.9566,  1.6258, -9.1507], grad_fn=<SubBackward0>), Loss = 0.052274685353040695\n",
      "tensor([ 0.0005, -0.0010,  0.0071])\n",
      "loss = 0.05222247168421745\n",
      "Iteration 419: b = tensor([-0.9571,  1.6268, -9.1578], grad_fn=<SubBackward0>), Loss = 0.05222247168421745\n",
      "tensor([ 0.0005, -0.0010,  0.0071])\n",
      "loss = 0.05217043682932854\n",
      "Iteration 420: b = tensor([-0.9575,  1.6279, -9.1650], grad_fn=<SubBackward0>), Loss = 0.05217043682932854\n",
      "tensor([ 0.0005, -0.0010,  0.0071])\n",
      "loss = 0.05211859941482544\n",
      "Iteration 421: b = tensor([-0.9580,  1.6289, -9.1721], grad_fn=<SubBackward0>), Loss = 0.05211859941482544\n",
      "tensor([ 0.0005, -0.0010,  0.0071])\n",
      "loss = 0.05206693336367607\n",
      "Iteration 422: b = tensor([-0.9585,  1.6299, -9.1791], grad_fn=<SubBackward0>), Loss = 0.05206693336367607\n",
      "tensor([ 0.0005, -0.0010,  0.0071])\n",
      "loss = 0.05201544240117073\n",
      "Iteration 423: b = tensor([-0.9589,  1.6310, -9.1862], grad_fn=<SubBackward0>), Loss = 0.05201544240117073\n",
      "tensor([ 0.0005, -0.0010,  0.0071])\n",
      "loss = 0.051964133977890015\n",
      "Iteration 424: b = tensor([-0.9594,  1.6320, -9.1933], grad_fn=<SubBackward0>), Loss = 0.051964133977890015\n",
      "tensor([ 0.0005, -0.0010,  0.0071])\n",
      "loss = 0.051913000643253326\n",
      "Iteration 425: b = tensor([-0.9598,  1.6330, -9.2003], grad_fn=<SubBackward0>), Loss = 0.051913000643253326\n",
      "tensor([ 0.0005, -0.0010,  0.0071])\n",
      "loss = 0.05186203867197037\n",
      "Iteration 426: b = tensor([-0.9603,  1.6340, -9.2074], grad_fn=<SubBackward0>), Loss = 0.05186203867197037\n",
      "tensor([ 0.0005, -0.0010,  0.0070])\n",
      "loss = 0.05181126669049263\n",
      "Iteration 427: b = tensor([-0.9607,  1.6351, -9.2144], grad_fn=<SubBackward0>), Loss = 0.05181126669049263\n",
      "tensor([ 0.0005, -0.0010,  0.0070])\n",
      "loss = 0.051760654896497726\n",
      "Iteration 428: b = tensor([-0.9612,  1.6361, -9.2214], grad_fn=<SubBackward0>), Loss = 0.051760654896497726\n",
      "tensor([ 0.0005, -0.0010,  0.0070])\n",
      "loss = 0.051710229367017746\n",
      "Iteration 429: b = tensor([-0.9616,  1.6371, -9.2284], grad_fn=<SubBackward0>), Loss = 0.051710229367017746\n",
      "tensor([ 0.0005, -0.0010,  0.0070])\n",
      "loss = 0.051659975200891495\n",
      "Iteration 430: b = tensor([-0.9621,  1.6381, -9.2354], grad_fn=<SubBackward0>), Loss = 0.051659975200891495\n",
      "tensor([ 0.0005, -0.0010,  0.0070])\n",
      "loss = 0.051609884947538376\n",
      "Iteration 431: b = tensor([-0.9625,  1.6391, -9.2424], grad_fn=<SubBackward0>), Loss = 0.051609884947538376\n",
      "tensor([ 0.0004, -0.0010,  0.0070])\n",
      "loss = 0.05155997350811958\n",
      "Iteration 432: b = tensor([-0.9630,  1.6401, -9.2494], grad_fn=<SubBackward0>), Loss = 0.05155997350811958\n",
      "tensor([ 0.0004, -0.0010,  0.0070])\n",
      "loss = 0.05151023343205452\n",
      "Iteration 433: b = tensor([-0.9634,  1.6411, -9.2563], grad_fn=<SubBackward0>), Loss = 0.05151023343205452\n",
      "tensor([ 0.0004, -0.0010,  0.0070])\n",
      "loss = 0.051460642367601395\n",
      "Iteration 434: b = tensor([-0.9639,  1.6421, -9.2633], grad_fn=<SubBackward0>), Loss = 0.051460642367601395\n",
      "tensor([ 0.0004, -0.0010,  0.0069])\n",
      "loss = 0.05141123756766319\n",
      "Iteration 435: b = tensor([-0.9643,  1.6431, -9.2702], grad_fn=<SubBackward0>), Loss = 0.05141123756766319\n",
      "tensor([ 0.0004, -0.0010,  0.0069])\n",
      "loss = 0.05136199668049812\n",
      "Iteration 436: b = tensor([-0.9648,  1.6441, -9.2771], grad_fn=<SubBackward0>), Loss = 0.05136199668049812\n",
      "tensor([ 0.0004, -0.0010,  0.0069])\n",
      "loss = 0.05131290853023529\n",
      "Iteration 437: b = tensor([-0.9652,  1.6451, -9.2840], grad_fn=<SubBackward0>), Loss = 0.05131290853023529\n",
      "tensor([ 0.0004, -0.0010,  0.0069])\n",
      "loss = 0.05126399174332619\n",
      "Iteration 438: b = tensor([-0.9657,  1.6461, -9.2909], grad_fn=<SubBackward0>), Loss = 0.05126399174332619\n",
      "tensor([ 0.0004, -0.0010,  0.0069])\n",
      "loss = 0.051215242594480515\n",
      "Iteration 439: b = tensor([-0.9661,  1.6471, -9.2978], grad_fn=<SubBackward0>), Loss = 0.051215242594480515\n",
      "tensor([ 0.0004, -0.0010,  0.0069])\n",
      "loss = 0.051166657358407974\n",
      "Iteration 440: b = tensor([-0.9665,  1.6481, -9.3047], grad_fn=<SubBackward0>), Loss = 0.051166657358407974\n",
      "tensor([ 0.0004, -0.0010,  0.0069])\n",
      "loss = 0.05111822858452797\n",
      "Iteration 441: b = tensor([-0.9670,  1.6490, -9.3116], grad_fn=<SubBackward0>), Loss = 0.05111822858452797\n",
      "tensor([ 0.0004, -0.0010,  0.0069])\n",
      "loss = 0.05106997862458229\n",
      "Iteration 442: b = tensor([-0.9674,  1.6500, -9.3184], grad_fn=<SubBackward0>), Loss = 0.05106997862458229\n",
      "tensor([ 0.0004, -0.0010,  0.0069])\n",
      "loss = 0.051021866500377655\n",
      "Iteration 443: b = tensor([-0.9678,  1.6510, -9.3253], grad_fn=<SubBackward0>), Loss = 0.051021866500377655\n",
      "tensor([ 0.0004, -0.0010,  0.0068])\n",
      "loss = 0.05097392946481705\n",
      "Iteration 444: b = tensor([-0.9683,  1.6520, -9.3321], grad_fn=<SubBackward0>), Loss = 0.05097392946481705\n",
      "tensor([ 0.0004, -0.0010,  0.0068])\n",
      "loss = 0.05092614144086838\n",
      "Iteration 445: b = tensor([-0.9687,  1.6529, -9.3389], grad_fn=<SubBackward0>), Loss = 0.05092614144086838\n",
      "tensor([ 0.0004, -0.0010,  0.0068])\n",
      "loss = 0.05087851360440254\n",
      "Iteration 446: b = tensor([-0.9691,  1.6539, -9.3457], grad_fn=<SubBackward0>), Loss = 0.05087851360440254\n",
      "tensor([ 0.0004, -0.0010,  0.0068])\n",
      "loss = 0.05083104968070984\n",
      "Iteration 447: b = tensor([-0.9696,  1.6549, -9.3525], grad_fn=<SubBackward0>), Loss = 0.05083104968070984\n",
      "tensor([ 0.0004, -0.0010,  0.0068])\n",
      "loss = 0.050783734768629074\n",
      "Iteration 448: b = tensor([-0.9700,  1.6559, -9.3593], grad_fn=<SubBackward0>), Loss = 0.050783734768629074\n",
      "tensor([ 0.0004, -0.0010,  0.0068])\n",
      "loss = 0.050736572593450546\n",
      "Iteration 449: b = tensor([-0.9704,  1.6568, -9.3661], grad_fn=<SubBackward0>), Loss = 0.050736572593450546\n",
      "tensor([ 0.0004, -0.0010,  0.0068])\n",
      "loss = 0.05068955942988396\n",
      "Iteration 450: b = tensor([-0.9709,  1.6578, -9.3729], grad_fn=<SubBackward0>), Loss = 0.05068955942988396\n",
      "tensor([ 0.0004, -0.0010,  0.0068])\n",
      "loss = 0.0506427101790905\n",
      "Iteration 451: b = tensor([-0.9713,  1.6587, -9.3796], grad_fn=<SubBackward0>), Loss = 0.0506427101790905\n",
      "tensor([ 0.0004, -0.0010,  0.0068])\n",
      "loss = 0.05059600993990898\n",
      "Iteration 452: b = tensor([-0.9717,  1.6597, -9.3864], grad_fn=<SubBackward0>), Loss = 0.05059600993990898\n",
      "tensor([ 0.0004, -0.0010,  0.0067])\n",
      "loss = 0.0505494624376297\n",
      "Iteration 453: b = tensor([-0.9721,  1.6606, -9.3931], grad_fn=<SubBackward0>), Loss = 0.0505494624376297\n",
      "tensor([ 0.0004, -0.0010,  0.0067])\n",
      "loss = 0.05050307512283325\n",
      "Iteration 454: b = tensor([-0.9725,  1.6616, -9.3998], grad_fn=<SubBackward0>), Loss = 0.05050307512283325\n",
      "tensor([ 0.0004, -0.0010,  0.0067])\n",
      "loss = 0.05045682191848755\n",
      "Iteration 455: b = tensor([-0.9730,  1.6625, -9.4065], grad_fn=<SubBackward0>), Loss = 0.05045682191848755\n",
      "tensor([ 0.0004, -0.0009,  0.0067])\n",
      "loss = 0.05041072145104408\n",
      "Iteration 456: b = tensor([-0.9734,  1.6635, -9.4132], grad_fn=<SubBackward0>), Loss = 0.05041072145104408\n",
      "tensor([ 0.0004, -0.0009,  0.0067])\n",
      "loss = 0.050364769995212555\n",
      "Iteration 457: b = tensor([-0.9738,  1.6644, -9.4199], grad_fn=<SubBackward0>), Loss = 0.050364769995212555\n",
      "tensor([ 0.0004, -0.0009,  0.0067])\n",
      "loss = 0.050318971276283264\n",
      "Iteration 458: b = tensor([-0.9742,  1.6654, -9.4266], grad_fn=<SubBackward0>), Loss = 0.050318971276283264\n",
      "tensor([ 0.0004, -0.0009,  0.0067])\n",
      "loss = 0.050273310393095016\n",
      "Iteration 459: b = tensor([-0.9746,  1.6663, -9.4333], grad_fn=<SubBackward0>), Loss = 0.050273310393095016\n",
      "tensor([ 0.0004, -0.0009,  0.0067])\n",
      "loss = 0.050227805972099304\n",
      "Iteration 460: b = tensor([-0.9750,  1.6673, -9.4400], grad_fn=<SubBackward0>), Loss = 0.050227805972099304\n",
      "tensor([ 0.0004, -0.0009,  0.0067])\n",
      "loss = 0.05018242448568344\n",
      "Iteration 461: b = tensor([-0.9755,  1.6682, -9.4466], grad_fn=<SubBackward0>), Loss = 0.05018242448568344\n",
      "tensor([ 0.0004, -0.0009,  0.0066])\n",
      "loss = 0.05013721063733101\n",
      "Iteration 462: b = tensor([-0.9759,  1.6691, -9.4532], grad_fn=<SubBackward0>), Loss = 0.05013721063733101\n",
      "tensor([ 0.0004, -0.0009,  0.0066])\n",
      "loss = 0.05009213089942932\n",
      "Iteration 463: b = tensor([-0.9763,  1.6701, -9.4599], grad_fn=<SubBackward0>), Loss = 0.05009213089942932\n",
      "tensor([ 0.0004, -0.0009,  0.0066])\n",
      "loss = 0.050047196447849274\n",
      "Iteration 464: b = tensor([-0.9767,  1.6710, -9.4665], grad_fn=<SubBackward0>), Loss = 0.050047196447849274\n",
      "tensor([ 0.0004, -0.0009,  0.0066])\n",
      "loss = 0.05000239983201027\n",
      "Iteration 465: b = tensor([-0.9771,  1.6719, -9.4731], grad_fn=<SubBackward0>), Loss = 0.05000239983201027\n",
      "tensor([ 0.0004, -0.0009,  0.0066])\n",
      "loss = 0.0499577522277832\n",
      "Iteration 466: b = tensor([-0.9775,  1.6728, -9.4797], grad_fn=<SubBackward0>), Loss = 0.0499577522277832\n",
      "tensor([ 0.0004, -0.0009,  0.0066])\n",
      "loss = 0.04991324245929718\n",
      "Iteration 467: b = tensor([-0.9779,  1.6738, -9.4863], grad_fn=<SubBackward0>), Loss = 0.04991324245929718\n",
      "tensor([ 0.0004, -0.0009,  0.0066])\n",
      "loss = 0.0498688779771328\n",
      "Iteration 468: b = tensor([-0.9783,  1.6747, -9.4929], grad_fn=<SubBackward0>), Loss = 0.0498688779771328\n",
      "tensor([ 0.0004, -0.0009,  0.0066])\n",
      "loss = 0.04982462897896767\n",
      "Iteration 469: b = tensor([-0.9787,  1.6756, -9.4994], grad_fn=<SubBackward0>), Loss = 0.04982462897896767\n",
      "tensor([ 0.0004, -0.0009,  0.0066])\n",
      "loss = 0.04978054016828537\n",
      "Iteration 470: b = tensor([-0.9791,  1.6765, -9.5060], grad_fn=<SubBackward0>), Loss = 0.04978054016828537\n",
      "tensor([ 0.0004, -0.0009,  0.0066])\n",
      "loss = 0.04973658174276352\n",
      "Iteration 471: b = tensor([-0.9795,  1.6774, -9.5125], grad_fn=<SubBackward0>), Loss = 0.04973658174276352\n",
      "tensor([ 0.0004, -0.0009,  0.0065])\n",
      "loss = 0.04969276115298271\n",
      "Iteration 472: b = tensor([-0.9799,  1.6783, -9.5191], grad_fn=<SubBackward0>), Loss = 0.04969276115298271\n",
      "tensor([ 0.0004, -0.0009,  0.0065])\n",
      "loss = 0.04964907094836235\n",
      "Iteration 473: b = tensor([-0.9803,  1.6793, -9.5256], grad_fn=<SubBackward0>), Loss = 0.04964907094836235\n",
      "tensor([ 0.0004, -0.0009,  0.0065])\n",
      "loss = 0.04960551857948303\n",
      "Iteration 474: b = tensor([-0.9807,  1.6802, -9.5321], grad_fn=<SubBackward0>), Loss = 0.04960551857948303\n",
      "tensor([ 0.0004, -0.0009,  0.0065])\n",
      "loss = 0.04956210032105446\n",
      "Iteration 475: b = tensor([-0.9811,  1.6811, -9.5386], grad_fn=<SubBackward0>), Loss = 0.04956210032105446\n",
      "tensor([ 0.0004, -0.0009,  0.0065])\n",
      "loss = 0.04951881617307663\n",
      "Iteration 476: b = tensor([-0.9815,  1.6820, -9.5451], grad_fn=<SubBackward0>), Loss = 0.04951881617307663\n",
      "tensor([ 0.0004, -0.0009,  0.0065])\n",
      "loss = 0.04947568103671074\n",
      "Iteration 477: b = tensor([-0.9819,  1.6829, -9.5516], grad_fn=<SubBackward0>), Loss = 0.04947568103671074\n",
      "tensor([ 0.0004, -0.0009,  0.0065])\n",
      "loss = 0.0494326613843441\n",
      "Iteration 478: b = tensor([-0.9823,  1.6838, -9.5581], grad_fn=<SubBackward0>), Loss = 0.0494326613843441\n",
      "tensor([ 0.0004, -0.0009,  0.0065])\n",
      "loss = 0.04938976839184761\n",
      "Iteration 479: b = tensor([-0.9827,  1.6847, -9.5645], grad_fn=<SubBackward0>), Loss = 0.04938976839184761\n",
      "tensor([ 0.0004, -0.0009,  0.0065])\n",
      "loss = 0.04934701323509216\n",
      "Iteration 480: b = tensor([-0.9831,  1.6856, -9.5710], grad_fn=<SubBackward0>), Loss = 0.04934701323509216\n",
      "tensor([ 0.0004, -0.0009,  0.0065])\n",
      "loss = 0.04930439591407776\n",
      "Iteration 481: b = tensor([-0.9835,  1.6865, -9.5774], grad_fn=<SubBackward0>), Loss = 0.04930439591407776\n",
      "tensor([ 0.0004, -0.0009,  0.0064])\n",
      "loss = 0.049261901527643204\n",
      "Iteration 482: b = tensor([-0.9839,  1.6874, -9.5839], grad_fn=<SubBackward0>), Loss = 0.049261901527643204\n",
      "tensor([ 0.0004, -0.0009,  0.0064])\n",
      "loss = 0.049219537526369095\n",
      "Iteration 483: b = tensor([-0.9843,  1.6882, -9.5903], grad_fn=<SubBackward0>), Loss = 0.049219537526369095\n",
      "tensor([ 0.0004, -0.0009,  0.0064])\n",
      "loss = 0.049177300184965134\n",
      "Iteration 484: b = tensor([-0.9847,  1.6891, -9.5967], grad_fn=<SubBackward0>), Loss = 0.049177300184965134\n",
      "tensor([ 0.0004, -0.0009,  0.0064])\n",
      "loss = 0.04913519322872162\n",
      "Iteration 485: b = tensor([-0.9851,  1.6900, -9.6031], grad_fn=<SubBackward0>), Loss = 0.04913519322872162\n",
      "tensor([ 0.0004, -0.0009,  0.0064])\n",
      "loss = 0.049093205481767654\n",
      "Iteration 486: b = tensor([-0.9854,  1.6909, -9.6095], grad_fn=<SubBackward0>), Loss = 0.049093205481767654\n",
      "tensor([ 0.0004, -0.0009,  0.0064])\n",
      "loss = 0.049051351845264435\n",
      "Iteration 487: b = tensor([-0.9858,  1.6918, -9.6159], grad_fn=<SubBackward0>), Loss = 0.049051351845264435\n",
      "tensor([ 0.0004, -0.0009,  0.0064])\n",
      "loss = 0.049009621143341064\n",
      "Iteration 488: b = tensor([-0.9862,  1.6927, -9.6223], grad_fn=<SubBackward0>), Loss = 0.049009621143341064\n",
      "tensor([ 0.0004, -0.0009,  0.0064])\n",
      "loss = 0.04896802082657814\n",
      "Iteration 489: b = tensor([-0.9866,  1.6935, -9.6287], grad_fn=<SubBackward0>), Loss = 0.04896802082657814\n",
      "tensor([ 0.0004, -0.0009,  0.0064])\n",
      "loss = 0.04892653971910477\n",
      "Iteration 490: b = tensor([-0.9870,  1.6944, -9.6350], grad_fn=<SubBackward0>), Loss = 0.04892653971910477\n",
      "tensor([ 0.0004, -0.0009,  0.0064])\n",
      "loss = 0.048885177820920944\n",
      "Iteration 491: b = tensor([-0.9874,  1.6953, -9.6414], grad_fn=<SubBackward0>), Loss = 0.048885177820920944\n",
      "tensor([ 0.0004, -0.0009,  0.0064])\n",
      "loss = 0.04884393885731697\n",
      "Iteration 492: b = tensor([-0.9877,  1.6961, -9.6477], grad_fn=<SubBackward0>), Loss = 0.04884393885731697\n",
      "tensor([ 0.0004, -0.0009,  0.0063])\n",
      "loss = 0.048802830278873444\n",
      "Iteration 493: b = tensor([-0.9881,  1.6970, -9.6541], grad_fn=<SubBackward0>), Loss = 0.048802830278873444\n",
      "tensor([ 0.0004, -0.0009,  0.0063])\n",
      "loss = 0.04876183718442917\n",
      "Iteration 494: b = tensor([-0.9885,  1.6979, -9.6604], grad_fn=<SubBackward0>), Loss = 0.04876183718442917\n",
      "tensor([ 0.0004, -0.0009,  0.0063])\n",
      "loss = 0.04872097447514534\n",
      "Iteration 495: b = tensor([-0.9889,  1.6987, -9.6667], grad_fn=<SubBackward0>), Loss = 0.04872097447514534\n",
      "tensor([ 0.0004, -0.0009,  0.0063])\n",
      "loss = 0.04868023470044136\n",
      "Iteration 496: b = tensor([-0.9893,  1.6996, -9.6730], grad_fn=<SubBackward0>), Loss = 0.04868023470044136\n",
      "tensor([ 0.0004, -0.0009,  0.0063])\n",
      "loss = 0.04863959550857544\n",
      "Iteration 497: b = tensor([-0.9896,  1.7005, -9.6793], grad_fn=<SubBackward0>), Loss = 0.04863959550857544\n",
      "tensor([ 0.0004, -0.0009,  0.0063])\n",
      "loss = 0.04859910160303116\n",
      "Iteration 498: b = tensor([-0.9900,  1.7013, -9.6856], grad_fn=<SubBackward0>), Loss = 0.04859910160303116\n",
      "tensor([ 0.0004, -0.0009,  0.0063])\n",
      "loss = 0.04855870082974434\n",
      "Iteration 499: b = tensor([-0.9904,  1.7022, -9.6919], grad_fn=<SubBackward0>), Loss = 0.04855870082974434\n",
      "tensor([ 0.0004, -0.0009,  0.0063])\n",
      "loss = 0.048518434166908264\n",
      "Iteration 500: b = tensor([-0.9908,  1.7030, -9.6982], grad_fn=<SubBackward0>), Loss = 0.048518434166908264\n",
      "tensor([ 0.0004, -0.0009,  0.0063])\n",
      "loss = 0.048478271812200546\n",
      "Iteration 501: b = tensor([-0.9911,  1.7039, -9.7044], grad_fn=<SubBackward0>), Loss = 0.048478271812200546\n",
      "tensor([ 0.0004, -0.0009,  0.0063])\n",
      "loss = 0.04843824729323387\n",
      "Iteration 502: b = tensor([-0.9915,  1.7047, -9.7107], grad_fn=<SubBackward0>), Loss = 0.04843824729323387\n",
      "tensor([ 0.0004, -0.0009,  0.0063])\n",
      "loss = 0.048398323357105255\n",
      "Iteration 503: b = tensor([-0.9919,  1.7056, -9.7169], grad_fn=<SubBackward0>), Loss = 0.048398323357105255\n",
      "tensor([ 0.0004, -0.0008,  0.0062])\n",
      "loss = 0.04835852235555649\n",
      "Iteration 504: b = tensor([-0.9922,  1.7064, -9.7231], grad_fn=<SubBackward0>), Loss = 0.04835852235555649\n",
      "tensor([ 0.0004, -0.0008,  0.0062])\n",
      "loss = 0.048318833112716675\n",
      "Iteration 505: b = tensor([-0.9926,  1.7073, -9.7294], grad_fn=<SubBackward0>), Loss = 0.048318833112716675\n",
      "tensor([ 0.0004, -0.0008,  0.0062])\n",
      "loss = 0.04827926307916641\n",
      "Iteration 506: b = tensor([-0.9930,  1.7081, -9.7356], grad_fn=<SubBackward0>), Loss = 0.04827926307916641\n",
      "tensor([ 0.0004, -0.0008,  0.0062])\n",
      "loss = 0.0482398085296154\n",
      "Iteration 507: b = tensor([-0.9933,  1.7090, -9.7418], grad_fn=<SubBackward0>), Loss = 0.0482398085296154\n",
      "tensor([ 0.0004, -0.0008,  0.0062])\n",
      "loss = 0.048200469464063644\n",
      "Iteration 508: b = tensor([-0.9937,  1.7098, -9.7480], grad_fn=<SubBackward0>), Loss = 0.048200469464063644\n",
      "tensor([ 0.0004, -0.0008,  0.0062])\n",
      "loss = 0.04816122353076935\n",
      "Iteration 509: b = tensor([-0.9941,  1.7106, -9.7542], grad_fn=<SubBackward0>), Loss = 0.04816122353076935\n",
      "tensor([ 0.0004, -0.0008,  0.0062])\n",
      "loss = 0.0481221042573452\n",
      "Iteration 510: b = tensor([-0.9944,  1.7115, -9.7604], grad_fn=<SubBackward0>), Loss = 0.0481221042573452\n",
      "tensor([ 0.0004, -0.0008,  0.0062])\n",
      "loss = 0.04808308556675911\n",
      "Iteration 511: b = tensor([-0.9948,  1.7123, -9.7665], grad_fn=<SubBackward0>), Loss = 0.04808308556675911\n",
      "tensor([ 0.0004, -0.0008,  0.0062])\n",
      "loss = 0.04804420843720436\n",
      "Iteration 512: b = tensor([-0.9951,  1.7131, -9.7727], grad_fn=<SubBackward0>), Loss = 0.04804420843720436\n",
      "tensor([ 0.0004, -0.0008,  0.0062])\n",
      "loss = 0.04800541698932648\n",
      "Iteration 513: b = tensor([-0.9955,  1.7140, -9.7789], grad_fn=<SubBackward0>), Loss = 0.04800541698932648\n",
      "tensor([ 0.0004, -0.0008,  0.0062])\n",
      "loss = 0.047966741025447845\n",
      "Iteration 514: b = tensor([-0.9959,  1.7148, -9.7850], grad_fn=<SubBackward0>), Loss = 0.047966741025447845\n",
      "tensor([ 0.0004, -0.0008,  0.0061])\n",
      "loss = 0.047928180545568466\n",
      "Iteration 515: b = tensor([-0.9962,  1.7156, -9.7911], grad_fn=<SubBackward0>), Loss = 0.047928180545568466\n",
      "tensor([ 0.0004, -0.0008,  0.0061])\n",
      "loss = 0.04788972809910774\n",
      "Iteration 516: b = tensor([-0.9966,  1.7164, -9.7973], grad_fn=<SubBackward0>), Loss = 0.04788972809910774\n",
      "tensor([ 0.0004, -0.0008,  0.0061])\n",
      "loss = 0.047851379960775375\n",
      "Iteration 517: b = tensor([-0.9969,  1.7173, -9.8034], grad_fn=<SubBackward0>), Loss = 0.047851379960775375\n",
      "tensor([ 0.0004, -0.0008,  0.0061])\n",
      "loss = 0.047813139855861664\n",
      "Iteration 518: b = tensor([-0.9973,  1.7181, -9.8095], grad_fn=<SubBackward0>), Loss = 0.047813139855861664\n",
      "tensor([ 0.0004, -0.0008,  0.0061])\n",
      "loss = 0.04777500778436661\n",
      "Iteration 519: b = tensor([-0.9976,  1.7189, -9.8156], grad_fn=<SubBackward0>), Loss = 0.04777500778436661\n",
      "tensor([ 0.0004, -0.0008,  0.0061])\n",
      "loss = 0.0477369949221611\n",
      "Iteration 520: b = tensor([-0.9980,  1.7197, -9.8217], grad_fn=<SubBackward0>), Loss = 0.0477369949221611\n",
      "tensor([ 0.0004, -0.0008,  0.0061])\n",
      "loss = 0.04769907519221306\n",
      "Iteration 521: b = tensor([-0.9983,  1.7205, -9.8278], grad_fn=<SubBackward0>), Loss = 0.04769907519221306\n",
      "tensor([ 0.0004, -0.0008,  0.0061])\n",
      "loss = 0.04766127094626427\n",
      "Iteration 522: b = tensor([-0.9987,  1.7213, -9.8339], grad_fn=<SubBackward0>), Loss = 0.04766127094626427\n",
      "tensor([ 0.0004, -0.0008,  0.0061])\n",
      "loss = 0.04762355610728264\n",
      "Iteration 523: b = tensor([-0.9991,  1.7222, -9.8399], grad_fn=<SubBackward0>), Loss = 0.04762355610728264\n",
      "tensor([ 0.0004, -0.0008,  0.0061])\n",
      "loss = 0.047585953027009964\n",
      "Iteration 524: b = tensor([-0.9994,  1.7230, -9.8460], grad_fn=<SubBackward0>), Loss = 0.047585953027009964\n",
      "tensor([ 0.0003, -0.0008,  0.0061])\n",
      "loss = 0.04754846543073654\n",
      "Iteration 525: b = tensor([-0.9997,  1.7238, -9.8521], grad_fn=<SubBackward0>), Loss = 0.04754846543073654\n",
      "tensor([ 0.0003, -0.0008,  0.0061])\n",
      "loss = 0.04751107841730118\n",
      "Iteration 526: b = tensor([-1.0001,  1.7246, -9.8581], grad_fn=<SubBackward0>), Loss = 0.04751107841730118\n",
      "tensor([ 0.0003, -0.0008,  0.0060])\n",
      "loss = 0.047473788261413574\n",
      "Iteration 527: b = tensor([-1.0004,  1.7254, -9.8641], grad_fn=<SubBackward0>), Loss = 0.047473788261413574\n",
      "tensor([ 0.0003, -0.0008,  0.0060])\n",
      "loss = 0.047436606138944626\n",
      "Iteration 528: b = tensor([-1.0008,  1.7262, -9.8702], grad_fn=<SubBackward0>), Loss = 0.047436606138944626\n",
      "tensor([ 0.0003, -0.0008,  0.0060])\n",
      "loss = 0.04739953204989433\n",
      "Iteration 529: b = tensor([-1.0011,  1.7270, -9.8762], grad_fn=<SubBackward0>), Loss = 0.04739953204989433\n",
      "tensor([ 0.0003, -0.0008,  0.0060])\n",
      "loss = 0.047362543642520905\n",
      "Iteration 530: b = tensor([-1.0015,  1.7278, -9.8822], grad_fn=<SubBackward0>), Loss = 0.047362543642520905\n",
      "tensor([ 0.0003, -0.0008,  0.0060])\n",
      "loss = 0.047325678169727325\n",
      "Iteration 531: b = tensor([-1.0018,  1.7286, -9.8882], grad_fn=<SubBackward0>), Loss = 0.047325678169727325\n",
      "tensor([ 0.0003, -0.0008,  0.0060])\n",
      "loss = 0.04728890210390091\n",
      "Iteration 532: b = tensor([-1.0022,  1.7294, -9.8942], grad_fn=<SubBackward0>), Loss = 0.04728890210390091\n",
      "tensor([ 0.0003, -0.0008,  0.0060])\n",
      "loss = 0.04725222289562225\n",
      "Iteration 533: b = tensor([-1.0025,  1.7302, -9.9002], grad_fn=<SubBackward0>), Loss = 0.04725222289562225\n",
      "tensor([ 0.0003, -0.0008,  0.0060])\n",
      "loss = 0.047215647995471954\n",
      "Iteration 534: b = tensor([-1.0028,  1.7310, -9.9062], grad_fn=<SubBackward0>), Loss = 0.047215647995471954\n",
      "tensor([ 0.0003, -0.0008,  0.0060])\n",
      "loss = 0.047179169952869415\n",
      "Iteration 535: b = tensor([-1.0032,  1.7317, -9.9121], grad_fn=<SubBackward0>), Loss = 0.047179169952869415\n",
      "tensor([ 0.0003, -0.0008,  0.0060])\n",
      "loss = 0.047142792493104935\n",
      "Iteration 536: b = tensor([-1.0035,  1.7325, -9.9181], grad_fn=<SubBackward0>), Loss = 0.047142792493104935\n",
      "tensor([ 0.0003, -0.0008,  0.0060])\n",
      "loss = 0.04710652679204941\n",
      "Iteration 537: b = tensor([-1.0039,  1.7333, -9.9241], grad_fn=<SubBackward0>), Loss = 0.04710652679204941\n",
      "tensor([ 0.0003, -0.0008,  0.0060])\n",
      "loss = 0.047070350497961044\n",
      "Iteration 538: b = tensor([-1.0042,  1.7341, -9.9300], grad_fn=<SubBackward0>), Loss = 0.047070350497961044\n",
      "tensor([ 0.0003, -0.0008,  0.0059])\n",
      "loss = 0.047034259885549545\n",
      "Iteration 539: b = tensor([-1.0045,  1.7349, -9.9359], grad_fn=<SubBackward0>), Loss = 0.047034259885549545\n",
      "tensor([ 0.0003, -0.0008,  0.0059])\n",
      "loss = 0.046998281031847\n",
      "Iteration 540: b = tensor([-1.0049,  1.7357, -9.9419], grad_fn=<SubBackward0>), Loss = 0.046998281031847\n",
      "tensor([ 0.0003, -0.0008,  0.0059])\n",
      "loss = 0.046962399035692215\n",
      "Iteration 541: b = tensor([-1.0052,  1.7364, -9.9478], grad_fn=<SubBackward0>), Loss = 0.046962399035692215\n",
      "tensor([ 0.0003, -0.0008,  0.0059])\n",
      "loss = 0.04692661389708519\n",
      "Iteration 542: b = tensor([-1.0055,  1.7372, -9.9537], grad_fn=<SubBackward0>), Loss = 0.04692661389708519\n",
      "tensor([ 0.0003, -0.0008,  0.0059])\n",
      "loss = 0.046890921890735626\n",
      "Iteration 543: b = tensor([-1.0059,  1.7380, -9.9596], grad_fn=<SubBackward0>), Loss = 0.046890921890735626\n",
      "tensor([ 0.0003, -0.0008,  0.0059])\n",
      "loss = 0.04685532674193382\n",
      "Iteration 544: b = tensor([-1.0062,  1.7388, -9.9655], grad_fn=<SubBackward0>), Loss = 0.04685532674193382\n",
      "tensor([ 0.0003, -0.0008,  0.0059])\n",
      "loss = 0.04681982472538948\n",
      "Iteration 545: b = tensor([-1.0065,  1.7395, -9.9714], grad_fn=<SubBackward0>), Loss = 0.04681982472538948\n",
      "tensor([ 0.0003, -0.0008,  0.0059])\n",
      "loss = 0.0467844195663929\n",
      "Iteration 546: b = tensor([-1.0069,  1.7403, -9.9773], grad_fn=<SubBackward0>), Loss = 0.0467844195663929\n",
      "tensor([ 0.0003, -0.0008,  0.0059])\n",
      "loss = 0.04674910381436348\n",
      "Iteration 547: b = tensor([-1.0072,  1.7411, -9.9832], grad_fn=<SubBackward0>), Loss = 0.04674910381436348\n",
      "tensor([ 0.0003, -0.0008,  0.0059])\n",
      "loss = 0.04671388864517212\n",
      "Iteration 548: b = tensor([-1.0075,  1.7418, -9.9890], grad_fn=<SubBackward0>), Loss = 0.04671388864517212\n",
      "tensor([ 0.0003, -0.0008,  0.0059])\n",
      "loss = 0.04667876288294792\n",
      "Iteration 549: b = tensor([-1.0079,  1.7426, -9.9949], grad_fn=<SubBackward0>), Loss = 0.04667876288294792\n",
      "tensor([ 0.0003, -0.0008,  0.0059])\n",
      "loss = 0.04664372652769089\n",
      "Iteration 550: b = tensor([ -1.0082,   1.7434, -10.0008], grad_fn=<SubBackward0>), Loss = 0.04664372652769089\n",
      "tensor([ 0.0003, -0.0008,  0.0059])\n",
      "loss = 0.04660879820585251\n",
      "Iteration 551: b = tensor([ -1.0085,   1.7441, -10.0066], grad_fn=<SubBackward0>), Loss = 0.04660879820585251\n",
      "tensor([ 0.0003, -0.0008,  0.0058])\n",
      "loss = 0.046573951840400696\n",
      "Iteration 552: b = tensor([ -1.0088,   1.7449, -10.0124], grad_fn=<SubBackward0>), Loss = 0.046573951840400696\n",
      "tensor([ 0.0003, -0.0008,  0.0058])\n",
      "loss = 0.04653920605778694\n",
      "Iteration 553: b = tensor([ -1.0092,   1.7457, -10.0183], grad_fn=<SubBackward0>), Loss = 0.04653920605778694\n",
      "tensor([ 0.0003, -0.0008,  0.0058])\n",
      "loss = 0.04650454595685005\n",
      "Iteration 554: b = tensor([ -1.0095,   1.7464, -10.0241], grad_fn=<SubBackward0>), Loss = 0.04650454595685005\n",
      "tensor([ 0.0003, -0.0008,  0.0058])\n",
      "loss = 0.046469978988170624\n",
      "Iteration 555: b = tensor([ -1.0098,   1.7472, -10.0299], grad_fn=<SubBackward0>), Loss = 0.046469978988170624\n",
      "tensor([ 0.0003, -0.0008,  0.0058])\n",
      "loss = 0.04643549025058746\n",
      "Iteration 556: b = tensor([ -1.0101,   1.7479, -10.0357], grad_fn=<SubBackward0>), Loss = 0.04643549025058746\n",
      "tensor([ 0.0003, -0.0008,  0.0058])\n",
      "loss = 0.04640110209584236\n",
      "Iteration 557: b = tensor([ -1.0104,   1.7487, -10.0415], grad_fn=<SubBackward0>), Loss = 0.04640110209584236\n",
      "tensor([ 0.0003, -0.0008,  0.0058])\n",
      "loss = 0.04636680707335472\n",
      "Iteration 558: b = tensor([ -1.0108,   1.7494, -10.0473], grad_fn=<SubBackward0>), Loss = 0.04636680707335472\n",
      "tensor([ 0.0003, -0.0008,  0.0058])\n",
      "loss = 0.046332601457834244\n",
      "Iteration 559: b = tensor([ -1.0111,   1.7502, -10.0531], grad_fn=<SubBackward0>), Loss = 0.046332601457834244\n",
      "tensor([ 0.0003, -0.0007,  0.0058])\n",
      "loss = 0.046298470348119736\n",
      "Iteration 560: b = tensor([ -1.0114,   1.7509, -10.0589], grad_fn=<SubBackward0>), Loss = 0.046298470348119736\n",
      "tensor([ 0.0003, -0.0007,  0.0058])\n",
      "loss = 0.046264439821243286\n",
      "Iteration 561: b = tensor([ -1.0117,   1.7517, -10.0647], grad_fn=<SubBackward0>), Loss = 0.046264439821243286\n",
      "tensor([ 0.0003, -0.0007,  0.0058])\n",
      "loss = 0.0462304949760437\n",
      "Iteration 562: b = tensor([ -1.0120,   1.7524, -10.0704], grad_fn=<SubBackward0>), Loss = 0.0462304949760437\n",
      "tensor([ 0.0003, -0.0007,  0.0058])\n",
      "loss = 0.046196646988391876\n",
      "Iteration 563: b = tensor([ -1.0124,   1.7532, -10.0762], grad_fn=<SubBackward0>), Loss = 0.046196646988391876\n",
      "tensor([ 0.0003, -0.0007,  0.0058])\n",
      "loss = 0.04616287723183632\n",
      "Iteration 564: b = tensor([ -1.0127,   1.7539, -10.0819], grad_fn=<SubBackward0>), Loss = 0.04616287723183632\n",
      "tensor([ 0.0003, -0.0007,  0.0057])\n",
      "loss = 0.04612918570637703\n",
      "Iteration 565: b = tensor([ -1.0130,   1.7546, -10.0877], grad_fn=<SubBackward0>), Loss = 0.04612918570637703\n",
      "tensor([ 0.0003, -0.0007,  0.0057])\n",
      "loss = 0.0460955910384655\n",
      "Iteration 566: b = tensor([ -1.0133,   1.7554, -10.0934], grad_fn=<SubBackward0>), Loss = 0.0460955910384655\n",
      "tensor([ 0.0003, -0.0007,  0.0057])\n",
      "loss = 0.04606208950281143\n",
      "Iteration 567: b = tensor([ -1.0136,   1.7561, -10.0991], grad_fn=<SubBackward0>), Loss = 0.04606208950281143\n",
      "tensor([ 0.0003, -0.0007,  0.0057])\n",
      "loss = 0.046028655022382736\n",
      "Iteration 568: b = tensor([ -1.0139,   1.7569, -10.1049], grad_fn=<SubBackward0>), Loss = 0.046028655022382736\n",
      "tensor([ 0.0003, -0.0007,  0.0057])\n",
      "loss = 0.0459953248500824\n",
      "Iteration 569: b = tensor([ -1.0142,   1.7576, -10.1106], grad_fn=<SubBackward0>), Loss = 0.0459953248500824\n",
      "tensor([ 0.0003, -0.0007,  0.0057])\n",
      "loss = 0.04596208408474922\n",
      "Iteration 570: b = tensor([ -1.0145,   1.7583, -10.1163], grad_fn=<SubBackward0>), Loss = 0.04596208408474922\n",
      "tensor([ 0.0003, -0.0007,  0.0057])\n",
      "loss = 0.045928917825222015\n",
      "Iteration 571: b = tensor([ -1.0149,   1.7590, -10.1220], grad_fn=<SubBackward0>), Loss = 0.045928917825222015\n",
      "tensor([ 0.0003, -0.0007,  0.0057])\n",
      "loss = 0.04589582607150078\n",
      "Iteration 572: b = tensor([ -1.0152,   1.7598, -10.1277], grad_fn=<SubBackward0>), Loss = 0.04589582607150078\n",
      "tensor([ 0.0003, -0.0007,  0.0057])\n",
      "loss = 0.0458628349006176\n",
      "Iteration 573: b = tensor([ -1.0155,   1.7605, -10.1333], grad_fn=<SubBackward0>), Loss = 0.0458628349006176\n",
      "tensor([ 0.0003, -0.0007,  0.0057])\n",
      "loss = 0.04582991823554039\n",
      "Iteration 574: b = tensor([ -1.0158,   1.7612, -10.1390], grad_fn=<SubBackward0>), Loss = 0.04582991823554039\n",
      "tensor([ 0.0003, -0.0007,  0.0057])\n",
      "loss = 0.045797090977430344\n",
      "Iteration 575: b = tensor([ -1.0161,   1.7620, -10.1447], grad_fn=<SubBackward0>), Loss = 0.045797090977430344\n",
      "tensor([ 0.0003, -0.0007,  0.0057])\n",
      "loss = 0.045764341950416565\n",
      "Iteration 576: b = tensor([ -1.0164,   1.7627, -10.1504], grad_fn=<SubBackward0>), Loss = 0.045764341950416565\n",
      "tensor([ 0.0003, -0.0007,  0.0057])\n",
      "loss = 0.04573167860507965\n",
      "Iteration 577: b = tensor([ -1.0167,   1.7634, -10.1560], grad_fn=<SubBackward0>), Loss = 0.04573167860507965\n",
      "tensor([ 0.0003, -0.0007,  0.0057])\n",
      "loss = 0.045699093490839005\n",
      "Iteration 578: b = tensor([ -1.0170,   1.7641, -10.1617], grad_fn=<SubBackward0>), Loss = 0.045699093490839005\n",
      "tensor([ 0.0003, -0.0007,  0.0056])\n",
      "loss = 0.04566659405827522\n",
      "Iteration 579: b = tensor([ -1.0173,   1.7648, -10.1673], grad_fn=<SubBackward0>), Loss = 0.04566659405827522\n",
      "tensor([ 0.0003, -0.0007,  0.0056])\n",
      "loss = 0.04563417285680771\n",
      "Iteration 580: b = tensor([ -1.0176,   1.7655, -10.1729], grad_fn=<SubBackward0>), Loss = 0.04563417285680771\n",
      "tensor([ 0.0003, -0.0007,  0.0056])\n",
      "loss = 0.04560182988643646\n",
      "Iteration 581: b = tensor([ -1.0179,   1.7663, -10.1786], grad_fn=<SubBackward0>), Loss = 0.04560182988643646\n",
      "tensor([ 0.0003, -0.0007,  0.0056])\n",
      "loss = 0.04556957632303238\n",
      "Iteration 582: b = tensor([ -1.0182,   1.7670, -10.1842], grad_fn=<SubBackward0>), Loss = 0.04556957632303238\n",
      "tensor([ 0.0003, -0.0007,  0.0056])\n",
      "loss = 0.04553741216659546\n",
      "Iteration 583: b = tensor([ -1.0185,   1.7677, -10.1898], grad_fn=<SubBackward0>), Loss = 0.04553741216659546\n",
      "tensor([ 0.0003, -0.0007,  0.0056])\n",
      "loss = 0.04550531134009361\n",
      "Iteration 584: b = tensor([ -1.0188,   1.7684, -10.1954], grad_fn=<SubBackward0>), Loss = 0.04550531134009361\n",
      "tensor([ 0.0003, -0.0007,  0.0056])\n",
      "loss = 0.045473288744688034\n",
      "Iteration 585: b = tensor([ -1.0191,   1.7691, -10.2010], grad_fn=<SubBackward0>), Loss = 0.045473288744688034\n",
      "tensor([ 0.0003, -0.0007,  0.0056])\n",
      "loss = 0.04544135555624962\n",
      "Iteration 586: b = tensor([ -1.0194,   1.7698, -10.2066], grad_fn=<SubBackward0>), Loss = 0.04544135555624962\n",
      "tensor([ 0.0003, -0.0007,  0.0056])\n",
      "loss = 0.04540950059890747\n",
      "Iteration 587: b = tensor([ -1.0197,   1.7705, -10.2122], grad_fn=<SubBackward0>), Loss = 0.04540950059890747\n",
      "tensor([ 0.0003, -0.0007,  0.0056])\n",
      "loss = 0.04537772387266159\n",
      "Iteration 588: b = tensor([ -1.0200,   1.7712, -10.2178], grad_fn=<SubBackward0>), Loss = 0.04537772387266159\n",
      "tensor([ 0.0003, -0.0007,  0.0056])\n",
      "loss = 0.045346032828092575\n",
      "Iteration 589: b = tensor([ -1.0203,   1.7719, -10.2233], grad_fn=<SubBackward0>), Loss = 0.045346032828092575\n",
      "tensor([ 0.0003, -0.0007,  0.0056])\n",
      "loss = 0.04531441256403923\n",
      "Iteration 590: b = tensor([ -1.0206,   1.7726, -10.2289], grad_fn=<SubBackward0>), Loss = 0.04531441256403923\n",
      "tensor([ 0.0003, -0.0007,  0.0056])\n",
      "loss = 0.045282866805791855\n",
      "Iteration 591: b = tensor([ -1.0209,   1.7733, -10.2345], grad_fn=<SubBackward0>), Loss = 0.045282866805791855\n",
      "tensor([ 0.0003, -0.0007,  0.0056])\n",
      "loss = 0.04525139182806015\n",
      "Iteration 592: b = tensor([ -1.0212,   1.7740, -10.2400], grad_fn=<SubBackward0>), Loss = 0.04525139182806015\n",
      "tensor([ 0.0003, -0.0007,  0.0056])\n",
      "loss = 0.04522000998258591\n",
      "Iteration 593: b = tensor([ -1.0215,   1.7747, -10.2456], grad_fn=<SubBackward0>), Loss = 0.04522000998258591\n",
      "tensor([ 0.0003, -0.0007,  0.0055])\n",
      "loss = 0.04518868774175644\n",
      "Iteration 594: b = tensor([ -1.0218,   1.7754, -10.2511], grad_fn=<SubBackward0>), Loss = 0.04518868774175644\n",
      "tensor([ 0.0003, -0.0007,  0.0055])\n",
      "loss = 0.04515747353434563\n",
      "Iteration 595: b = tensor([ -1.0221,   1.7761, -10.2566], grad_fn=<SubBackward0>), Loss = 0.04515747353434563\n",
      "tensor([ 0.0003, -0.0007,  0.0055])\n",
      "loss = 0.045126307755708694\n",
      "Iteration 596: b = tensor([ -1.0224,   1.7768, -10.2622], grad_fn=<SubBackward0>), Loss = 0.045126307755708694\n",
      "tensor([ 0.0003, -0.0007,  0.0055])\n",
      "loss = 0.04509522765874863\n",
      "Iteration 597: b = tensor([ -1.0226,   1.7775, -10.2677], grad_fn=<SubBackward0>), Loss = 0.04509522765874863\n",
      "tensor([ 0.0003, -0.0007,  0.0055])\n",
      "loss = 0.04506422206759453\n",
      "Iteration 598: b = tensor([ -1.0229,   1.7782, -10.2732], grad_fn=<SubBackward0>), Loss = 0.04506422206759453\n",
      "tensor([ 0.0003, -0.0007,  0.0055])\n",
      "loss = 0.0450332909822464\n",
      "Iteration 599: b = tensor([ -1.0232,   1.7789, -10.2787], grad_fn=<SubBackward0>), Loss = 0.0450332909822464\n",
      "tensor([ 0.0003, -0.0007,  0.0055])\n",
      "loss = 0.045002419501543045\n",
      "Iteration 600: b = tensor([ -1.0235,   1.7796, -10.2842], grad_fn=<SubBackward0>), Loss = 0.045002419501543045\n",
      "tensor([ 0.0003, -0.0007,  0.0055])\n",
      "loss = 0.04497165605425835\n",
      "Iteration 601: b = tensor([ -1.0238,   1.7802, -10.2897], grad_fn=<SubBackward0>), Loss = 0.04497165605425835\n",
      "tensor([ 0.0003, -0.0007,  0.0055])\n",
      "loss = 0.04494094476103783\n",
      "Iteration 602: b = tensor([ -1.0241,   1.7809, -10.2952], grad_fn=<SubBackward0>), Loss = 0.04494094476103783\n",
      "tensor([ 0.0003, -0.0007,  0.0055])\n",
      "loss = 0.04491030052304268\n",
      "Iteration 603: b = tensor([ -1.0244,   1.7816, -10.3007], grad_fn=<SubBackward0>), Loss = 0.04491030052304268\n",
      "tensor([ 0.0003, -0.0007,  0.0055])\n",
      "loss = 0.044879745692014694\n",
      "Iteration 604: b = tensor([ -1.0247,   1.7823, -10.3061], grad_fn=<SubBackward0>), Loss = 0.044879745692014694\n",
      "tensor([ 0.0003, -0.0007,  0.0055])\n",
      "loss = 0.04484926536679268\n",
      "Iteration 605: b = tensor([ -1.0249,   1.7830, -10.3116], grad_fn=<SubBackward0>), Loss = 0.04484926536679268\n",
      "tensor([ 0.0003, -0.0007,  0.0055])\n",
      "loss = 0.04481884837150574\n",
      "Iteration 606: b = tensor([ -1.0252,   1.7837, -10.3171], grad_fn=<SubBackward0>), Loss = 0.04481884837150574\n",
      "tensor([ 0.0003, -0.0007,  0.0055])\n",
      "loss = 0.04478850215673447\n",
      "Iteration 607: b = tensor([ -1.0255,   1.7843, -10.3225], grad_fn=<SubBackward0>), Loss = 0.04478850215673447\n",
      "tensor([ 0.0003, -0.0007,  0.0055])\n",
      "loss = 0.04475823789834976\n",
      "Iteration 608: b = tensor([ -1.0258,   1.7850, -10.3280], grad_fn=<SubBackward0>), Loss = 0.04475823789834976\n",
      "tensor([ 0.0003, -0.0007,  0.0054])\n",
      "loss = 0.04472804814577103\n",
      "Iteration 609: b = tensor([ -1.0261,   1.7857, -10.3334], grad_fn=<SubBackward0>), Loss = 0.04472804814577103\n",
      "tensor([ 0.0003, -0.0007,  0.0054])\n",
      "loss = 0.04469791799783707\n",
      "Iteration 610: b = tensor([ -1.0263,   1.7864, -10.3388], grad_fn=<SubBackward0>), Loss = 0.04469791799783707\n",
      "tensor([ 0.0003, -0.0007,  0.0054])\n",
      "loss = 0.044667866080999374\n",
      "Iteration 611: b = tensor([ -1.0266,   1.7870, -10.3443], grad_fn=<SubBackward0>), Loss = 0.044667866080999374\n",
      "tensor([ 0.0003, -0.0007,  0.0054])\n",
      "loss = 0.04463789239525795\n",
      "Iteration 612: b = tensor([ -1.0269,   1.7877, -10.3497], grad_fn=<SubBackward0>), Loss = 0.04463789239525795\n",
      "tensor([ 0.0003, -0.0007,  0.0054])\n",
      "loss = 0.0446079783141613\n",
      "Iteration 613: b = tensor([ -1.0272,   1.7884, -10.3551], grad_fn=<SubBackward0>), Loss = 0.0446079783141613\n",
      "tensor([ 0.0003, -0.0007,  0.0054])\n",
      "loss = 0.04457814618945122\n",
      "Iteration 614: b = tensor([ -1.0275,   1.7890, -10.3605], grad_fn=<SubBackward0>), Loss = 0.04457814618945122\n",
      "tensor([ 0.0003, -0.0007,  0.0054])\n",
      "loss = 0.04454837366938591\n",
      "Iteration 615: b = tensor([ -1.0277,   1.7897, -10.3659], grad_fn=<SubBackward0>), Loss = 0.04454837366938591\n",
      "tensor([ 0.0003, -0.0007,  0.0054])\n",
      "loss = 0.04451868683099747\n",
      "Iteration 616: b = tensor([ -1.0280,   1.7904, -10.3713], grad_fn=<SubBackward0>), Loss = 0.04451868683099747\n",
      "tensor([ 0.0003, -0.0007,  0.0054])\n",
      "loss = 0.0444890595972538\n",
      "Iteration 617: b = tensor([ -1.0283,   1.7910, -10.3767], grad_fn=<SubBackward0>), Loss = 0.0444890595972538\n",
      "tensor([ 0.0003, -0.0007,  0.0054])\n",
      "loss = 0.0444595031440258\n",
      "Iteration 618: b = tensor([ -1.0286,   1.7917, -10.3821], grad_fn=<SubBackward0>), Loss = 0.0444595031440258\n",
      "tensor([ 0.0003, -0.0007,  0.0054])\n",
      "loss = 0.04443000629544258\n",
      "Iteration 619: b = tensor([ -1.0288,   1.7924, -10.3875], grad_fn=<SubBackward0>), Loss = 0.04443000629544258\n",
      "tensor([ 0.0003, -0.0007,  0.0054])\n",
      "loss = 0.044400595128536224\n",
      "Iteration 620: b = tensor([ -1.0291,   1.7930, -10.3928], grad_fn=<SubBackward0>), Loss = 0.044400595128536224\n",
      "tensor([ 0.0003, -0.0007,  0.0054])\n",
      "loss = 0.04437124729156494\n",
      "Iteration 621: b = tensor([ -1.0294,   1.7937, -10.3982], grad_fn=<SubBackward0>), Loss = 0.04437124729156494\n",
      "tensor([ 0.0003, -0.0007,  0.0054])\n",
      "loss = 0.04434196650981903\n",
      "Iteration 622: b = tensor([ -1.0297,   1.7943, -10.4036], grad_fn=<SubBackward0>), Loss = 0.04434196650981903\n",
      "tensor([ 0.0003, -0.0007,  0.0054])\n",
      "loss = 0.04431275650858879\n",
      "Iteration 623: b = tensor([ -1.0299,   1.7950, -10.4089], grad_fn=<SubBackward0>), Loss = 0.04431275650858879\n",
      "tensor([ 0.0003, -0.0007,  0.0054])\n",
      "loss = 0.044283606112003326\n",
      "Iteration 624: b = tensor([ -1.0302,   1.7956, -10.4143], grad_fn=<SubBackward0>), Loss = 0.044283606112003326\n",
      "tensor([ 0.0003, -0.0007,  0.0053])\n",
      "loss = 0.04425452649593353\n",
      "Iteration 625: b = tensor([ -1.0305,   1.7963, -10.4196], grad_fn=<SubBackward0>), Loss = 0.04425452649593353\n",
      "tensor([ 0.0003, -0.0007,  0.0053])\n",
      "loss = 0.04422552511096001\n",
      "Iteration 626: b = tensor([ -1.0307,   1.7969, -10.4249], grad_fn=<SubBackward0>), Loss = 0.04422552511096001\n",
      "tensor([ 0.0003, -0.0007,  0.0053])\n",
      "loss = 0.04419657215476036\n",
      "Iteration 627: b = tensor([ -1.0310,   1.7976, -10.4303], grad_fn=<SubBackward0>), Loss = 0.04419657215476036\n",
      "tensor([ 0.0003, -0.0007,  0.0053])\n",
      "loss = 0.04416769742965698\n",
      "Iteration 628: b = tensor([ -1.0313,   1.7982, -10.4356], grad_fn=<SubBackward0>), Loss = 0.04416769742965698\n",
      "tensor([ 0.0003, -0.0006,  0.0053])\n",
      "loss = 0.044138893485069275\n",
      "Iteration 629: b = tensor([ -1.0316,   1.7989, -10.4409], grad_fn=<SubBackward0>), Loss = 0.044138893485069275\n",
      "tensor([ 0.0003, -0.0006,  0.0053])\n",
      "loss = 0.04411014914512634\n",
      "Iteration 630: b = tensor([ -1.0318,   1.7995, -10.4462], grad_fn=<SubBackward0>), Loss = 0.04411014914512634\n",
      "tensor([ 0.0003, -0.0006,  0.0053])\n",
      "loss = 0.044081468135118484\n",
      "Iteration 631: b = tensor([ -1.0321,   1.8002, -10.4515], grad_fn=<SubBackward0>), Loss = 0.044081468135118484\n",
      "tensor([ 0.0003, -0.0006,  0.0053])\n",
      "loss = 0.044052865356206894\n",
      "Iteration 632: b = tensor([ -1.0324,   1.8008, -10.4568], grad_fn=<SubBackward0>), Loss = 0.044052865356206894\n",
      "tensor([ 0.0003, -0.0006,  0.0053])\n",
      "loss = 0.044024329632520676\n",
      "Iteration 633: b = tensor([ -1.0326,   1.8015, -10.4621], grad_fn=<SubBackward0>), Loss = 0.044024329632520676\n",
      "tensor([ 0.0003, -0.0006,  0.0053])\n",
      "loss = 0.04399585351347923\n",
      "Iteration 634: b = tensor([ -1.0329,   1.8021, -10.4674], grad_fn=<SubBackward0>), Loss = 0.04399585351347923\n",
      "tensor([ 0.0003, -0.0006,  0.0053])\n",
      "loss = 0.04396742582321167\n",
      "Iteration 635: b = tensor([ -1.0331,   1.8027, -10.4727], grad_fn=<SubBackward0>), Loss = 0.04396742582321167\n",
      "tensor([ 0.0003, -0.0006,  0.0053])\n",
      "loss = 0.04393908381462097\n",
      "Iteration 636: b = tensor([ -1.0334,   1.8034, -10.4780], grad_fn=<SubBackward0>), Loss = 0.04393908381462097\n",
      "tensor([ 0.0003, -0.0006,  0.0053])\n",
      "loss = 0.04391080141067505\n",
      "Iteration 637: b = tensor([ -1.0337,   1.8040, -10.4832], grad_fn=<SubBackward0>), Loss = 0.04391080141067505\n",
      "tensor([ 0.0003, -0.0006,  0.0053])\n",
      "loss = 0.043882571160793304\n",
      "Iteration 638: b = tensor([ -1.0339,   1.8047, -10.4885], grad_fn=<SubBackward0>), Loss = 0.043882571160793304\n",
      "tensor([ 0.0003, -0.0006,  0.0053])\n",
      "loss = 0.04385441541671753\n",
      "Iteration 639: b = tensor([ -1.0342,   1.8053, -10.4937], grad_fn=<SubBackward0>), Loss = 0.04385441541671753\n",
      "tensor([ 0.0003, -0.0006,  0.0053])\n",
      "loss = 0.04382632300257683\n",
      "Iteration 640: b = tensor([ -1.0345,   1.8059, -10.4990], grad_fn=<SubBackward0>), Loss = 0.04382632300257683\n",
      "tensor([ 0.0003, -0.0006,  0.0053])\n",
      "loss = 0.0437982976436615\n",
      "Iteration 641: b = tensor([ -1.0347,   1.8066, -10.5042], grad_fn=<SubBackward0>), Loss = 0.0437982976436615\n",
      "tensor([ 0.0003, -0.0006,  0.0052])\n",
      "loss = 0.043770331889390945\n",
      "Iteration 642: b = tensor([ -1.0350,   1.8072, -10.5095], grad_fn=<SubBackward0>), Loss = 0.043770331889390945\n",
      "tensor([ 0.0003, -0.0006,  0.0052])\n",
      "loss = 0.04374243691563606\n",
      "Iteration 643: b = tensor([ -1.0352,   1.8078, -10.5147], grad_fn=<SubBackward0>), Loss = 0.04374243691563606\n",
      "tensor([ 0.0003, -0.0006,  0.0052])\n",
      "loss = 0.04371458664536476\n",
      "Iteration 644: b = tensor([ -1.0355,   1.8084, -10.5199], grad_fn=<SubBackward0>), Loss = 0.04371458664536476\n",
      "tensor([ 0.0003, -0.0006,  0.0052])\n",
      "loss = 0.043686822056770325\n",
      "Iteration 645: b = tensor([ -1.0357,   1.8091, -10.5252], grad_fn=<SubBackward0>), Loss = 0.043686822056770325\n",
      "tensor([ 0.0003, -0.0006,  0.0052])\n",
      "loss = 0.04365910217165947\n",
      "Iteration 646: b = tensor([ -1.0360,   1.8097, -10.5304], grad_fn=<SubBackward0>), Loss = 0.04365910217165947\n",
      "tensor([ 0.0003, -0.0006,  0.0052])\n",
      "loss = 0.04363144934177399\n",
      "Iteration 647: b = tensor([ -1.0363,   1.8103, -10.5356], grad_fn=<SubBackward0>), Loss = 0.04363144934177399\n",
      "tensor([ 0.0003, -0.0006,  0.0052])\n",
      "loss = 0.04360385611653328\n",
      "Iteration 648: b = tensor([ -1.0365,   1.8109, -10.5408], grad_fn=<SubBackward0>), Loss = 0.04360385611653328\n",
      "tensor([ 0.0003, -0.0006,  0.0052])\n",
      "loss = 0.04357631877064705\n",
      "Iteration 649: b = tensor([ -1.0368,   1.8116, -10.5460], grad_fn=<SubBackward0>), Loss = 0.04357631877064705\n",
      "tensor([ 0.0003, -0.0006,  0.0052])\n",
      "loss = 0.04354887083172798\n",
      "Iteration 650: b = tensor([ -1.0370,   1.8122, -10.5512], grad_fn=<SubBackward0>), Loss = 0.04354887083172798\n",
      "tensor([ 0.0003, -0.0006,  0.0052])\n",
      "loss = 0.043521448969841\n",
      "Iteration 651: b = tensor([ -1.0373,   1.8128, -10.5564], grad_fn=<SubBackward0>), Loss = 0.043521448969841\n",
      "tensor([ 0.0003, -0.0006,  0.0052])\n",
      "loss = 0.043494101613759995\n",
      "Iteration 652: b = tensor([ -1.0375,   1.8134, -10.5616], grad_fn=<SubBackward0>), Loss = 0.043494101613759995\n",
      "tensor([ 0.0003, -0.0006,  0.0052])\n",
      "loss = 0.043466825038194656\n",
      "Iteration 653: b = tensor([ -1.0378,   1.8140, -10.5667], grad_fn=<SubBackward0>), Loss = 0.043466825038194656\n",
      "tensor([ 0.0003, -0.0006,  0.0052])\n",
      "loss = 0.0434395968914032\n",
      "Iteration 654: b = tensor([ -1.0380,   1.8147, -10.5719], grad_fn=<SubBackward0>), Loss = 0.0434395968914032\n",
      "tensor([ 0.0003, -0.0006,  0.0052])\n",
      "loss = 0.043412432074546814\n",
      "Iteration 655: b = tensor([ -1.0383,   1.8153, -10.5771], grad_fn=<SubBackward0>), Loss = 0.043412432074546814\n",
      "tensor([ 0.0003, -0.0006,  0.0052])\n",
      "loss = 0.043385330587625504\n",
      "Iteration 656: b = tensor([ -1.0385,   1.8159, -10.5822], grad_fn=<SubBackward0>), Loss = 0.043385330587625504\n",
      "tensor([ 0.0003, -0.0006,  0.0052])\n",
      "loss = 0.04335828498005867\n",
      "Iteration 657: b = tensor([ -1.0388,   1.8165, -10.5874], grad_fn=<SubBackward0>), Loss = 0.04335828498005867\n",
      "tensor([ 0.0002, -0.0006,  0.0052])\n",
      "loss = 0.04333129897713661\n",
      "Iteration 658: b = tensor([ -1.0390,   1.8171, -10.5925], grad_fn=<SubBackward0>), Loss = 0.04333129897713661\n",
      "tensor([ 0.0002, -0.0006,  0.0051])\n",
      "loss = 0.043304383754730225\n",
      "Iteration 659: b = tensor([ -1.0393,   1.8177, -10.5977], grad_fn=<SubBackward0>), Loss = 0.043304383754730225\n",
      "tensor([ 0.0002, -0.0006,  0.0051])\n",
      "loss = 0.043277520686388016\n",
      "Iteration 660: b = tensor([ -1.0395,   1.8183, -10.6028], grad_fn=<SubBackward0>), Loss = 0.043277520686388016\n",
      "tensor([ 0.0002, -0.0006,  0.0051])\n",
      "loss = 0.04325070604681969\n",
      "Iteration 661: b = tensor([ -1.0398,   1.8189, -10.6079], grad_fn=<SubBackward0>), Loss = 0.04325070604681969\n",
      "tensor([ 0.0002, -0.0006,  0.0051])\n",
      "loss = 0.04322396218776703\n",
      "Iteration 662: b = tensor([ -1.0400,   1.8195, -10.6131], grad_fn=<SubBackward0>), Loss = 0.04322396218776703\n",
      "tensor([ 0.0002, -0.0006,  0.0051])\n",
      "loss = 0.04319727048277855\n",
      "Iteration 663: b = tensor([ -1.0403,   1.8201, -10.6182], grad_fn=<SubBackward0>), Loss = 0.04319727048277855\n",
      "tensor([ 0.0002, -0.0006,  0.0051])\n",
      "loss = 0.04317064955830574\n",
      "Iteration 664: b = tensor([ -1.0405,   1.8207, -10.6233], grad_fn=<SubBackward0>), Loss = 0.04317064955830574\n",
      "tensor([ 0.0002, -0.0006,  0.0051])\n",
      "loss = 0.043144069612026215\n",
      "Iteration 665: b = tensor([ -1.0408,   1.8213, -10.6284], grad_fn=<SubBackward0>), Loss = 0.043144069612026215\n",
      "tensor([ 0.0002, -0.0006,  0.0051])\n",
      "loss = 0.04311756417155266\n",
      "Iteration 666: b = tensor([ -1.0410,   1.8220, -10.6335], grad_fn=<SubBackward0>), Loss = 0.04311756417155266\n",
      "tensor([ 0.0002, -0.0006,  0.0051])\n",
      "loss = 0.043091099709272385\n",
      "Iteration 667: b = tensor([ -1.0413,   1.8226, -10.6386], grad_fn=<SubBackward0>), Loss = 0.043091099709272385\n",
      "tensor([ 0.0002, -0.0006,  0.0051])\n",
      "loss = 0.04306470602750778\n",
      "Iteration 668: b = tensor([ -1.0415,   1.8232, -10.6437], grad_fn=<SubBackward0>), Loss = 0.04306470602750778\n",
      "tensor([ 0.0002, -0.0006,  0.0051])\n",
      "loss = 0.04303836449980736\n",
      "Iteration 669: b = tensor([ -1.0417,   1.8237, -10.6488], grad_fn=<SubBackward0>), Loss = 0.04303836449980736\n",
      "tensor([ 0.0002, -0.0006,  0.0051])\n",
      "loss = 0.04301208257675171\n",
      "Iteration 670: b = tensor([ -1.0420,   1.8243, -10.6539], grad_fn=<SubBackward0>), Loss = 0.04301208257675171\n",
      "tensor([ 0.0002, -0.0006,  0.0051])\n",
      "loss = 0.04298584163188934\n",
      "Iteration 671: b = tensor([ -1.0422,   1.8249, -10.6590], grad_fn=<SubBackward0>), Loss = 0.04298584163188934\n",
      "tensor([ 0.0002, -0.0006,  0.0051])\n",
      "loss = 0.042959682643413544\n",
      "Iteration 672: b = tensor([ -1.0425,   1.8255, -10.6640], grad_fn=<SubBackward0>), Loss = 0.042959682643413544\n",
      "tensor([ 0.0002, -0.0006,  0.0051])\n",
      "loss = 0.04293356463313103\n",
      "Iteration 673: b = tensor([ -1.0427,   1.8261, -10.6691], grad_fn=<SubBackward0>), Loss = 0.04293356463313103\n",
      "tensor([ 0.0002, -0.0006,  0.0051])\n",
      "loss = 0.04290750250220299\n",
      "Iteration 674: b = tensor([ -1.0429,   1.8267, -10.6742], grad_fn=<SubBackward0>), Loss = 0.04290750250220299\n",
      "tensor([ 0.0002, -0.0006,  0.0051])\n",
      "loss = 0.042881499975919724\n",
      "Iteration 675: b = tensor([ -1.0432,   1.8273, -10.6792], grad_fn=<SubBackward0>), Loss = 0.042881499975919724\n",
      "tensor([ 0.0002, -0.0006,  0.0051])\n",
      "loss = 0.042855553328990936\n",
      "Iteration 676: b = tensor([ -1.0434,   1.8279, -10.6843], grad_fn=<SubBackward0>), Loss = 0.042855553328990936\n",
      "tensor([ 0.0002, -0.0006,  0.0050])\n",
      "loss = 0.04282965883612633\n",
      "Iteration 677: b = tensor([ -1.0437,   1.8285, -10.6893], grad_fn=<SubBackward0>), Loss = 0.04282965883612633\n",
      "tensor([ 0.0002, -0.0006,  0.0050])\n",
      "loss = 0.042803823947906494\n",
      "Iteration 678: b = tensor([ -1.0439,   1.8291, -10.6943], grad_fn=<SubBackward0>), Loss = 0.042803823947906494\n",
      "tensor([ 0.0002, -0.0006,  0.0050])\n",
      "loss = 0.04277804121375084\n",
      "Iteration 679: b = tensor([ -1.0441,   1.8297, -10.6994], grad_fn=<SubBackward0>), Loss = 0.04277804121375084\n",
      "tensor([ 0.0002, -0.0006,  0.0050])\n",
      "loss = 0.04275232553482056\n",
      "Iteration 680: b = tensor([ -1.0444,   1.8302, -10.7044], grad_fn=<SubBackward0>), Loss = 0.04275232553482056\n",
      "tensor([ 0.0002, -0.0006,  0.0050])\n",
      "loss = 0.04272664710879326\n",
      "Iteration 681: b = tensor([ -1.0446,   1.8308, -10.7094], grad_fn=<SubBackward0>), Loss = 0.04272664710879326\n",
      "tensor([ 0.0002, -0.0006,  0.0050])\n",
      "loss = 0.042701032012701035\n",
      "Iteration 682: b = tensor([ -1.0448,   1.8314, -10.7144], grad_fn=<SubBackward0>), Loss = 0.042701032012701035\n",
      "tensor([ 0.0002, -0.0006,  0.0050])\n",
      "loss = 0.04267546162009239\n",
      "Iteration 683: b = tensor([ -1.0451,   1.8320, -10.7195], grad_fn=<SubBackward0>), Loss = 0.04267546162009239\n",
      "tensor([ 0.0002, -0.0006,  0.0050])\n",
      "loss = 0.04264996200799942\n",
      "Iteration 684: b = tensor([ -1.0453,   1.8326, -10.7245], grad_fn=<SubBackward0>), Loss = 0.04264996200799942\n",
      "tensor([ 0.0002, -0.0006,  0.0050])\n",
      "loss = 0.042624495923519135\n",
      "Iteration 685: b = tensor([ -1.0455,   1.8332, -10.7295], grad_fn=<SubBackward0>), Loss = 0.042624495923519135\n",
      "tensor([ 0.0002, -0.0006,  0.0050])\n",
      "loss = 0.04259910434484482\n",
      "Iteration 686: b = tensor([ -1.0458,   1.8337, -10.7345], grad_fn=<SubBackward0>), Loss = 0.04259910434484482\n",
      "tensor([ 0.0002, -0.0006,  0.0050])\n",
      "loss = 0.04257375746965408\n",
      "Iteration 687: b = tensor([ -1.0460,   1.8343, -10.7395], grad_fn=<SubBackward0>), Loss = 0.04257375746965408\n",
      "tensor([ 0.0002, -0.0006,  0.0050])\n",
      "loss = 0.042548470199108124\n",
      "Iteration 688: b = tensor([ -1.0462,   1.8349, -10.7444], grad_fn=<SubBackward0>), Loss = 0.042548470199108124\n",
      "tensor([ 0.0002, -0.0006,  0.0050])\n",
      "loss = 0.04252322018146515\n",
      "Iteration 689: b = tensor([ -1.0465,   1.8355, -10.7494], grad_fn=<SubBackward0>), Loss = 0.04252322018146515\n",
      "tensor([ 0.0002, -0.0006,  0.0050])\n",
      "loss = 0.042498037219047546\n",
      "Iteration 690: b = tensor([ -1.0467,   1.8360, -10.7544], grad_fn=<SubBackward0>), Loss = 0.042498037219047546\n",
      "tensor([ 0.0002, -0.0006,  0.0050])\n",
      "loss = 0.042472902685403824\n",
      "Iteration 691: b = tensor([ -1.0469,   1.8366, -10.7594], grad_fn=<SubBackward0>), Loss = 0.042472902685403824\n",
      "tensor([ 0.0002, -0.0006,  0.0050])\n",
      "loss = 0.04244782030582428\n",
      "Iteration 692: b = tensor([ -1.0472,   1.8372, -10.7643], grad_fn=<SubBackward0>), Loss = 0.04244782030582428\n",
      "tensor([ 0.0002, -0.0006,  0.0050])\n",
      "loss = 0.04242279753088951\n",
      "Iteration 693: b = tensor([ -1.0474,   1.8378, -10.7693], grad_fn=<SubBackward0>), Loss = 0.04242279753088951\n",
      "tensor([ 0.0002, -0.0006,  0.0050])\n",
      "loss = 0.042397819459438324\n",
      "Iteration 694: b = tensor([ -1.0476,   1.8383, -10.7743], grad_fn=<SubBackward0>), Loss = 0.042397819459438324\n",
      "tensor([ 0.0002, -0.0006,  0.0050])\n",
      "loss = 0.04237290099263191\n",
      "Iteration 695: b = tensor([ -1.0478,   1.8389, -10.7792], grad_fn=<SubBackward0>), Loss = 0.04237290099263191\n",
      "tensor([ 0.0002, -0.0006,  0.0050])\n",
      "loss = 0.04234801232814789\n",
      "Iteration 696: b = tensor([ -1.0481,   1.8395, -10.7842], grad_fn=<SubBackward0>), Loss = 0.04234801232814789\n",
      "tensor([ 0.0002, -0.0006,  0.0049])\n",
      "loss = 0.042323194444179535\n",
      "Iteration 697: b = tensor([ -1.0483,   1.8400, -10.7891], grad_fn=<SubBackward0>), Loss = 0.042323194444179535\n",
      "tensor([ 0.0002, -0.0006,  0.0049])\n",
      "loss = 0.04229843243956566\n",
      "Iteration 698: b = tensor([ -1.0485,   1.8406, -10.7940], grad_fn=<SubBackward0>), Loss = 0.04229843243956566\n",
      "tensor([ 0.0002, -0.0006,  0.0049])\n",
      "loss = 0.04227370768785477\n",
      "Iteration 699: b = tensor([ -1.0488,   1.8412, -10.7990], grad_fn=<SubBackward0>), Loss = 0.04227370768785477\n",
      "tensor([ 0.0002, -0.0006,  0.0049])\n",
      "loss = 0.04224904626607895\n",
      "Iteration 700: b = tensor([ -1.0490,   1.8417, -10.8039], grad_fn=<SubBackward0>), Loss = 0.04224904626607895\n",
      "tensor([ 0.0002, -0.0006,  0.0049])\n",
      "loss = 0.04222442954778671\n",
      "Iteration 701: b = tensor([ -1.0492,   1.8423, -10.8088], grad_fn=<SubBackward0>), Loss = 0.04222442954778671\n",
      "tensor([ 0.0002, -0.0006,  0.0049])\n",
      "loss = 0.042199861258268356\n",
      "Iteration 702: b = tensor([ -1.0494,   1.8428, -10.8137], grad_fn=<SubBackward0>), Loss = 0.042199861258268356\n",
      "tensor([ 0.0002, -0.0006,  0.0049])\n",
      "loss = 0.04217533767223358\n",
      "Iteration 703: b = tensor([ -1.0496,   1.8434, -10.8186], grad_fn=<SubBackward0>), Loss = 0.04217533767223358\n",
      "tensor([ 0.0002, -0.0006,  0.0049])\n",
      "loss = 0.042150888592004776\n",
      "Iteration 704: b = tensor([ -1.0499,   1.8440, -10.8235], grad_fn=<SubBackward0>), Loss = 0.042150888592004776\n",
      "tensor([ 0.0002, -0.0006,  0.0049])\n",
      "loss = 0.04212646186351776\n",
      "Iteration 705: b = tensor([ -1.0501,   1.8445, -10.8284], grad_fn=<SubBackward0>), Loss = 0.04212646186351776\n",
      "tensor([ 0.0002, -0.0006,  0.0049])\n",
      "loss = 0.04210210591554642\n",
      "Iteration 706: b = tensor([ -1.0503,   1.8451, -10.8333], grad_fn=<SubBackward0>), Loss = 0.04210210591554642\n",
      "tensor([ 0.0002, -0.0006,  0.0049])\n",
      "loss = 0.04207778349518776\n",
      "Iteration 707: b = tensor([ -1.0505,   1.8456, -10.8382], grad_fn=<SubBackward0>), Loss = 0.04207778349518776\n",
      "tensor([ 0.0002, -0.0006,  0.0049])\n",
      "loss = 0.042053524404764175\n",
      "Iteration 708: b = tensor([ -1.0508,   1.8462, -10.8431], grad_fn=<SubBackward0>), Loss = 0.042053524404764175\n",
      "tensor([ 0.0002, -0.0006,  0.0049])\n",
      "loss = 0.042029306292533875\n",
      "Iteration 709: b = tensor([ -1.0510,   1.8467, -10.8480], grad_fn=<SubBackward0>), Loss = 0.042029306292533875\n",
      "tensor([ 0.0002, -0.0006,  0.0049])\n",
      "loss = 0.04200512170791626\n",
      "Iteration 710: b = tensor([ -1.0512,   1.8473, -10.8529], grad_fn=<SubBackward0>), Loss = 0.04200512170791626\n",
      "tensor([ 0.0002, -0.0006,  0.0049])\n",
      "loss = 0.041981011629104614\n",
      "Iteration 711: b = tensor([ -1.0514,   1.8478, -10.8577], grad_fn=<SubBackward0>), Loss = 0.041981011629104614\n",
      "tensor([ 0.0002, -0.0006,  0.0049])\n",
      "loss = 0.04195695370435715\n",
      "Iteration 712: b = tensor([ -1.0516,   1.8484, -10.8626], grad_fn=<SubBackward0>), Loss = 0.04195695370435715\n",
      "tensor([ 0.0002, -0.0006,  0.0049])\n",
      "loss = 0.04193292558193207\n",
      "Iteration 713: b = tensor([ -1.0519,   1.8489, -10.8675], grad_fn=<SubBackward0>), Loss = 0.04193292558193207\n",
      "tensor([ 0.0002, -0.0005,  0.0049])\n",
      "loss = 0.04190896078944206\n",
      "Iteration 714: b = tensor([ -1.0521,   1.8495, -10.8723], grad_fn=<SubBackward0>), Loss = 0.04190896078944206\n",
      "tensor([ 0.0002, -0.0005,  0.0049])\n",
      "loss = 0.04188504070043564\n",
      "Iteration 715: b = tensor([ -1.0523,   1.8500, -10.8772], grad_fn=<SubBackward0>), Loss = 0.04188504070043564\n",
      "tensor([ 0.0002, -0.0005,  0.0049])\n",
      "loss = 0.041861169040203094\n",
      "Iteration 716: b = tensor([ -1.0525,   1.8506, -10.8820], grad_fn=<SubBackward0>), Loss = 0.041861169040203094\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.04183734580874443\n",
      "Iteration 717: b = tensor([ -1.0527,   1.8511, -10.8869], grad_fn=<SubBackward0>), Loss = 0.04183734580874443\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.04181355983018875\n",
      "Iteration 718: b = tensor([ -1.0529,   1.8517, -10.8917], grad_fn=<SubBackward0>), Loss = 0.04181355983018875\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.04178982973098755\n",
      "Iteration 719: b = tensor([ -1.0531,   1.8522, -10.8965], grad_fn=<SubBackward0>), Loss = 0.04178982973098755\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.041766148060560226\n",
      "Iteration 720: b = tensor([ -1.0534,   1.8528, -10.9014], grad_fn=<SubBackward0>), Loss = 0.041766148060560226\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.04174252972006798\n",
      "Iteration 721: b = tensor([ -1.0536,   1.8533, -10.9062], grad_fn=<SubBackward0>), Loss = 0.04174252972006798\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.04171893745660782\n",
      "Iteration 722: b = tensor([ -1.0538,   1.8538, -10.9110], grad_fn=<SubBackward0>), Loss = 0.04171893745660782\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.04169539734721184\n",
      "Iteration 723: b = tensor([ -1.0540,   1.8544, -10.9158], grad_fn=<SubBackward0>), Loss = 0.04169539734721184\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.04167190566658974\n",
      "Iteration 724: b = tensor([ -1.0542,   1.8549, -10.9206], grad_fn=<SubBackward0>), Loss = 0.04167190566658974\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.04164845868945122\n",
      "Iteration 725: b = tensor([ -1.0544,   1.8555, -10.9254], grad_fn=<SubBackward0>), Loss = 0.04164845868945122\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.04162506014108658\n",
      "Iteration 726: b = tensor([ -1.0546,   1.8560, -10.9302], grad_fn=<SubBackward0>), Loss = 0.04162506014108658\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.041601717472076416\n",
      "Iteration 727: b = tensor([ -1.0548,   1.8565, -10.9350], grad_fn=<SubBackward0>), Loss = 0.041601717472076416\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.04157840088009834\n",
      "Iteration 728: b = tensor([ -1.0551,   1.8571, -10.9398], grad_fn=<SubBackward0>), Loss = 0.04157840088009834\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.04155514016747475\n",
      "Iteration 729: b = tensor([ -1.0553,   1.8576, -10.9446], grad_fn=<SubBackward0>), Loss = 0.04155514016747475\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.04153192415833473\n",
      "Iteration 730: b = tensor([ -1.0555,   1.8581, -10.9494], grad_fn=<SubBackward0>), Loss = 0.04153192415833473\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.041508749127388\n",
      "Iteration 731: b = tensor([ -1.0557,   1.8587, -10.9542], grad_fn=<SubBackward0>), Loss = 0.041508749127388\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.041485629975795746\n",
      "Iteration 732: b = tensor([ -1.0559,   1.8592, -10.9589], grad_fn=<SubBackward0>), Loss = 0.041485629975795746\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.04146255925297737\n",
      "Iteration 733: b = tensor([ -1.0561,   1.8597, -10.9637], grad_fn=<SubBackward0>), Loss = 0.04146255925297737\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.04143952578306198\n",
      "Iteration 734: b = tensor([ -1.0563,   1.8602, -10.9685], grad_fn=<SubBackward0>), Loss = 0.04143952578306198\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.041416529566049576\n",
      "Iteration 735: b = tensor([ -1.0565,   1.8608, -10.9732], grad_fn=<SubBackward0>), Loss = 0.041416529566049576\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.04139360040426254\n",
      "Iteration 736: b = tensor([ -1.0567,   1.8613, -10.9780], grad_fn=<SubBackward0>), Loss = 0.04139360040426254\n",
      "tensor([ 0.0002, -0.0005,  0.0048])\n",
      "loss = 0.0413706973195076\n",
      "Iteration 737: b = tensor([ -1.0569,   1.8618, -10.9827], grad_fn=<SubBackward0>), Loss = 0.0413706973195076\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.041347846388816833\n",
      "Iteration 738: b = tensor([ -1.0571,   1.8623, -10.9875], grad_fn=<SubBackward0>), Loss = 0.041347846388816833\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.04132504388689995\n",
      "Iteration 739: b = tensor([ -1.0573,   1.8629, -10.9922], grad_fn=<SubBackward0>), Loss = 0.04132504388689995\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.04130227491259575\n",
      "Iteration 740: b = tensor([ -1.0575,   1.8634, -10.9969], grad_fn=<SubBackward0>), Loss = 0.04130227491259575\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.04127956181764603\n",
      "Iteration 741: b = tensor([ -1.0577,   1.8639, -11.0017], grad_fn=<SubBackward0>), Loss = 0.04127956181764603\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.04125688225030899\n",
      "Iteration 742: b = tensor([ -1.0579,   1.8644, -11.0064], grad_fn=<SubBackward0>), Loss = 0.04125688225030899\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.04123425483703613\n",
      "Iteration 743: b = tensor([ -1.0581,   1.8650, -11.0111], grad_fn=<SubBackward0>), Loss = 0.04123425483703613\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.041211675852537155\n",
      "Iteration 744: b = tensor([ -1.0583,   1.8655, -11.0158], grad_fn=<SubBackward0>), Loss = 0.041211675852537155\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.04118913412094116\n",
      "Iteration 745: b = tensor([ -1.0586,   1.8660, -11.0205], grad_fn=<SubBackward0>), Loss = 0.04118913412094116\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.041166629642248154\n",
      "Iteration 746: b = tensor([ -1.0588,   1.8665, -11.0252], grad_fn=<SubBackward0>), Loss = 0.041166629642248154\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.04114418476819992\n",
      "Iteration 747: b = tensor([ -1.0590,   1.8670, -11.0299], grad_fn=<SubBackward0>), Loss = 0.04114418476819992\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.04112176597118378\n",
      "Iteration 748: b = tensor([ -1.0592,   1.8675, -11.0346], grad_fn=<SubBackward0>), Loss = 0.04112176597118378\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.04109940677881241\n",
      "Iteration 749: b = tensor([ -1.0594,   1.8680, -11.0393], grad_fn=<SubBackward0>), Loss = 0.04109940677881241\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.04107707738876343\n",
      "Iteration 750: b = tensor([ -1.0596,   1.8686, -11.0440], grad_fn=<SubBackward0>), Loss = 0.04107707738876343\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.04105479270219803\n",
      "Iteration 751: b = tensor([ -1.0598,   1.8691, -11.0487], grad_fn=<SubBackward0>), Loss = 0.04105479270219803\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.041032541543245316\n",
      "Iteration 752: b = tensor([ -1.0599,   1.8696, -11.0534], grad_fn=<SubBackward0>), Loss = 0.041032541543245316\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.041010353714227676\n",
      "Iteration 753: b = tensor([ -1.0601,   1.8701, -11.0581], grad_fn=<SubBackward0>), Loss = 0.041010353714227676\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.040988195687532425\n",
      "Iteration 754: b = tensor([ -1.0603,   1.8706, -11.0627], grad_fn=<SubBackward0>), Loss = 0.040988195687532425\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.04096609354019165\n",
      "Iteration 755: b = tensor([ -1.0605,   1.8711, -11.0674], grad_fn=<SubBackward0>), Loss = 0.04096609354019165\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.04094401374459267\n",
      "Iteration 756: b = tensor([ -1.0607,   1.8716, -11.0721], grad_fn=<SubBackward0>), Loss = 0.04094401374459267\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.04092199727892876\n",
      "Iteration 757: b = tensor([ -1.0609,   1.8721, -11.0767], grad_fn=<SubBackward0>), Loss = 0.04092199727892876\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.040900006890296936\n",
      "Iteration 758: b = tensor([ -1.0611,   1.8726, -11.0814], grad_fn=<SubBackward0>), Loss = 0.040900006890296936\n",
      "tensor([ 0.0002, -0.0005,  0.0047])\n",
      "loss = 0.0408780574798584\n",
      "Iteration 759: b = tensor([ -1.0613,   1.8731, -11.0860], grad_fn=<SubBackward0>), Loss = 0.0408780574798584\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.040856171399354935\n",
      "Iteration 760: b = tensor([ -1.0615,   1.8736, -11.0907], grad_fn=<SubBackward0>), Loss = 0.040856171399354935\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.04083429276943207\n",
      "Iteration 761: b = tensor([ -1.0617,   1.8741, -11.0953], grad_fn=<SubBackward0>), Loss = 0.04083429276943207\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.040812477469444275\n",
      "Iteration 762: b = tensor([ -1.0619,   1.8746, -11.1000], grad_fn=<SubBackward0>), Loss = 0.040812477469444275\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.040790706872940063\n",
      "Iteration 763: b = tensor([ -1.0621,   1.8751, -11.1046], grad_fn=<SubBackward0>), Loss = 0.040790706872940063\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.04076896980404854\n",
      "Iteration 764: b = tensor([ -1.0623,   1.8756, -11.1092], grad_fn=<SubBackward0>), Loss = 0.04076896980404854\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.040747273713350296\n",
      "Iteration 765: b = tensor([ -1.0625,   1.8761, -11.1138], grad_fn=<SubBackward0>), Loss = 0.040747273713350296\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.04072561860084534\n",
      "Iteration 766: b = tensor([ -1.0627,   1.8766, -11.1185], grad_fn=<SubBackward0>), Loss = 0.04072561860084534\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.04070401191711426\n",
      "Iteration 767: b = tensor([ -1.0629,   1.8771, -11.1231], grad_fn=<SubBackward0>), Loss = 0.04070401191711426\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.04068243131041527\n",
      "Iteration 768: b = tensor([ -1.0631,   1.8776, -11.1277], grad_fn=<SubBackward0>), Loss = 0.04068243131041527\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.04066089540719986\n",
      "Iteration 769: b = tensor([ -1.0632,   1.8781, -11.1323], grad_fn=<SubBackward0>), Loss = 0.04066089540719986\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.04063941165804863\n",
      "Iteration 770: b = tensor([ -1.0634,   1.8786, -11.1369], grad_fn=<SubBackward0>), Loss = 0.04063941165804863\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.040617961436510086\n",
      "Iteration 771: b = tensor([ -1.0636,   1.8791, -11.1415], grad_fn=<SubBackward0>), Loss = 0.040617961436510086\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.04059654474258423\n",
      "Iteration 772: b = tensor([ -1.0638,   1.8796, -11.1461], grad_fn=<SubBackward0>), Loss = 0.04059654474258423\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.040575165301561356\n",
      "Iteration 773: b = tensor([ -1.0640,   1.8801, -11.1507], grad_fn=<SubBackward0>), Loss = 0.040575165301561356\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.04055384173989296\n",
      "Iteration 774: b = tensor([ -1.0642,   1.8806, -11.1553], grad_fn=<SubBackward0>), Loss = 0.04055384173989296\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.04053254425525665\n",
      "Iteration 775: b = tensor([ -1.0644,   1.8811, -11.1598], grad_fn=<SubBackward0>), Loss = 0.04053254425525665\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.04051128774881363\n",
      "Iteration 776: b = tensor([ -1.0646,   1.8816, -11.1644], grad_fn=<SubBackward0>), Loss = 0.04051128774881363\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.040490083396434784\n",
      "Iteration 777: b = tensor([ -1.0648,   1.8820, -11.1690], grad_fn=<SubBackward0>), Loss = 0.040490083396434784\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.040468912571668625\n",
      "Iteration 778: b = tensor([ -1.0649,   1.8825, -11.1736], grad_fn=<SubBackward0>), Loss = 0.040468912571668625\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.040447767823934555\n",
      "Iteration 779: b = tensor([ -1.0651,   1.8830, -11.1781], grad_fn=<SubBackward0>), Loss = 0.040447767823934555\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.040426671504974365\n",
      "Iteration 780: b = tensor([ -1.0653,   1.8835, -11.1827], grad_fn=<SubBackward0>), Loss = 0.040426671504974365\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.04040561243891716\n",
      "Iteration 781: b = tensor([ -1.0655,   1.8840, -11.1872], grad_fn=<SubBackward0>), Loss = 0.04040561243891716\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.04038459062576294\n",
      "Iteration 782: b = tensor([ -1.0657,   1.8845, -11.1918], grad_fn=<SubBackward0>), Loss = 0.04038459062576294\n",
      "tensor([ 0.0002, -0.0005,  0.0046])\n",
      "loss = 0.040363628417253494\n",
      "Iteration 783: b = tensor([ -1.0659,   1.8850, -11.1963], grad_fn=<SubBackward0>), Loss = 0.040363628417253494\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.04034268483519554\n",
      "Iteration 784: b = tensor([ -1.0660,   1.8854, -11.2009], grad_fn=<SubBackward0>), Loss = 0.04034268483519554\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.040321774780750275\n",
      "Iteration 785: b = tensor([ -1.0662,   1.8859, -11.2054], grad_fn=<SubBackward0>), Loss = 0.040321774780750275\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.04030091315507889\n",
      "Iteration 786: b = tensor([ -1.0664,   1.8864, -11.2100], grad_fn=<SubBackward0>), Loss = 0.04030091315507889\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.04028008505702019\n",
      "Iteration 787: b = tensor([ -1.0666,   1.8869, -11.2145], grad_fn=<SubBackward0>), Loss = 0.04028008505702019\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.04025930538773537\n",
      "Iteration 788: b = tensor([ -1.0668,   1.8874, -11.2190], grad_fn=<SubBackward0>), Loss = 0.04025930538773537\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.04023854807019234\n",
      "Iteration 789: b = tensor([ -1.0670,   1.8878, -11.2235], grad_fn=<SubBackward0>), Loss = 0.04023854807019234\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.040217846632003784\n",
      "Iteration 790: b = tensor([ -1.0671,   1.8883, -11.2281], grad_fn=<SubBackward0>), Loss = 0.040217846632003784\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.040197160094976425\n",
      "Iteration 791: b = tensor([ -1.0673,   1.8888, -11.2326], grad_fn=<SubBackward0>), Loss = 0.040197160094976425\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.040176525712013245\n",
      "Iteration 792: b = tensor([ -1.0675,   1.8893, -11.2371], grad_fn=<SubBackward0>), Loss = 0.040176525712013245\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.04015593230724335\n",
      "Iteration 793: b = tensor([ -1.0677,   1.8897, -11.2416], grad_fn=<SubBackward0>), Loss = 0.04015593230724335\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.04013536125421524\n",
      "Iteration 794: b = tensor([ -1.0679,   1.8902, -11.2461], grad_fn=<SubBackward0>), Loss = 0.04013536125421524\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.040114834904670715\n",
      "Iteration 795: b = tensor([ -1.0680,   1.8907, -11.2506], grad_fn=<SubBackward0>), Loss = 0.040114834904670715\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.04009435325860977\n",
      "Iteration 796: b = tensor([ -1.0682,   1.8912, -11.2551], grad_fn=<SubBackward0>), Loss = 0.04009435325860977\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.04007390886545181\n",
      "Iteration 797: b = tensor([ -1.0684,   1.8916, -11.2596], grad_fn=<SubBackward0>), Loss = 0.04007390886545181\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.040053486824035645\n",
      "Iteration 798: b = tensor([ -1.0686,   1.8921, -11.2641], grad_fn=<SubBackward0>), Loss = 0.040053486824035645\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.04003310948610306\n",
      "Iteration 799: b = tensor([ -1.0687,   1.8926, -11.2686], grad_fn=<SubBackward0>), Loss = 0.04003310948610306\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.04001278057694435\n",
      "Iteration 800: b = tensor([ -1.0689,   1.8930, -11.2730], grad_fn=<SubBackward0>), Loss = 0.04001278057694435\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.03999247029423714\n",
      "Iteration 801: b = tensor([ -1.0691,   1.8935, -11.2775], grad_fn=<SubBackward0>), Loss = 0.03999247029423714\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.039972204715013504\n",
      "Iteration 802: b = tensor([ -1.0693,   1.8940, -11.2820], grad_fn=<SubBackward0>), Loss = 0.039972204715013504\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.03995197266340256\n",
      "Iteration 803: b = tensor([ -1.0694,   1.8944, -11.2864], grad_fn=<SubBackward0>), Loss = 0.03995197266340256\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.03993179276585579\n",
      "Iteration 804: b = tensor([ -1.0696,   1.8949, -11.2909], grad_fn=<SubBackward0>), Loss = 0.03993179276585579\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.039911624044179916\n",
      "Iteration 805: b = tensor([ -1.0698,   1.8954, -11.2954], grad_fn=<SubBackward0>), Loss = 0.039911624044179916\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.03989150747656822\n",
      "Iteration 806: b = tensor([ -1.0700,   1.8958, -11.2998], grad_fn=<SubBackward0>), Loss = 0.03989150747656822\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.03987141698598862\n",
      "Iteration 807: b = tensor([ -1.0701,   1.8963, -11.3043], grad_fn=<SubBackward0>), Loss = 0.03987141698598862\n",
      "tensor([ 0.0002, -0.0005,  0.0045])\n",
      "loss = 0.0398513562977314\n",
      "Iteration 808: b = tensor([ -1.0703,   1.8967, -11.3087], grad_fn=<SubBackward0>), Loss = 0.0398513562977314\n",
      "tensor([ 0.0002, -0.0005,  0.0044])\n",
      "loss = 0.039831358939409256\n",
      "Iteration 809: b = tensor([ -1.0705,   1.8972, -11.3132], grad_fn=<SubBackward0>), Loss = 0.039831358939409256\n",
      "tensor([ 0.0002, -0.0005,  0.0044])\n",
      "loss = 0.039811376482248306\n",
      "Iteration 810: b = tensor([ -1.0707,   1.8977, -11.3176], grad_fn=<SubBackward0>), Loss = 0.039811376482248306\n",
      "tensor([ 0.0002, -0.0005,  0.0044])\n",
      "loss = 0.03979143500328064\n",
      "Iteration 811: b = tensor([ -1.0708,   1.8981, -11.3220], grad_fn=<SubBackward0>), Loss = 0.03979143500328064\n",
      "tensor([ 0.0002, -0.0005,  0.0044])\n",
      "loss = 0.03977153077721596\n",
      "Iteration 812: b = tensor([ -1.0710,   1.8986, -11.3265], grad_fn=<SubBackward0>), Loss = 0.03977153077721596\n",
      "tensor([ 0.0002, -0.0005,  0.0044])\n",
      "loss = 0.039751652628183365\n",
      "Iteration 813: b = tensor([ -1.0712,   1.8990, -11.3309], grad_fn=<SubBackward0>), Loss = 0.039751652628183365\n",
      "tensor([ 0.0002, -0.0005,  0.0044])\n",
      "loss = 0.039731819182634354\n",
      "Iteration 814: b = tensor([ -1.0713,   1.8995, -11.3353], grad_fn=<SubBackward0>), Loss = 0.039731819182634354\n",
      "tensor([ 0.0002, -0.0005,  0.0044])\n",
      "loss = 0.03971201553940773\n",
      "Iteration 815: b = tensor([ -1.0715,   1.9000, -11.3397], grad_fn=<SubBackward0>), Loss = 0.03971201553940773\n",
      "tensor([ 0.0002, -0.0005,  0.0044])\n",
      "loss = 0.03969224542379379\n",
      "Iteration 816: b = tensor([ -1.0717,   1.9004, -11.3442], grad_fn=<SubBackward0>), Loss = 0.03969224542379379\n",
      "tensor([ 0.0002, -0.0005,  0.0044])\n",
      "loss = 0.03967251628637314\n",
      "Iteration 817: b = tensor([ -1.0719,   1.9009, -11.3486], grad_fn=<SubBackward0>), Loss = 0.03967251628637314\n",
      "tensor([ 0.0002, -0.0005,  0.0044])\n",
      "loss = 0.03965282440185547\n",
      "Iteration 818: b = tensor([ -1.0720,   1.9013, -11.3530], grad_fn=<SubBackward0>), Loss = 0.03965282440185547\n",
      "tensor([ 0.0002, -0.0005,  0.0044])\n",
      "loss = 0.039633166044950485\n",
      "Iteration 819: b = tensor([ -1.0722,   1.9018, -11.3574], grad_fn=<SubBackward0>), Loss = 0.039633166044950485\n",
      "tensor([ 0.0002, -0.0005,  0.0044])\n",
      "loss = 0.03961353003978729\n",
      "Iteration 820: b = tensor([ -1.0724,   1.9022, -11.3618], grad_fn=<SubBackward0>), Loss = 0.03961353003978729\n",
      "tensor([ 0.0002, -0.0005,  0.0044])\n",
      "loss = 0.039593927562236786\n",
      "Iteration 821: b = tensor([ -1.0725,   1.9027, -11.3662], grad_fn=<SubBackward0>), Loss = 0.039593927562236786\n",
      "tensor([ 0.0002, -0.0005,  0.0044])\n",
      "loss = 0.03957437351346016\n",
      "Iteration 822: b = tensor([ -1.0727,   1.9031, -11.3706], grad_fn=<SubBackward0>), Loss = 0.03957437351346016\n",
      "tensor([ 0.0002, -0.0005,  0.0044])\n",
      "loss = 0.03955485671758652\n",
      "Iteration 823: b = tensor([ -1.0729,   1.9036, -11.3750], grad_fn=<SubBackward0>), Loss = 0.03955485671758652\n",
      "tensor([ 0.0002, -0.0004,  0.0044])\n",
      "loss = 0.03953535482287407\n",
      "Iteration 824: b = tensor([ -1.0730,   1.9040, -11.3794], grad_fn=<SubBackward0>), Loss = 0.03953535482287407\n",
      "tensor([ 0.0002, -0.0004,  0.0044])\n",
      "loss = 0.0395159013569355\n",
      "Iteration 825: b = tensor([ -1.0732,   1.9045, -11.3837], grad_fn=<SubBackward0>), Loss = 0.0395159013569355\n",
      "tensor([ 0.0002, -0.0004,  0.0044])\n",
      "loss = 0.03949647769331932\n",
      "Iteration 826: b = tensor([ -1.0734,   1.9049, -11.3881], grad_fn=<SubBackward0>), Loss = 0.03949647769331932\n",
      "tensor([ 0.0002, -0.0004,  0.0044])\n",
      "loss = 0.039477091282606125\n",
      "Iteration 827: b = tensor([ -1.0735,   1.9054, -11.3925], grad_fn=<SubBackward0>), Loss = 0.039477091282606125\n",
      "tensor([ 0.0002, -0.0004,  0.0044])\n",
      "loss = 0.03945772722363472\n",
      "Iteration 828: b = tensor([ -1.0737,   1.9058, -11.3969], grad_fn=<SubBackward0>), Loss = 0.03945772722363472\n",
      "tensor([ 0.0002, -0.0004,  0.0044])\n",
      "loss = 0.03943841531872749\n",
      "Iteration 829: b = tensor([ -1.0739,   1.9062, -11.4012], grad_fn=<SubBackward0>), Loss = 0.03943841531872749\n",
      "tensor([ 0.0002, -0.0004,  0.0044])\n",
      "loss = 0.03941912204027176\n",
      "Iteration 830: b = tensor([ -1.0740,   1.9067, -11.4056], grad_fn=<SubBackward0>), Loss = 0.03941912204027176\n",
      "tensor([ 0.0002, -0.0004,  0.0044])\n",
      "loss = 0.039399873465299606\n",
      "Iteration 831: b = tensor([ -1.0742,   1.9071, -11.4100], grad_fn=<SubBackward0>), Loss = 0.039399873465299606\n",
      "tensor([ 0.0002, -0.0004,  0.0044])\n",
      "loss = 0.03938065096735954\n",
      "Iteration 832: b = tensor([ -1.0743,   1.9076, -11.4143], grad_fn=<SubBackward0>), Loss = 0.03938065096735954\n",
      "tensor([ 0.0002, -0.0004,  0.0044])\n",
      "loss = 0.03936145454645157\n",
      "Iteration 833: b = tensor([ -1.0745,   1.9080, -11.4187], grad_fn=<SubBackward0>), Loss = 0.03936145454645157\n",
      "tensor([ 0.0002, -0.0004,  0.0044])\n",
      "loss = 0.03934229910373688\n",
      "Iteration 834: b = tensor([ -1.0747,   1.9085, -11.4230], grad_fn=<SubBackward0>), Loss = 0.03934229910373688\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.03932318836450577\n",
      "Iteration 835: b = tensor([ -1.0748,   1.9089, -11.4274], grad_fn=<SubBackward0>), Loss = 0.03932318836450577\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.03930407762527466\n",
      "Iteration 836: b = tensor([ -1.0750,   1.9093, -11.4317], grad_fn=<SubBackward0>), Loss = 0.03930407762527466\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.039285026490688324\n",
      "Iteration 837: b = tensor([ -1.0752,   1.9098, -11.4360], grad_fn=<SubBackward0>), Loss = 0.039285026490688324\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.039266012609004974\n",
      "Iteration 838: b = tensor([ -1.0753,   1.9102, -11.4404], grad_fn=<SubBackward0>), Loss = 0.039266012609004974\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.03924701735377312\n",
      "Iteration 839: b = tensor([ -1.0755,   1.9107, -11.4447], grad_fn=<SubBackward0>), Loss = 0.03924701735377312\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.03922805190086365\n",
      "Iteration 840: b = tensor([ -1.0756,   1.9111, -11.4490], grad_fn=<SubBackward0>), Loss = 0.03922805190086365\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.039209116250276566\n",
      "Iteration 841: b = tensor([ -1.0758,   1.9115, -11.4533], grad_fn=<SubBackward0>), Loss = 0.039209116250276566\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.03919023275375366\n",
      "Iteration 842: b = tensor([ -1.0760,   1.9120, -11.4577], grad_fn=<SubBackward0>), Loss = 0.03919023275375366\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.03917137533426285\n",
      "Iteration 843: b = tensor([ -1.0761,   1.9124, -11.4620], grad_fn=<SubBackward0>), Loss = 0.03917137533426285\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.03915254399180412\n",
      "Iteration 844: b = tensor([ -1.0763,   1.9128, -11.4663], grad_fn=<SubBackward0>), Loss = 0.03915254399180412\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.03913373872637749\n",
      "Iteration 845: b = tensor([ -1.0764,   1.9133, -11.4706], grad_fn=<SubBackward0>), Loss = 0.03913373872637749\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.039114974439144135\n",
      "Iteration 846: b = tensor([ -1.0766,   1.9137, -11.4749], grad_fn=<SubBackward0>), Loss = 0.039114974439144135\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.03909624367952347\n",
      "Iteration 847: b = tensor([ -1.0767,   1.9141, -11.4792], grad_fn=<SubBackward0>), Loss = 0.03909624367952347\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.03907754272222519\n",
      "Iteration 848: b = tensor([ -1.0769,   1.9145, -11.4835], grad_fn=<SubBackward0>), Loss = 0.03907754272222519\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.0390588715672493\n",
      "Iteration 849: b = tensor([ -1.0771,   1.9150, -11.4878], grad_fn=<SubBackward0>), Loss = 0.0390588715672493\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.03904023393988609\n",
      "Iteration 850: b = tensor([ -1.0772,   1.9154, -11.4921], grad_fn=<SubBackward0>), Loss = 0.03904023393988609\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.03902162238955498\n",
      "Iteration 851: b = tensor([ -1.0774,   1.9158, -11.4964], grad_fn=<SubBackward0>), Loss = 0.03902162238955498\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.039003048092126846\n",
      "Iteration 852: b = tensor([ -1.0775,   1.9163, -11.5007], grad_fn=<SubBackward0>), Loss = 0.039003048092126846\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.038984496146440506\n",
      "Iteration 853: b = tensor([ -1.0777,   1.9167, -11.5049], grad_fn=<SubBackward0>), Loss = 0.038984496146440506\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.03896598890423775\n",
      "Iteration 854: b = tensor([ -1.0778,   1.9171, -11.5092], grad_fn=<SubBackward0>), Loss = 0.03896598890423775\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.03894750028848648\n",
      "Iteration 855: b = tensor([ -1.0780,   1.9175, -11.5135], grad_fn=<SubBackward0>), Loss = 0.03894750028848648\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.0389290489256382\n",
      "Iteration 856: b = tensor([ -1.0781,   1.9180, -11.5178], grad_fn=<SubBackward0>), Loss = 0.0389290489256382\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.0389106422662735\n",
      "Iteration 857: b = tensor([ -1.0783,   1.9184, -11.5220], grad_fn=<SubBackward0>), Loss = 0.0389106422662735\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.03889225050806999\n",
      "Iteration 858: b = tensor([ -1.0784,   1.9188, -11.5263], grad_fn=<SubBackward0>), Loss = 0.03889225050806999\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.038873884826898575\n",
      "Iteration 859: b = tensor([ -1.0786,   1.9192, -11.5305], grad_fn=<SubBackward0>), Loss = 0.038873884826898575\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.03885556384921074\n",
      "Iteration 860: b = tensor([ -1.0788,   1.9196, -11.5348], grad_fn=<SubBackward0>), Loss = 0.03885556384921074\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.038837261497974396\n",
      "Iteration 861: b = tensor([ -1.0789,   1.9201, -11.5391], grad_fn=<SubBackward0>), Loss = 0.038837261497974396\n",
      "tensor([ 0.0002, -0.0004,  0.0043])\n",
      "loss = 0.03881899639964104\n",
      "Iteration 862: b = tensor([ -1.0791,   1.9205, -11.5433], grad_fn=<SubBackward0>), Loss = 0.03881899639964104\n",
      "tensor([ 0.0002, -0.0004,  0.0042])\n",
      "loss = 0.038800761103630066\n",
      "Iteration 863: b = tensor([ -1.0792,   1.9209, -11.5475], grad_fn=<SubBackward0>), Loss = 0.038800761103630066\n",
      "tensor([ 0.0002, -0.0004,  0.0042])\n",
      "loss = 0.038782548159360886\n",
      "Iteration 864: b = tensor([ -1.0794,   1.9213, -11.5518], grad_fn=<SubBackward0>), Loss = 0.038782548159360886\n",
      "tensor([ 0.0002, -0.0004,  0.0042])\n",
      "loss = 0.03876437246799469\n",
      "Iteration 865: b = tensor([ -1.0795,   1.9217, -11.5560], grad_fn=<SubBackward0>), Loss = 0.03876437246799469\n",
      "tensor([ 0.0002, -0.0004,  0.0042])\n",
      "loss = 0.03874622657895088\n",
      "Iteration 866: b = tensor([ -1.0797,   1.9222, -11.5603], grad_fn=<SubBackward0>), Loss = 0.03874622657895088\n",
      "tensor([ 0.0002, -0.0004,  0.0042])\n",
      "loss = 0.03872810676693916\n",
      "Iteration 867: b = tensor([ -1.0798,   1.9226, -11.5645], grad_fn=<SubBackward0>), Loss = 0.03872810676693916\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.03871002793312073\n",
      "Iteration 868: b = tensor([ -1.0800,   1.9230, -11.5687], grad_fn=<SubBackward0>), Loss = 0.03871002793312073\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.03869197517633438\n",
      "Iteration 869: b = tensor([ -1.0801,   1.9234, -11.5729], grad_fn=<SubBackward0>), Loss = 0.03869197517633438\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.038673944771289825\n",
      "Iteration 870: b = tensor([ -1.0803,   1.9238, -11.5772], grad_fn=<SubBackward0>), Loss = 0.038673944771289825\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.038655947893857956\n",
      "Iteration 871: b = tensor([ -1.0804,   1.9242, -11.5814], grad_fn=<SubBackward0>), Loss = 0.038655947893857956\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.03863798826932907\n",
      "Iteration 872: b = tensor([ -1.0806,   1.9246, -11.5856], grad_fn=<SubBackward0>), Loss = 0.03863798826932907\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.03862004354596138\n",
      "Iteration 873: b = tensor([ -1.0807,   1.9251, -11.5898], grad_fn=<SubBackward0>), Loss = 0.03862004354596138\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.03860214725136757\n",
      "Iteration 874: b = tensor([ -1.0808,   1.9255, -11.5940], grad_fn=<SubBackward0>), Loss = 0.03860214725136757\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.038584258407354355\n",
      "Iteration 875: b = tensor([ -1.0810,   1.9259, -11.5982], grad_fn=<SubBackward0>), Loss = 0.038584258407354355\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.03856641799211502\n",
      "Iteration 876: b = tensor([ -1.0811,   1.9263, -11.6024], grad_fn=<SubBackward0>), Loss = 0.03856641799211502\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.03854859992861748\n",
      "Iteration 877: b = tensor([ -1.0813,   1.9267, -11.6066], grad_fn=<SubBackward0>), Loss = 0.03854859992861748\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.038530804216861725\n",
      "Iteration 878: b = tensor([ -1.0814,   1.9271, -11.6108], grad_fn=<SubBackward0>), Loss = 0.038530804216861725\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.03851303830742836\n",
      "Iteration 879: b = tensor([ -1.0816,   1.9275, -11.6150], grad_fn=<SubBackward0>), Loss = 0.03851303830742836\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.03849530592560768\n",
      "Iteration 880: b = tensor([ -1.0817,   1.9279, -11.6192], grad_fn=<SubBackward0>), Loss = 0.03849530592560768\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.03847759962081909\n",
      "Iteration 881: b = tensor([ -1.0819,   1.9283, -11.6234], grad_fn=<SubBackward0>), Loss = 0.03847759962081909\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.03845992684364319\n",
      "Iteration 882: b = tensor([ -1.0820,   1.9287, -11.6275], grad_fn=<SubBackward0>), Loss = 0.03845992684364319\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.038442280143499374\n",
      "Iteration 883: b = tensor([ -1.0822,   1.9291, -11.6317], grad_fn=<SubBackward0>), Loss = 0.038442280143499374\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.038424666970968246\n",
      "Iteration 884: b = tensor([ -1.0823,   1.9295, -11.6359], grad_fn=<SubBackward0>), Loss = 0.038424666970968246\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.03840707987546921\n",
      "Iteration 885: b = tensor([ -1.0824,   1.9299, -11.6401], grad_fn=<SubBackward0>), Loss = 0.03840707987546921\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.03838951140642166\n",
      "Iteration 886: b = tensor([ -1.0826,   1.9303, -11.6442], grad_fn=<SubBackward0>), Loss = 0.03838951140642166\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.038371991366147995\n",
      "Iteration 887: b = tensor([ -1.0827,   1.9308, -11.6484], grad_fn=<SubBackward0>), Loss = 0.038371991366147995\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.03835448622703552\n",
      "Iteration 888: b = tensor([ -1.0829,   1.9312, -11.6525], grad_fn=<SubBackward0>), Loss = 0.03835448622703552\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.03833701089024544\n",
      "Iteration 889: b = tensor([ -1.0830,   1.9316, -11.6567], grad_fn=<SubBackward0>), Loss = 0.03833701089024544\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.03831956535577774\n",
      "Iteration 890: b = tensor([ -1.0832,   1.9320, -11.6608], grad_fn=<SubBackward0>), Loss = 0.03831956535577774\n",
      "tensor([ 0.0001, -0.0004,  0.0042])\n",
      "loss = 0.03830214962363243\n",
      "Iteration 891: b = tensor([ -1.0833,   1.9324, -11.6650], grad_fn=<SubBackward0>), Loss = 0.03830214962363243\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03828476369380951\n",
      "Iteration 892: b = tensor([ -1.0834,   1.9328, -11.6691], grad_fn=<SubBackward0>), Loss = 0.03828476369380951\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03826738893985748\n",
      "Iteration 893: b = tensor([ -1.0836,   1.9331, -11.6733], grad_fn=<SubBackward0>), Loss = 0.03826738893985748\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03825005516409874\n",
      "Iteration 894: b = tensor([ -1.0837,   1.9335, -11.6774], grad_fn=<SubBackward0>), Loss = 0.03825005516409874\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03823273628950119\n",
      "Iteration 895: b = tensor([ -1.0839,   1.9339, -11.6816], grad_fn=<SubBackward0>), Loss = 0.03823273628950119\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03821546211838722\n",
      "Iteration 896: b = tensor([ -1.0840,   1.9343, -11.6857], grad_fn=<SubBackward0>), Loss = 0.03821546211838722\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03819822147488594\n",
      "Iteration 897: b = tensor([ -1.0841,   1.9347, -11.6898], grad_fn=<SubBackward0>), Loss = 0.03819822147488594\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.038180992007255554\n",
      "Iteration 898: b = tensor([ -1.0843,   1.9351, -11.6940], grad_fn=<SubBackward0>), Loss = 0.038180992007255554\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03816379979252815\n",
      "Iteration 899: b = tensor([ -1.0844,   1.9355, -11.6981], grad_fn=<SubBackward0>), Loss = 0.03816379979252815\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03814662620425224\n",
      "Iteration 900: b = tensor([ -1.0846,   1.9359, -11.7022], grad_fn=<SubBackward0>), Loss = 0.03814662620425224\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03812948241829872\n",
      "Iteration 901: b = tensor([ -1.0847,   1.9363, -11.7063], grad_fn=<SubBackward0>), Loss = 0.03812948241829872\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.038112372159957886\n",
      "Iteration 902: b = tensor([ -1.0848,   1.9367, -11.7104], grad_fn=<SubBackward0>), Loss = 0.038112372159957886\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03809529170393944\n",
      "Iteration 903: b = tensor([ -1.0850,   1.9371, -11.7145], grad_fn=<SubBackward0>), Loss = 0.03809529170393944\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.038078226149082184\n",
      "Iteration 904: b = tensor([ -1.0851,   1.9375, -11.7186], grad_fn=<SubBackward0>), Loss = 0.038078226149082184\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03806119039654732\n",
      "Iteration 905: b = tensor([ -1.0852,   1.9379, -11.7227], grad_fn=<SubBackward0>), Loss = 0.03806119039654732\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03804418817162514\n",
      "Iteration 906: b = tensor([ -1.0854,   1.9383, -11.7268], grad_fn=<SubBackward0>), Loss = 0.03804418817162514\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.038027212023735046\n",
      "Iteration 907: b = tensor([ -1.0855,   1.9386, -11.7309], grad_fn=<SubBackward0>), Loss = 0.038027212023735046\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03801025450229645\n",
      "Iteration 908: b = tensor([ -1.0856,   1.9390, -11.7350], grad_fn=<SubBackward0>), Loss = 0.03801025450229645\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.037993330508470535\n",
      "Iteration 909: b = tensor([ -1.0858,   1.9394, -11.7391], grad_fn=<SubBackward0>), Loss = 0.037993330508470535\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03797643259167671\n",
      "Iteration 910: b = tensor([ -1.0859,   1.9398, -11.7432], grad_fn=<SubBackward0>), Loss = 0.03797643259167671\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03795955330133438\n",
      "Iteration 911: b = tensor([ -1.0860,   1.9402, -11.7473], grad_fn=<SubBackward0>), Loss = 0.03795955330133438\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.037942711263895035\n",
      "Iteration 912: b = tensor([ -1.0862,   1.9406, -11.7514], grad_fn=<SubBackward0>), Loss = 0.037942711263895035\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03792588785290718\n",
      "Iteration 913: b = tensor([ -1.0863,   1.9410, -11.7555], grad_fn=<SubBackward0>), Loss = 0.03792588785290718\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.037909090518951416\n",
      "Iteration 914: b = tensor([ -1.0864,   1.9414, -11.7595], grad_fn=<SubBackward0>), Loss = 0.037909090518951416\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03789232671260834\n",
      "Iteration 915: b = tensor([ -1.0866,   1.9417, -11.7636], grad_fn=<SubBackward0>), Loss = 0.03789232671260834\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.037875592708587646\n",
      "Iteration 916: b = tensor([ -1.0867,   1.9421, -11.7677], grad_fn=<SubBackward0>), Loss = 0.037875592708587646\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.037858862429857254\n",
      "Iteration 917: b = tensor([ -1.0868,   1.9425, -11.7717], grad_fn=<SubBackward0>), Loss = 0.037858862429857254\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03784218803048134\n",
      "Iteration 918: b = tensor([ -1.0870,   1.9429, -11.7758], grad_fn=<SubBackward0>), Loss = 0.03784218803048134\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03782552853226662\n",
      "Iteration 919: b = tensor([ -1.0871,   1.9433, -11.7799], grad_fn=<SubBackward0>), Loss = 0.03782552853226662\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03780888393521309\n",
      "Iteration 920: b = tensor([ -1.0872,   1.9436, -11.7839], grad_fn=<SubBackward0>), Loss = 0.03780888393521309\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.037792280316352844\n",
      "Iteration 921: b = tensor([ -1.0874,   1.9440, -11.7880], grad_fn=<SubBackward0>), Loss = 0.037792280316352844\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03777569532394409\n",
      "Iteration 922: b = tensor([ -1.0875,   1.9444, -11.7920], grad_fn=<SubBackward0>), Loss = 0.03777569532394409\n",
      "tensor([ 0.0001, -0.0004,  0.0041])\n",
      "loss = 0.03775912895798683\n",
      "Iteration 923: b = tensor([ -1.0876,   1.9448, -11.7961], grad_fn=<SubBackward0>), Loss = 0.03775912895798683\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03774259611964226\n",
      "Iteration 924: b = tensor([ -1.0878,   1.9452, -11.8001], grad_fn=<SubBackward0>), Loss = 0.03774259611964226\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03772609308362007\n",
      "Iteration 925: b = tensor([ -1.0879,   1.9455, -11.8042], grad_fn=<SubBackward0>), Loss = 0.03772609308362007\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03770962357521057\n",
      "Iteration 926: b = tensor([ -1.0880,   1.9459, -11.8082], grad_fn=<SubBackward0>), Loss = 0.03770962357521057\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03769316151738167\n",
      "Iteration 927: b = tensor([ -1.0882,   1.9463, -11.8122], grad_fn=<SubBackward0>), Loss = 0.03769316151738167\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03767671808600426\n",
      "Iteration 928: b = tensor([ -1.0883,   1.9467, -11.8163], grad_fn=<SubBackward0>), Loss = 0.03767671808600426\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03766031563282013\n",
      "Iteration 929: b = tensor([ -1.0884,   1.9470, -11.8203], grad_fn=<SubBackward0>), Loss = 0.03766031563282013\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.037643931806087494\n",
      "Iteration 930: b = tensor([ -1.0885,   1.9474, -11.8243], grad_fn=<SubBackward0>), Loss = 0.037643931806087494\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.037627581506967545\n",
      "Iteration 931: b = tensor([ -1.0887,   1.9478, -11.8283], grad_fn=<SubBackward0>), Loss = 0.037627581506967545\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03761124983429909\n",
      "Iteration 932: b = tensor([ -1.0888,   1.9482, -11.8324], grad_fn=<SubBackward0>), Loss = 0.03761124983429909\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03759494423866272\n",
      "Iteration 933: b = tensor([ -1.0889,   1.9485, -11.8364], grad_fn=<SubBackward0>), Loss = 0.03759494423866272\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03757866472005844\n",
      "Iteration 934: b = tensor([ -1.0890,   1.9489, -11.8404], grad_fn=<SubBackward0>), Loss = 0.03757866472005844\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03756241872906685\n",
      "Iteration 935: b = tensor([ -1.0892,   1.9493, -11.8444], grad_fn=<SubBackward0>), Loss = 0.03756241872906685\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03754618391394615\n",
      "Iteration 936: b = tensor([ -1.0893,   1.9496, -11.8484], grad_fn=<SubBackward0>), Loss = 0.03754618391394615\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03752998262643814\n",
      "Iteration 937: b = tensor([ -1.0894,   1.9500, -11.8524], grad_fn=<SubBackward0>), Loss = 0.03752998262643814\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.037513796240091324\n",
      "Iteration 938: b = tensor([ -1.0896,   1.9504, -11.8564], grad_fn=<SubBackward0>), Loss = 0.037513796240091324\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.037497635930776596\n",
      "Iteration 939: b = tensor([ -1.0897,   1.9507, -11.8604], grad_fn=<SubBackward0>), Loss = 0.037497635930776596\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03748150169849396\n",
      "Iteration 940: b = tensor([ -1.0898,   1.9511, -11.8644], grad_fn=<SubBackward0>), Loss = 0.03748150169849396\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.0374654121696949\n",
      "Iteration 941: b = tensor([ -1.0899,   1.9515, -11.8684], grad_fn=<SubBackward0>), Loss = 0.0374654121696949\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03744932636618614\n",
      "Iteration 942: b = tensor([ -1.0901,   1.9518, -11.8724], grad_fn=<SubBackward0>), Loss = 0.03744932636618614\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03743327036499977\n",
      "Iteration 943: b = tensor([ -1.0902,   1.9522, -11.8764], grad_fn=<SubBackward0>), Loss = 0.03743327036499977\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03741723671555519\n",
      "Iteration 944: b = tensor([ -1.0903,   1.9526, -11.8804], grad_fn=<SubBackward0>), Loss = 0.03741723671555519\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.0374012254178524\n",
      "Iteration 945: b = tensor([ -1.0904,   1.9529, -11.8843], grad_fn=<SubBackward0>), Loss = 0.0374012254178524\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.0373852364718914\n",
      "Iteration 946: b = tensor([ -1.0905,   1.9533, -11.8883], grad_fn=<SubBackward0>), Loss = 0.0373852364718914\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.037369273602962494\n",
      "Iteration 947: b = tensor([ -1.0907,   1.9537, -11.8923], grad_fn=<SubBackward0>), Loss = 0.037369273602962494\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03735334426164627\n",
      "Iteration 948: b = tensor([ -1.0908,   1.9540, -11.8963], grad_fn=<SubBackward0>), Loss = 0.03735334426164627\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03733744099736214\n",
      "Iteration 949: b = tensor([ -1.0909,   1.9544, -11.9002], grad_fn=<SubBackward0>), Loss = 0.03733744099736214\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.0373215489089489\n",
      "Iteration 950: b = tensor([ -1.0910,   1.9548, -11.9042], grad_fn=<SubBackward0>), Loss = 0.0373215489089489\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03730568662285805\n",
      "Iteration 951: b = tensor([ -1.0912,   1.9551, -11.9082], grad_fn=<SubBackward0>), Loss = 0.03730568662285805\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03728983923792839\n",
      "Iteration 952: b = tensor([ -1.0913,   1.9555, -11.9121], grad_fn=<SubBackward0>), Loss = 0.03728983923792839\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.037274036556482315\n",
      "Iteration 953: b = tensor([ -1.0914,   1.9558, -11.9161], grad_fn=<SubBackward0>), Loss = 0.037274036556482315\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03725823014974594\n",
      "Iteration 954: b = tensor([ -1.0915,   1.9562, -11.9200], grad_fn=<SubBackward0>), Loss = 0.03725823014974594\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03724245727062225\n",
      "Iteration 955: b = tensor([ -1.0916,   1.9566, -11.9240], grad_fn=<SubBackward0>), Loss = 0.03724245727062225\n",
      "tensor([ 0.0001, -0.0004,  0.0040])\n",
      "loss = 0.03722671419382095\n",
      "Iteration 956: b = tensor([ -1.0918,   1.9569, -11.9279], grad_fn=<SubBackward0>), Loss = 0.03722671419382095\n",
      "tensor([ 0.0001, -0.0004,  0.0039])\n",
      "loss = 0.037210993468761444\n",
      "Iteration 957: b = tensor([ -1.0919,   1.9573, -11.9319], grad_fn=<SubBackward0>), Loss = 0.037210993468761444\n",
      "tensor([ 0.0001, -0.0004,  0.0039])\n",
      "loss = 0.03719528764486313\n",
      "Iteration 958: b = tensor([ -1.0920,   1.9576, -11.9358], grad_fn=<SubBackward0>), Loss = 0.03719528764486313\n",
      "tensor([ 0.0001, -0.0004,  0.0039])\n",
      "loss = 0.0371796153485775\n",
      "Iteration 959: b = tensor([ -1.0921,   1.9580, -11.9398], grad_fn=<SubBackward0>), Loss = 0.0371796153485775\n",
      "tensor([ 0.0001, -0.0004,  0.0039])\n",
      "loss = 0.03716397285461426\n",
      "Iteration 960: b = tensor([ -1.0922,   1.9583, -11.9437], grad_fn=<SubBackward0>), Loss = 0.03716397285461426\n",
      "tensor([ 0.0001, -0.0004,  0.0039])\n",
      "loss = 0.03714834526181221\n",
      "Iteration 961: b = tensor([ -1.0924,   1.9587, -11.9476], grad_fn=<SubBackward0>), Loss = 0.03714834526181221\n",
      "tensor([ 0.0001, -0.0004,  0.0039])\n",
      "loss = 0.037132736295461655\n",
      "Iteration 962: b = tensor([ -1.0925,   1.9590, -11.9516], grad_fn=<SubBackward0>), Loss = 0.037132736295461655\n",
      "tensor([ 0.0001, -0.0004,  0.0039])\n",
      "loss = 0.03711714595556259\n",
      "Iteration 963: b = tensor([ -1.0926,   1.9594, -11.9555], grad_fn=<SubBackward0>), Loss = 0.03711714595556259\n",
      "tensor([ 0.0001, -0.0004,  0.0039])\n",
      "loss = 0.03710160404443741\n",
      "Iteration 964: b = tensor([ -1.0927,   1.9598, -11.9594], grad_fn=<SubBackward0>), Loss = 0.03710160404443741\n",
      "tensor([ 0.0001, -0.0004,  0.0039])\n",
      "loss = 0.03708605840802193\n",
      "Iteration 965: b = tensor([ -1.0928,   1.9601, -11.9633], grad_fn=<SubBackward0>), Loss = 0.03708605840802193\n",
      "tensor([ 0.0001, -0.0004,  0.0039])\n",
      "loss = 0.03707055374979973\n",
      "Iteration 966: b = tensor([ -1.0929,   1.9605, -11.9672], grad_fn=<SubBackward0>), Loss = 0.03707055374979973\n",
      "tensor([ 0.0001, -0.0004,  0.0039])\n",
      "loss = 0.03705505654215813\n",
      "Iteration 967: b = tensor([ -1.0931,   1.9608, -11.9712], grad_fn=<SubBackward0>), Loss = 0.03705505654215813\n",
      "tensor([ 0.0001, -0.0004,  0.0039])\n",
      "loss = 0.03703959286212921\n",
      "Iteration 968: b = tensor([ -1.0932,   1.9612, -11.9751], grad_fn=<SubBackward0>), Loss = 0.03703959286212921\n",
      "tensor([ 0.0001, -0.0004,  0.0039])\n",
      "loss = 0.03702414408326149\n",
      "Iteration 969: b = tensor([ -1.0933,   1.9615, -11.9790], grad_fn=<SubBackward0>), Loss = 0.03702414408326149\n",
      "tensor([ 0.0001, -0.0004,  0.0039])\n",
      "loss = 0.03700873255729675\n",
      "Iteration 970: b = tensor([ -1.0934,   1.9619, -11.9829], grad_fn=<SubBackward0>), Loss = 0.03700873255729675\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.03699333593249321\n",
      "Iteration 971: b = tensor([ -1.0935,   1.9622, -11.9868], grad_fn=<SubBackward0>), Loss = 0.03699333593249321\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.03697795793414116\n",
      "Iteration 972: b = tensor([ -1.0936,   1.9626, -11.9907], grad_fn=<SubBackward0>), Loss = 0.03697795793414116\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.0369626060128212\n",
      "Iteration 973: b = tensor([ -1.0938,   1.9629, -11.9946], grad_fn=<SubBackward0>), Loss = 0.0369626060128212\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.03694727644324303\n",
      "Iteration 974: b = tensor([ -1.0939,   1.9633, -11.9985], grad_fn=<SubBackward0>), Loss = 0.03694727644324303\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.036931972950696945\n",
      "Iteration 975: b = tensor([ -1.0940,   1.9636, -12.0024], grad_fn=<SubBackward0>), Loss = 0.036931972950696945\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.036916691809892654\n",
      "Iteration 976: b = tensor([ -1.0941,   1.9640, -12.0063], grad_fn=<SubBackward0>), Loss = 0.036916691809892654\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.036901433020830154\n",
      "Iteration 977: b = tensor([ -1.0942,   1.9643, -12.0102], grad_fn=<SubBackward0>), Loss = 0.036901433020830154\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.03688618913292885\n",
      "Iteration 978: b = tensor([ -1.0943,   1.9646, -12.0140], grad_fn=<SubBackward0>), Loss = 0.03688618913292885\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.03687097504734993\n",
      "Iteration 979: b = tensor([ -1.0944,   1.9650, -12.0179], grad_fn=<SubBackward0>), Loss = 0.03687097504734993\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.03685575723648071\n",
      "Iteration 980: b = tensor([ -1.0946,   1.9653, -12.0218], grad_fn=<SubBackward0>), Loss = 0.03685575723648071\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.036840591579675674\n",
      "Iteration 981: b = tensor([ -1.0947,   1.9657, -12.0257], grad_fn=<SubBackward0>), Loss = 0.036840591579675674\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.03682543709874153\n",
      "Iteration 982: b = tensor([ -1.0948,   1.9660, -12.0296], grad_fn=<SubBackward0>), Loss = 0.03682543709874153\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.03681030869483948\n",
      "Iteration 983: b = tensor([ -1.0949,   1.9664, -12.0334], grad_fn=<SubBackward0>), Loss = 0.03681030869483948\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.036795202642679214\n",
      "Iteration 984: b = tensor([ -1.0950,   1.9667, -12.0373], grad_fn=<SubBackward0>), Loss = 0.036795202642679214\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.03678010776638985\n",
      "Iteration 985: b = tensor([ -1.0951,   1.9670, -12.0412], grad_fn=<SubBackward0>), Loss = 0.03678010776638985\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.036765050143003464\n",
      "Iteration 986: b = tensor([ -1.0952,   1.9674, -12.0450], grad_fn=<SubBackward0>), Loss = 0.036765050143003464\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.03675001114606857\n",
      "Iteration 987: b = tensor([ -1.0953,   1.9677, -12.0489], grad_fn=<SubBackward0>), Loss = 0.03675001114606857\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.036734990775585175\n",
      "Iteration 988: b = tensor([ -1.0954,   1.9681, -12.0527], grad_fn=<SubBackward0>), Loss = 0.036734990775585175\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.03671999275684357\n",
      "Iteration 989: b = tensor([ -1.0956,   1.9684, -12.0566], grad_fn=<SubBackward0>), Loss = 0.03671999275684357\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.036705005913972855\n",
      "Iteration 990: b = tensor([ -1.0957,   1.9687, -12.0604], grad_fn=<SubBackward0>), Loss = 0.036705005913972855\n",
      "tensor([ 0.0001, -0.0003,  0.0039])\n",
      "loss = 0.03669005632400513\n",
      "Iteration 991: b = tensor([ -1.0958,   1.9691, -12.0643], grad_fn=<SubBackward0>), Loss = 0.03669005632400513\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.036675117909908295\n",
      "Iteration 992: b = tensor([ -1.0959,   1.9694, -12.0681], grad_fn=<SubBackward0>), Loss = 0.036675117909908295\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.03666020557284355\n",
      "Iteration 993: b = tensor([ -1.0960,   1.9698, -12.0720], grad_fn=<SubBackward0>), Loss = 0.03666020557284355\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.0366453118622303\n",
      "Iteration 994: b = tensor([ -1.0961,   1.9701, -12.0758], grad_fn=<SubBackward0>), Loss = 0.0366453118622303\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.03663043677806854\n",
      "Iteration 995: b = tensor([ -1.0962,   1.9704, -12.0797], grad_fn=<SubBackward0>), Loss = 0.03663043677806854\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.03661559522151947\n",
      "Iteration 996: b = tensor([ -1.0963,   1.9708, -12.0835], grad_fn=<SubBackward0>), Loss = 0.03661559522151947\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.03660076856613159\n",
      "Iteration 997: b = tensor([ -1.0964,   1.9711, -12.0873], grad_fn=<SubBackward0>), Loss = 0.03660076856613159\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.0365859679877758\n",
      "Iteration 998: b = tensor([ -1.0965,   1.9714, -12.0912], grad_fn=<SubBackward0>), Loss = 0.0365859679877758\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.03657118231058121\n",
      "Iteration 999: b = tensor([ -1.0966,   1.9718, -12.0950], grad_fn=<SubBackward0>), Loss = 0.03657118231058121\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.0365564227104187\n",
      "Iteration 1000: b = tensor([ -1.0967,   1.9721, -12.0988], grad_fn=<SubBackward0>), Loss = 0.0365564227104187\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.03654167801141739\n",
      "Iteration 1001: b = tensor([ -1.0969,   1.9724, -12.1026], grad_fn=<SubBackward0>), Loss = 0.03654167801141739\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.036526959389448166\n",
      "Iteration 1002: b = tensor([ -1.0970,   1.9728, -12.1065], grad_fn=<SubBackward0>), Loss = 0.036526959389448166\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.03651225566864014\n",
      "Iteration 1003: b = tensor([ -1.0971,   1.9731, -12.1103], grad_fn=<SubBackward0>), Loss = 0.03651225566864014\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.0364975742995739\n",
      "Iteration 1004: b = tensor([ -1.0972,   1.9734, -12.1141], grad_fn=<SubBackward0>), Loss = 0.0364975742995739\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.03648291155695915\n",
      "Iteration 1005: b = tensor([ -1.0973,   1.9738, -12.1179], grad_fn=<SubBackward0>), Loss = 0.03648291155695915\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.036468274891376495\n",
      "Iteration 1006: b = tensor([ -1.0974,   1.9741, -12.1217], grad_fn=<SubBackward0>), Loss = 0.036468274891376495\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.03645366057753563\n",
      "Iteration 1007: b = tensor([ -1.0975,   1.9744, -12.1255], grad_fn=<SubBackward0>), Loss = 0.03645366057753563\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.036439064890146255\n",
      "Iteration 1008: b = tensor([ -1.0976,   1.9747, -12.1293], grad_fn=<SubBackward0>), Loss = 0.036439064890146255\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.036424484103918076\n",
      "Iteration 1009: b = tensor([ -1.0977,   1.9751, -12.1331], grad_fn=<SubBackward0>), Loss = 0.036424484103918076\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.036409929394721985\n",
      "Iteration 1010: b = tensor([ -1.0978,   1.9754, -12.1369], grad_fn=<SubBackward0>), Loss = 0.036409929394721985\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.036395393311977386\n",
      "Iteration 1011: b = tensor([ -1.0979,   1.9757, -12.1407], grad_fn=<SubBackward0>), Loss = 0.036395393311977386\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.03638088330626488\n",
      "Iteration 1012: b = tensor([ -1.0980,   1.9761, -12.1445], grad_fn=<SubBackward0>), Loss = 0.03638088330626488\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.03636639937758446\n",
      "Iteration 1013: b = tensor([ -1.0981,   1.9764, -12.1483], grad_fn=<SubBackward0>), Loss = 0.03636639937758446\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.036351922899484634\n",
      "Iteration 1014: b = tensor([ -1.0982,   1.9767, -12.1521], grad_fn=<SubBackward0>), Loss = 0.036351922899484634\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.0363374724984169\n",
      "Iteration 1015: b = tensor([ -1.0983,   1.9770, -12.1559], grad_fn=<SubBackward0>), Loss = 0.0363374724984169\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.03632304444909096\n",
      "Iteration 1016: b = tensor([ -1.0984,   1.9774, -12.1596], grad_fn=<SubBackward0>), Loss = 0.03632304444909096\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.03630862757563591\n",
      "Iteration 1017: b = tensor([ -1.0985,   1.9777, -12.1634], grad_fn=<SubBackward0>), Loss = 0.03630862757563591\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.03629423677921295\n",
      "Iteration 1018: b = tensor([ -1.0986,   1.9780, -12.1672], grad_fn=<SubBackward0>), Loss = 0.03629423677921295\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.036279864609241486\n",
      "Iteration 1019: b = tensor([ -1.0987,   1.9783, -12.1710], grad_fn=<SubBackward0>), Loss = 0.036279864609241486\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.036265503615140915\n",
      "Iteration 1020: b = tensor([ -1.0988,   1.9786, -12.1747], grad_fn=<SubBackward0>), Loss = 0.036265503615140915\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.03625117614865303\n",
      "Iteration 1021: b = tensor([ -1.0989,   1.9790, -12.1785], grad_fn=<SubBackward0>), Loss = 0.03625117614865303\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.03623686358332634\n",
      "Iteration 1022: b = tensor([ -1.0990,   1.9793, -12.1823], grad_fn=<SubBackward0>), Loss = 0.03623686358332634\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.03622257709503174\n",
      "Iteration 1023: b = tensor([ -1.0991,   1.9796, -12.1860], grad_fn=<SubBackward0>), Loss = 0.03622257709503174\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.03620830178260803\n",
      "Iteration 1024: b = tensor([ -1.0992,   1.9799, -12.1898], grad_fn=<SubBackward0>), Loss = 0.03620830178260803\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.036194056272506714\n",
      "Iteration 1025: b = tensor([ -1.0993,   1.9803, -12.1936], grad_fn=<SubBackward0>), Loss = 0.036194056272506714\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.03617982193827629\n",
      "Iteration 1026: b = tensor([ -1.0994,   1.9806, -12.1973], grad_fn=<SubBackward0>), Loss = 0.03617982193827629\n",
      "tensor([ 0.0001, -0.0003,  0.0038])\n",
      "loss = 0.03616560623049736\n",
      "Iteration 1027: b = tensor([ -1.0995,   1.9809, -12.2011], grad_fn=<SubBackward0>), Loss = 0.03616560623049736\n",
      "tensor([ 9.9923e-05, -3.1890e-04,  3.7530e-03])\n",
      "loss = 0.036151427775621414\n",
      "Iteration 1028: b = tensor([ -1.0996,   1.9812, -12.2048], grad_fn=<SubBackward0>), Loss = 0.036151427775621414\n",
      "tensor([ 9.9656e-05, -3.1839e-04,  3.7505e-03])\n",
      "loss = 0.03613725304603577\n",
      "Iteration 1029: b = tensor([ -1.0997,   1.9815, -12.2086], grad_fn=<SubBackward0>), Loss = 0.03613725304603577\n",
      "tensor([ 9.9395e-05, -3.1788e-04,  3.7479e-03])\n",
      "loss = 0.03612309694290161\n",
      "Iteration 1030: b = tensor([ -1.0998,   1.9818, -12.2123], grad_fn=<SubBackward0>), Loss = 0.03612309694290161\n",
      "tensor([ 9.9130e-05, -3.1737e-04,  3.7453e-03])\n",
      "loss = 0.03610895946621895\n",
      "Iteration 1031: b = tensor([ -1.0999,   1.9822, -12.2161], grad_fn=<SubBackward0>), Loss = 0.03610895946621895\n",
      "tensor([ 9.8868e-05, -3.1686e-04,  3.7428e-03])\n",
      "loss = 0.03609484061598778\n",
      "Iteration 1032: b = tensor([ -1.1000,   1.9825, -12.2198], grad_fn=<SubBackward0>), Loss = 0.03609484061598778\n",
      "tensor([ 9.8611e-05, -3.1635e-04,  3.7402e-03])\n",
      "loss = 0.036080747842788696\n",
      "Iteration 1033: b = tensor([ -1.1001,   1.9828, -12.2235], grad_fn=<SubBackward0>), Loss = 0.036080747842788696\n",
      "tensor([ 9.8351e-05, -3.1585e-04,  3.7377e-03])\n",
      "loss = 0.03606666997075081\n",
      "Iteration 1034: b = tensor([ -1.1002,   1.9831, -12.2273], grad_fn=<SubBackward0>), Loss = 0.03606666997075081\n",
      "tensor([ 9.8090e-05, -3.1534e-04,  3.7351e-03])\n",
      "loss = 0.03605261817574501\n",
      "Iteration 1035: b = tensor([ -1.1003,   1.9834, -12.2310], grad_fn=<SubBackward0>), Loss = 0.03605261817574501\n",
      "tensor([ 9.7830e-05, -3.1484e-04,  3.7326e-03])\n",
      "loss = 0.036038581281900406\n",
      "Iteration 1036: b = tensor([ -1.1004,   1.9837, -12.2347], grad_fn=<SubBackward0>), Loss = 0.036038581281900406\n",
      "tensor([ 9.7568e-05, -3.1433e-04,  3.7300e-03])\n",
      "loss = 0.03602456673979759\n",
      "Iteration 1037: b = tensor([ -1.1005,   1.9841, -12.2385], grad_fn=<SubBackward0>), Loss = 0.03602456673979759\n",
      "tensor([ 9.7316e-05, -3.1383e-04,  3.7275e-03])\n",
      "loss = 0.03601057082414627\n",
      "Iteration 1038: b = tensor([ -1.1006,   1.9844, -12.2422], grad_fn=<SubBackward0>), Loss = 0.03601057082414627\n",
      "tensor([ 9.7058e-05, -3.1332e-04,  3.7249e-03])\n",
      "loss = 0.03599659726023674\n",
      "Iteration 1039: b = tensor([ -1.1007,   1.9847, -12.2459], grad_fn=<SubBackward0>), Loss = 0.03599659726023674\n",
      "tensor([ 9.6797e-05, -3.1282e-04,  3.7224e-03])\n",
      "loss = 0.035982631146907806\n",
      "Iteration 1040: b = tensor([ -1.1008,   1.9850, -12.2496], grad_fn=<SubBackward0>), Loss = 0.035982631146907806\n",
      "tensor([ 9.6544e-05, -3.1232e-04,  3.7199e-03])\n",
      "loss = 0.03596869111061096\n",
      "Iteration 1041: b = tensor([ -1.1009,   1.9853, -12.2533], grad_fn=<SubBackward0>), Loss = 0.03596869111061096\n",
      "tensor([ 9.6284e-05, -3.1183e-04,  3.7174e-03])\n",
      "loss = 0.03595477342605591\n",
      "Iteration 1042: b = tensor([ -1.1010,   1.9856, -12.2571], grad_fn=<SubBackward0>), Loss = 0.03595477342605591\n",
      "tensor([ 9.6030e-05, -3.1133e-04,  3.7148e-03])\n",
      "loss = 0.03594087436795235\n",
      "Iteration 1043: b = tensor([ -1.1011,   1.9859, -12.2608], grad_fn=<SubBackward0>), Loss = 0.03594087436795235\n",
      "tensor([ 9.5775e-05, -3.1083e-04,  3.7123e-03])\n",
      "loss = 0.03592698648571968\n",
      "Iteration 1044: b = tensor([ -1.1012,   1.9862, -12.2645], grad_fn=<SubBackward0>), Loss = 0.03592698648571968\n",
      "tensor([ 9.5516e-05, -3.1033e-04,  3.7098e-03])\n",
      "loss = 0.035913124680519104\n",
      "Iteration 1045: b = tensor([ -1.1013,   1.9865, -12.2682], grad_fn=<SubBackward0>), Loss = 0.035913124680519104\n",
      "tensor([ 9.5263e-05, -3.0984e-04,  3.7073e-03])\n",
      "loss = 0.03589927405118942\n",
      "Iteration 1046: b = tensor([ -1.1014,   1.9869, -12.2719], grad_fn=<SubBackward0>), Loss = 0.03589927405118942\n",
      "tensor([ 9.5011e-05, -3.0934e-04,  3.7048e-03])\n",
      "loss = 0.03588545322418213\n",
      "Iteration 1047: b = tensor([ -1.1015,   1.9872, -12.2756], grad_fn=<SubBackward0>), Loss = 0.03588545322418213\n",
      "tensor([ 9.4757e-05, -3.0885e-04,  3.7023e-03])\n",
      "loss = 0.03587164357304573\n",
      "Iteration 1048: b = tensor([ -1.1016,   1.9875, -12.2793], grad_fn=<SubBackward0>), Loss = 0.03587164357304573\n",
      "tensor([ 9.4505e-05, -3.0836e-04,  3.6998e-03])\n",
      "loss = 0.03585786372423172\n",
      "Iteration 1049: b = tensor([ -1.1017,   1.9878, -12.2830], grad_fn=<SubBackward0>), Loss = 0.03585786372423172\n",
      "tensor([ 9.4249e-05, -3.0787e-04,  3.6973e-03])\n",
      "loss = 0.035844091325998306\n",
      "Iteration 1050: b = tensor([ -1.1018,   1.9881, -12.2867], grad_fn=<SubBackward0>), Loss = 0.035844091325998306\n",
      "tensor([ 9.3997e-05, -3.0738e-04,  3.6949e-03])\n",
      "loss = 0.035830333828926086\n",
      "Iteration 1051: b = tensor([ -1.1019,   1.9884, -12.2904], grad_fn=<SubBackward0>), Loss = 0.035830333828926086\n",
      "tensor([ 9.3746e-05, -3.0689e-04,  3.6924e-03])\n",
      "loss = 0.035816606134176254\n",
      "Iteration 1052: b = tensor([ -1.1020,   1.9887, -12.2941], grad_fn=<SubBackward0>), Loss = 0.035816606134176254\n",
      "tensor([ 9.3496e-05, -3.0640e-04,  3.6899e-03])\n",
      "loss = 0.035802897065877914\n",
      "Iteration 1053: b = tensor([ -1.1020,   1.9890, -12.2978], grad_fn=<SubBackward0>), Loss = 0.035802897065877914\n",
      "tensor([ 9.3244e-05, -3.0591e-04,  3.6874e-03])\n",
      "loss = 0.03578919917345047\n",
      "Iteration 1054: b = tensor([ -1.1021,   1.9893, -12.3014], grad_fn=<SubBackward0>), Loss = 0.03578919917345047\n",
      "tensor([ 9.2993e-05, -3.0543e-04,  3.6850e-03])\n",
      "loss = 0.035775523632764816\n",
      "Iteration 1055: b = tensor([ -1.1022,   1.9896, -12.3051], grad_fn=<SubBackward0>), Loss = 0.035775523632764816\n",
      "tensor([ 9.2743e-05, -3.0494e-04,  3.6825e-03])\n",
      "loss = 0.03576185926795006\n",
      "Iteration 1056: b = tensor([ -1.1023,   1.9899, -12.3088], grad_fn=<SubBackward0>), Loss = 0.03576185926795006\n",
      "tensor([ 9.2496e-05, -3.0445e-04,  3.6800e-03])\n",
      "loss = 0.03574821725487709\n",
      "Iteration 1057: b = tensor([ -1.1024,   1.9902, -12.3125], grad_fn=<SubBackward0>), Loss = 0.03574821725487709\n",
      "tensor([ 9.2248e-05, -3.0397e-04,  3.6776e-03])\n",
      "loss = 0.035734593868255615\n",
      "Iteration 1058: b = tensor([ -1.1025,   1.9905, -12.3162], grad_fn=<SubBackward0>), Loss = 0.035734593868255615\n",
      "tensor([ 9.2000e-05, -3.0349e-04,  3.6751e-03])\n",
      "loss = 0.035721004009246826\n",
      "Iteration 1059: b = tensor([ -1.1026,   1.9908, -12.3198], grad_fn=<SubBackward0>), Loss = 0.035721004009246826\n",
      "tensor([ 9.1752e-05, -3.0301e-04,  3.6727e-03])\n",
      "loss = 0.035707417875528336\n",
      "Iteration 1060: b = tensor([ -1.1027,   1.9911, -12.3235], grad_fn=<SubBackward0>), Loss = 0.035707417875528336\n",
      "tensor([ 9.1505e-05, -3.0252e-04,  3.6703e-03])\n",
      "loss = 0.035693854093551636\n",
      "Iteration 1061: b = tensor([ -1.1028,   1.9914, -12.3272], grad_fn=<SubBackward0>), Loss = 0.035693854093551636\n",
      "tensor([ 9.1256e-05, -3.0204e-04,  3.6678e-03])\n",
      "loss = 0.03568029776215553\n",
      "Iteration 1062: b = tensor([ -1.1029,   1.9917, -12.3308], grad_fn=<SubBackward0>), Loss = 0.03568029776215553\n",
      "tensor([ 9.1008e-05, -3.0157e-04,  3.6654e-03])\n",
      "loss = 0.03566677123308182\n",
      "Iteration 1063: b = tensor([ -1.1030,   1.9920, -12.3345], grad_fn=<SubBackward0>), Loss = 0.03566677123308182\n",
      "tensor([ 9.0764e-05, -3.0109e-04,  3.6629e-03])\n",
      "loss = 0.0356532521545887\n",
      "Iteration 1064: b = tensor([ -1.1031,   1.9923, -12.3382], grad_fn=<SubBackward0>), Loss = 0.0356532521545887\n",
      "tensor([ 9.0521e-05, -3.0061e-04,  3.6605e-03])\n",
      "loss = 0.03563975915312767\n",
      "Iteration 1065: b = tensor([ -1.1031,   1.9926, -12.3418], grad_fn=<SubBackward0>), Loss = 0.03563975915312767\n",
      "tensor([ 9.0277e-05, -3.0013e-04,  3.6581e-03])\n",
      "loss = 0.03562629222869873\n",
      "Iteration 1066: b = tensor([ -1.1032,   1.9929, -12.3455], grad_fn=<SubBackward0>), Loss = 0.03562629222869873\n",
      "tensor([ 9.0035e-05, -2.9965e-04,  3.6557e-03])\n",
      "loss = 0.03561283275485039\n",
      "Iteration 1067: b = tensor([ -1.1033,   1.9932, -12.3491], grad_fn=<SubBackward0>), Loss = 0.03561283275485039\n",
      "tensor([ 8.9793e-05, -2.9918e-04,  3.6533e-03])\n",
      "loss = 0.035599395632743835\n",
      "Iteration 1068: b = tensor([ -1.1034,   1.9935, -12.3528], grad_fn=<SubBackward0>), Loss = 0.035599395632743835\n",
      "tensor([ 8.9552e-05, -2.9870e-04,  3.6508e-03])\n",
      "loss = 0.035585980862379074\n",
      "Iteration 1069: b = tensor([ -1.1035,   1.9938, -12.3564], grad_fn=<SubBackward0>), Loss = 0.035585980862379074\n",
      "tensor([ 8.9308e-05, -2.9823e-04,  3.6484e-03])\n",
      "loss = 0.03557256609201431\n",
      "Iteration 1070: b = tensor([ -1.1036,   1.9941, -12.3601], grad_fn=<SubBackward0>), Loss = 0.03557256609201431\n",
      "tensor([ 8.9066e-05, -2.9776e-04,  3.6460e-03])\n",
      "loss = 0.03555918484926224\n",
      "Iteration 1071: b = tensor([ -1.1037,   1.9944, -12.3637], grad_fn=<SubBackward0>), Loss = 0.03555918484926224\n",
      "tensor([ 8.8827e-05, -2.9729e-04,  3.6436e-03])\n",
      "loss = 0.03554581478238106\n",
      "Iteration 1072: b = tensor([ -1.1038,   1.9947, -12.3674], grad_fn=<SubBackward0>), Loss = 0.03554581478238106\n",
      "tensor([ 8.8584e-05, -2.9682e-04,  3.6412e-03])\n",
      "loss = 0.03553245961666107\n",
      "Iteration 1073: b = tensor([ -1.1039,   1.9950, -12.3710], grad_fn=<SubBackward0>), Loss = 0.03553245961666107\n",
      "tensor([ 8.8343e-05, -2.9635e-04,  3.6388e-03])\n",
      "loss = 0.035519134253263474\n",
      "Iteration 1074: b = tensor([ -1.1039,   1.9953, -12.3746], grad_fn=<SubBackward0>), Loss = 0.035519134253263474\n",
      "tensor([ 8.8105e-05, -2.9588e-04,  3.6365e-03])\n",
      "loss = 0.03550581634044647\n",
      "Iteration 1075: b = tensor([ -1.1040,   1.9956, -12.3783], grad_fn=<SubBackward0>), Loss = 0.03550581634044647\n",
      "tensor([ 8.7863e-05, -2.9541e-04,  3.6341e-03])\n",
      "loss = 0.03549252450466156\n",
      "Iteration 1076: b = tensor([ -1.1041,   1.9959, -12.3819], grad_fn=<SubBackward0>), Loss = 0.03549252450466156\n",
      "tensor([ 8.7623e-05, -2.9495e-04,  3.6317e-03])\n",
      "loss = 0.03547924384474754\n",
      "Iteration 1077: b = tensor([ -1.1042,   1.9962, -12.3855], grad_fn=<SubBackward0>), Loss = 0.03547924384474754\n",
      "tensor([ 8.7382e-05, -2.9448e-04,  3.6293e-03])\n",
      "loss = 0.03546598181128502\n",
      "Iteration 1078: b = tensor([ -1.1043,   1.9965, -12.3891], grad_fn=<SubBackward0>), Loss = 0.03546598181128502\n",
      "tensor([ 8.7143e-05, -2.9402e-04,  3.6269e-03])\n",
      "loss = 0.03545272350311279\n",
      "Iteration 1079: b = tensor([ -1.1044,   1.9968, -12.3928], grad_fn=<SubBackward0>), Loss = 0.03545272350311279\n",
      "tensor([ 8.6905e-05, -2.9355e-04,  3.6246e-03])\n",
      "loss = 0.03543950989842415\n",
      "Iteration 1080: b = tensor([ -1.1045,   1.9971, -12.3964], grad_fn=<SubBackward0>), Loss = 0.03543950989842415\n",
      "tensor([ 8.6667e-05, -2.9309e-04,  3.6222e-03])\n",
      "loss = 0.035426292568445206\n",
      "Iteration 1081: b = tensor([ -1.1046,   1.9974, -12.4000], grad_fn=<SubBackward0>), Loss = 0.035426292568445206\n",
      "tensor([ 8.6428e-05, -2.9263e-04,  3.6198e-03])\n",
      "loss = 0.03541310504078865\n",
      "Iteration 1082: b = tensor([ -1.1046,   1.9977, -12.4036], grad_fn=<SubBackward0>), Loss = 0.03541310504078865\n",
      "tensor([ 8.6192e-05, -2.9217e-04,  3.6175e-03])\n",
      "loss = 0.03539993241429329\n",
      "Iteration 1083: b = tensor([ -1.1047,   1.9980, -12.4072], grad_fn=<SubBackward0>), Loss = 0.03539993241429329\n",
      "tensor([ 8.5955e-05, -2.9171e-04,  3.6151e-03])\n",
      "loss = 0.03538677468895912\n",
      "Iteration 1084: b = tensor([ -1.1048,   1.9983, -12.4109], grad_fn=<SubBackward0>), Loss = 0.03538677468895912\n",
      "tensor([ 8.5719e-05, -2.9125e-04,  3.6128e-03])\n",
      "loss = 0.03537362813949585\n",
      "Iteration 1085: b = tensor([ -1.1049,   1.9985, -12.4145], grad_fn=<SubBackward0>), Loss = 0.03537362813949585\n",
      "tensor([ 8.5481e-05, -2.9079e-04,  3.6104e-03])\n",
      "loss = 0.03536050394177437\n",
      "Iteration 1086: b = tensor([ -1.1050,   1.9988, -12.4181], grad_fn=<SubBackward0>), Loss = 0.03536050394177437\n",
      "tensor([ 8.5250e-05, -2.9033e-04,  3.6081e-03])\n",
      "loss = 0.03534739837050438\n",
      "Iteration 1087: b = tensor([ -1.1051,   1.9991, -12.4217], grad_fn=<SubBackward0>), Loss = 0.03534739837050438\n",
      "tensor([ 8.5014e-05, -2.8988e-04,  3.6058e-03])\n",
      "loss = 0.03533432260155678\n",
      "Iteration 1088: b = tensor([ -1.1052,   1.9994, -12.4253], grad_fn=<SubBackward0>), Loss = 0.03533432260155678\n",
      "tensor([ 8.4778e-05, -2.8942e-04,  3.6034e-03])\n",
      "loss = 0.03532124683260918\n",
      "Iteration 1089: b = tensor([ -1.1052,   1.9997, -12.4289], grad_fn=<SubBackward0>), Loss = 0.03532124683260918\n",
      "tensor([ 8.4545e-05, -2.8896e-04,  3.6011e-03])\n",
      "loss = 0.03530818969011307\n",
      "Iteration 1090: b = tensor([ -1.1053,   2.0000, -12.4325], grad_fn=<SubBackward0>), Loss = 0.03530818969011307\n",
      "tensor([ 8.4313e-05, -2.8851e-04,  3.5988e-03])\n",
      "loss = 0.03529514744877815\n",
      "Iteration 1091: b = tensor([ -1.1054,   2.0003, -12.4361], grad_fn=<SubBackward0>), Loss = 0.03529514744877815\n",
      "tensor([ 8.4083e-05, -2.8806e-04,  3.5964e-03])\n",
      "loss = 0.03528213128447533\n",
      "Iteration 1092: b = tensor([ -1.1055,   2.0006, -12.4397], grad_fn=<SubBackward0>), Loss = 0.03528213128447533\n",
      "tensor([ 8.3848e-05, -2.8760e-04,  3.5941e-03])\n",
      "loss = 0.035269126296043396\n",
      "Iteration 1093: b = tensor([ -1.1056,   2.0009, -12.4433], grad_fn=<SubBackward0>), Loss = 0.035269126296043396\n",
      "tensor([ 8.3616e-05, -2.8715e-04,  3.5918e-03])\n",
      "loss = 0.035256147384643555\n",
      "Iteration 1094: b = tensor([ -1.1057,   2.0011, -12.4469], grad_fn=<SubBackward0>), Loss = 0.035256147384643555\n",
      "tensor([ 8.3385e-05, -2.8670e-04,  3.5895e-03])\n",
      "loss = 0.03524317964911461\n",
      "Iteration 1095: b = tensor([ -1.1057,   2.0014, -12.4504], grad_fn=<SubBackward0>), Loss = 0.03524317964911461\n",
      "tensor([ 8.3155e-05, -2.8625e-04,  3.5872e-03])\n",
      "loss = 0.03523021936416626\n",
      "Iteration 1096: b = tensor([ -1.1058,   2.0017, -12.4540], grad_fn=<SubBackward0>), Loss = 0.03523021936416626\n",
      "tensor([ 8.2925e-05, -2.8580e-04,  3.5849e-03])\n",
      "loss = 0.0352172888815403\n",
      "Iteration 1097: b = tensor([ -1.1059,   2.0020, -12.4576], grad_fn=<SubBackward0>), Loss = 0.0352172888815403\n",
      "tensor([ 8.2694e-05, -2.8535e-04,  3.5826e-03])\n",
      "loss = 0.03520435839891434\n",
      "Iteration 1098: b = tensor([ -1.1060,   2.0023, -12.4612], grad_fn=<SubBackward0>), Loss = 0.03520435839891434\n",
      "tensor([ 8.2462e-05, -2.8491e-04,  3.5803e-03])\n",
      "loss = 0.035191457718610764\n",
      "Iteration 1099: b = tensor([ -1.1061,   2.0026, -12.4648], grad_fn=<SubBackward0>), Loss = 0.035191457718610764\n",
      "tensor([ 8.2232e-05, -2.8446e-04,  3.5780e-03])\n",
      "loss = 0.03517857939004898\n",
      "Iteration 1100: b = tensor([ -1.1062,   2.0028, -12.4683], grad_fn=<SubBackward0>), Loss = 0.03517857939004898\n",
      "tensor([ 8.2001e-05, -2.8402e-04,  3.5757e-03])\n",
      "loss = 0.035165708512067795\n",
      "Iteration 1101: b = tensor([ -1.1062,   2.0031, -12.4719], grad_fn=<SubBackward0>), Loss = 0.035165708512067795\n",
      "tensor([ 8.1774e-05, -2.8357e-04,  3.5734e-03])\n",
      "loss = 0.0351528525352478\n",
      "Iteration 1102: b = tensor([ -1.1063,   2.0034, -12.4755], grad_fn=<SubBackward0>), Loss = 0.0351528525352478\n",
      "tensor([ 8.1542e-05, -2.8313e-04,  3.5711e-03])\n",
      "loss = 0.0351400300860405\n",
      "Iteration 1103: b = tensor([ -1.1064,   2.0037, -12.4791], grad_fn=<SubBackward0>), Loss = 0.0351400300860405\n",
      "tensor([ 8.1316e-05, -2.8268e-04,  3.5688e-03])\n",
      "loss = 0.035127200186252594\n",
      "Iteration 1104: b = tensor([ -1.1065,   2.0040, -12.4826], grad_fn=<SubBackward0>), Loss = 0.035127200186252594\n",
      "tensor([ 8.1090e-05, -2.8224e-04,  3.5666e-03])\n",
      "loss = 0.035114411264657974\n",
      "Iteration 1105: b = tensor([ -1.1066,   2.0043, -12.4862], grad_fn=<SubBackward0>), Loss = 0.035114411264657974\n",
      "tensor([ 8.0863e-05, -2.8180e-04,  3.5643e-03])\n",
      "loss = 0.03510161116719246\n",
      "Iteration 1106: b = tensor([ -1.1066,   2.0045, -12.4898], grad_fn=<SubBackward0>), Loss = 0.03510161116719246\n",
      "tensor([ 8.0638e-05, -2.8136e-04,  3.5620e-03])\n",
      "loss = 0.03508884087204933\n",
      "Iteration 1107: b = tensor([ -1.1067,   2.0048, -12.4933], grad_fn=<SubBackward0>), Loss = 0.03508884087204933\n",
      "tensor([ 8.0414e-05, -2.8092e-04,  3.5597e-03])\n",
      "loss = 0.03507609665393829\n",
      "Iteration 1108: b = tensor([ -1.1068,   2.0051, -12.4969], grad_fn=<SubBackward0>), Loss = 0.03507609665393829\n",
      "tensor([ 8.0185e-05, -2.8048e-04,  3.5575e-03])\n",
      "loss = 0.035063356161117554\n",
      "Iteration 1109: b = tensor([ -1.1069,   2.0054, -12.5004], grad_fn=<SubBackward0>), Loss = 0.035063356161117554\n",
      "tensor([ 7.9958e-05, -2.8004e-04,  3.5552e-03])\n",
      "loss = 0.0350506417453289\n",
      "Iteration 1110: b = tensor([ -1.1070,   2.0057, -12.5040], grad_fn=<SubBackward0>), Loss = 0.0350506417453289\n",
      "tensor([ 7.9731e-05, -2.7961e-04,  3.5530e-03])\n",
      "loss = 0.03503793478012085\n",
      "Iteration 1111: b = tensor([ -1.1070,   2.0059, -12.5075], grad_fn=<SubBackward0>), Loss = 0.03503793478012085\n",
      "tensor([ 7.9509e-05, -2.7917e-04,  3.5507e-03])\n",
      "loss = 0.03502524271607399\n",
      "Iteration 1112: b = tensor([ -1.1071,   2.0062, -12.5111], grad_fn=<SubBackward0>), Loss = 0.03502524271607399\n",
      "tensor([ 7.9283e-05, -2.7873e-04,  3.5485e-03])\n",
      "loss = 0.035012561827898026\n",
      "Iteration 1113: b = tensor([ -1.1072,   2.0065, -12.5146], grad_fn=<SubBackward0>), Loss = 0.035012561827898026\n",
      "tensor([ 7.9064e-05, -2.7830e-04,  3.5462e-03])\n",
      "loss = 0.03499991446733475\n",
      "Iteration 1114: b = tensor([ -1.1073,   2.0068, -12.5182], grad_fn=<SubBackward0>), Loss = 0.03499991446733475\n",
      "tensor([ 7.8837e-05, -2.7786e-04,  3.5440e-03])\n",
      "loss = 0.03498728573322296\n",
      "Iteration 1115: b = tensor([ -1.1074,   2.0071, -12.5217], grad_fn=<SubBackward0>), Loss = 0.03498728573322296\n",
      "tensor([ 7.8614e-05, -2.7743e-04,  3.5417e-03])\n",
      "loss = 0.03497465327382088\n",
      "Iteration 1116: b = tensor([ -1.1074,   2.0073, -12.5253], grad_fn=<SubBackward0>), Loss = 0.03497465327382088\n",
      "tensor([ 7.8395e-05, -2.7700e-04,  3.5395e-03])\n",
      "loss = 0.03496205806732178\n",
      "Iteration 1117: b = tensor([ -1.1075,   2.0076, -12.5288], grad_fn=<SubBackward0>), Loss = 0.03496205806732178\n",
      "tensor([ 7.8169e-05, -2.7657e-04,  3.5373e-03])\n",
      "loss = 0.03494945541024208\n",
      "Iteration 1118: b = tensor([ -1.1076,   2.0079, -12.5323], grad_fn=<SubBackward0>), Loss = 0.03494945541024208\n",
      "tensor([ 7.7948e-05, -2.7614e-04,  3.5350e-03])\n",
      "loss = 0.03493688628077507\n",
      "Iteration 1119: b = tensor([ -1.1077,   2.0082, -12.5359], grad_fn=<SubBackward0>), Loss = 0.03493688628077507\n",
      "tensor([ 7.7729e-05, -2.7571e-04,  3.5328e-03])\n",
      "loss = 0.034924328327178955\n",
      "Iteration 1120: b = tensor([ -1.1077,   2.0084, -12.5394], grad_fn=<SubBackward0>), Loss = 0.034924328327178955\n",
      "tensor([ 7.7504e-05, -2.7528e-04,  3.5306e-03])\n",
      "loss = 0.03491178900003433\n",
      "Iteration 1121: b = tensor([ -1.1078,   2.0087, -12.5429], grad_fn=<SubBackward0>), Loss = 0.03491178900003433\n",
      "tensor([ 7.7289e-05, -2.7485e-04,  3.5284e-03])\n",
      "loss = 0.03489925339818001\n",
      "Iteration 1122: b = tensor([ -1.1079,   2.0090, -12.5464], grad_fn=<SubBackward0>), Loss = 0.03489925339818001\n",
      "tensor([ 7.7071e-05, -2.7442e-04,  3.5262e-03])\n",
      "loss = 0.034886740148067474\n",
      "Iteration 1123: b = tensor([ -1.1080,   2.0093, -12.5500], grad_fn=<SubBackward0>), Loss = 0.034886740148067474\n",
      "tensor([ 7.6848e-05, -2.7399e-04,  3.5240e-03])\n",
      "loss = 0.03487425670027733\n",
      "Iteration 1124: b = tensor([ -1.1081,   2.0095, -12.5535], grad_fn=<SubBackward0>), Loss = 0.03487425670027733\n",
      "tensor([ 7.6629e-05, -2.7357e-04,  3.5218e-03])\n",
      "loss = 0.03486177325248718\n",
      "Iteration 1125: b = tensor([ -1.1081,   2.0098, -12.5570], grad_fn=<SubBackward0>), Loss = 0.03486177325248718\n",
      "tensor([ 7.6405e-05, -2.7315e-04,  3.5195e-03])\n",
      "loss = 0.03484930843114853\n",
      "Iteration 1126: b = tensor([ -1.1082,   2.0101, -12.5605], grad_fn=<SubBackward0>), Loss = 0.03484930843114853\n",
      "tensor([ 7.6192e-05, -2.7272e-04,  3.5173e-03])\n",
      "loss = 0.03483685851097107\n",
      "Iteration 1127: b = tensor([ -1.1083,   2.0104, -12.5640], grad_fn=<SubBackward0>), Loss = 0.03483685851097107\n",
      "tensor([ 7.5971e-05, -2.7230e-04,  3.5151e-03])\n",
      "loss = 0.0348244309425354\n",
      "Iteration 1128: b = tensor([ -1.1084,   2.0106, -12.5676], grad_fn=<SubBackward0>), Loss = 0.0348244309425354\n",
      "tensor([ 7.5756e-05, -2.7187e-04,  3.5130e-03])\n",
      "loss = 0.03481200709939003\n",
      "Iteration 1129: b = tensor([ -1.1084,   2.0109, -12.5711], grad_fn=<SubBackward0>), Loss = 0.03481200709939003\n",
      "tensor([ 7.5541e-05, -2.7145e-04,  3.5108e-03])\n",
      "loss = 0.03479960560798645\n",
      "Iteration 1130: b = tensor([ -1.1085,   2.0112, -12.5746], grad_fn=<SubBackward0>), Loss = 0.03479960560798645\n",
      "tensor([ 7.5320e-05, -2.7103e-04,  3.5086e-03])\n",
      "loss = 0.034787215292453766\n",
      "Iteration 1131: b = tensor([ -1.1086,   2.0114, -12.5781], grad_fn=<SubBackward0>), Loss = 0.034787215292453766\n",
      "tensor([ 7.5106e-05, -2.7061e-04,  3.5064e-03])\n",
      "loss = 0.03477485477924347\n",
      "Iteration 1132: b = tensor([ -1.1087,   2.0117, -12.5816], grad_fn=<SubBackward0>), Loss = 0.03477485477924347\n",
      "tensor([ 7.4892e-05, -2.7019e-04,  3.5042e-03])\n",
      "loss = 0.03476249426603317\n",
      "Iteration 1133: b = tensor([ -1.1087,   2.0120, -12.5851], grad_fn=<SubBackward0>), Loss = 0.03476249426603317\n",
      "tensor([ 7.4674e-05, -2.6977e-04,  3.5020e-03])\n",
      "loss = 0.034750159829854965\n",
      "Iteration 1134: b = tensor([ -1.1088,   2.0122, -12.5886], grad_fn=<SubBackward0>), Loss = 0.034750159829854965\n",
      "tensor([ 7.4458e-05, -2.6935e-04,  3.4999e-03])\n",
      "loss = 0.034737832844257355\n",
      "Iteration 1135: b = tensor([ -1.1089,   2.0125, -12.5921], grad_fn=<SubBackward0>), Loss = 0.034737832844257355\n",
      "tensor([ 7.4243e-05, -2.6893e-04,  3.4977e-03])\n",
      "loss = 0.034725528210401535\n",
      "Iteration 1136: b = tensor([ -1.1090,   2.0128, -12.5956], grad_fn=<SubBackward0>), Loss = 0.034725528210401535\n",
      "tensor([ 7.4030e-05, -2.6852e-04,  3.4955e-03])\n",
      "loss = 0.03471323475241661\n",
      "Iteration 1137: b = tensor([ -1.1090,   2.0131, -12.5991], grad_fn=<SubBackward0>), Loss = 0.03471323475241661\n",
      "tensor([ 7.3816e-05, -2.6810e-04,  3.4934e-03])\n",
      "loss = 0.03470095992088318\n",
      "Iteration 1138: b = tensor([ -1.1091,   2.0133, -12.6026], grad_fn=<SubBackward0>), Loss = 0.03470095992088318\n",
      "tensor([ 7.3599e-05, -2.6769e-04,  3.4912e-03])\n",
      "loss = 0.03468870371580124\n",
      "Iteration 1139: b = tensor([ -1.1092,   2.0136, -12.6061], grad_fn=<SubBackward0>), Loss = 0.03468870371580124\n",
      "tensor([ 7.3390e-05, -2.6727e-04,  3.4890e-03])\n",
      "loss = 0.0346764512360096\n",
      "Iteration 1140: b = tensor([ -1.1093,   2.0139, -12.6095], grad_fn=<SubBackward0>), Loss = 0.0346764512360096\n",
      "tensor([ 7.3176e-05, -2.6686e-04,  3.4869e-03])\n",
      "loss = 0.03466421738266945\n",
      "Iteration 1141: b = tensor([ -1.1093,   2.0141, -12.6130], grad_fn=<SubBackward0>), Loss = 0.03466421738266945\n",
      "tensor([ 7.2961e-05, -2.6645e-04,  3.4847e-03])\n",
      "loss = 0.03465201333165169\n",
      "Iteration 1142: b = tensor([ -1.1094,   2.0144, -12.6165], grad_fn=<SubBackward0>), Loss = 0.03465201333165169\n",
      "tensor([ 7.2750e-05, -2.6603e-04,  3.4826e-03])\n",
      "loss = 0.03463980555534363\n",
      "Iteration 1143: b = tensor([ -1.1095,   2.0147, -12.6200], grad_fn=<SubBackward0>), Loss = 0.03463980555534363\n",
      "tensor([ 7.2539e-05, -2.6562e-04,  3.4804e-03])\n",
      "loss = 0.03462762013077736\n",
      "Iteration 1144: b = tensor([ -1.1095,   2.0149, -12.6235], grad_fn=<SubBackward0>), Loss = 0.03462762013077736\n",
      "tensor([ 7.2327e-05, -2.6521e-04,  3.4783e-03])\n",
      "loss = 0.03461544215679169\n",
      "Iteration 1145: b = tensor([ -1.1096,   2.0152, -12.6269], grad_fn=<SubBackward0>), Loss = 0.03461544215679169\n",
      "tensor([ 7.2116e-05, -2.6480e-04,  3.4762e-03])\n",
      "loss = 0.0346032977104187\n",
      "Iteration 1146: b = tensor([ -1.1097,   2.0154, -12.6304], grad_fn=<SubBackward0>), Loss = 0.0346032977104187\n",
      "tensor([ 7.1907e-05, -2.6439e-04,  3.4740e-03])\n",
      "loss = 0.03459114581346512\n",
      "Iteration 1147: b = tensor([ -1.1098,   2.0157, -12.6339], grad_fn=<SubBackward0>), Loss = 0.03459114581346512\n",
      "tensor([ 7.1698e-05, -2.6398e-04,  3.4719e-03])\n",
      "loss = 0.03457902371883392\n",
      "Iteration 1148: b = tensor([ -1.1098,   2.0160, -12.6374], grad_fn=<SubBackward0>), Loss = 0.03457902371883392\n",
      "tensor([ 7.1489e-05, -2.6358e-04,  3.4698e-03])\n",
      "loss = 0.034566912800073624\n",
      "Iteration 1149: b = tensor([ -1.1099,   2.0162, -12.6408], grad_fn=<SubBackward0>), Loss = 0.034566912800073624\n",
      "tensor([ 7.1277e-05, -2.6317e-04,  3.4676e-03])\n",
      "loss = 0.03455481678247452\n",
      "Iteration 1150: b = tensor([ -1.1100,   2.0165, -12.6443], grad_fn=<SubBackward0>), Loss = 0.03455481678247452\n",
      "tensor([ 7.1069e-05, -2.6276e-04,  3.4655e-03])\n",
      "loss = 0.034542739391326904\n",
      "Iteration 1151: b = tensor([ -1.1100,   2.0168, -12.6478], grad_fn=<SubBackward0>), Loss = 0.034542739391326904\n",
      "tensor([ 7.0861e-05, -2.6236e-04,  3.4634e-03])\n",
      "loss = 0.03453066200017929\n",
      "Iteration 1152: b = tensor([ -1.1101,   2.0170, -12.6512], grad_fn=<SubBackward0>), Loss = 0.03453066200017929\n",
      "tensor([ 7.0655e-05, -2.6195e-04,  3.4613e-03])\n",
      "loss = 0.03451861813664436\n",
      "Iteration 1153: b = tensor([ -1.1102,   2.0173, -12.6547], grad_fn=<SubBackward0>), Loss = 0.03451861813664436\n",
      "tensor([ 7.0448e-05, -2.6155e-04,  3.4592e-03])\n",
      "loss = 0.03450658172369003\n",
      "Iteration 1154: b = tensor([ -1.1103,   2.0175, -12.6581], grad_fn=<SubBackward0>), Loss = 0.03450658172369003\n",
      "tensor([ 7.0241e-05, -2.6114e-04,  3.4571e-03])\n",
      "loss = 0.03449457511305809\n",
      "Iteration 1155: b = tensor([ -1.1103,   2.0178, -12.6616], grad_fn=<SubBackward0>), Loss = 0.03449457511305809\n",
      "tensor([ 7.0030e-05, -2.6074e-04,  3.4550e-03])\n",
      "loss = 0.03448255732655525\n",
      "Iteration 1156: b = tensor([ -1.1104,   2.0181, -12.6650], grad_fn=<SubBackward0>), Loss = 0.03448255732655525\n",
      "tensor([ 6.9830e-05, -2.6034e-04,  3.4529e-03])\n",
      "loss = 0.034470561891794205\n",
      "Iteration 1157: b = tensor([ -1.1105,   2.0183, -12.6685], grad_fn=<SubBackward0>), Loss = 0.034470561891794205\n",
      "tensor([ 6.9621e-05, -2.5994e-04,  3.4508e-03])\n",
      "loss = 0.03445858880877495\n",
      "Iteration 1158: b = tensor([ -1.1105,   2.0186, -12.6719], grad_fn=<SubBackward0>), Loss = 0.03445858880877495\n",
      "tensor([ 6.9414e-05, -2.5954e-04,  3.4487e-03])\n",
      "loss = 0.03444662690162659\n",
      "Iteration 1159: b = tensor([ -1.1106,   2.0188, -12.6754], grad_fn=<SubBackward0>), Loss = 0.03444662690162659\n",
      "tensor([ 6.9208e-05, -2.5914e-04,  3.4466e-03])\n",
      "loss = 0.03443467617034912\n",
      "Iteration 1160: b = tensor([ -1.1107,   2.0191, -12.6788], grad_fn=<SubBackward0>), Loss = 0.03443467617034912\n",
      "tensor([ 6.9004e-05, -2.5874e-04,  3.4445e-03])\n",
      "loss = 0.034422751516103745\n",
      "Iteration 1161: b = tensor([ -1.1107,   2.0194, -12.6823], grad_fn=<SubBackward0>), Loss = 0.034422751516103745\n",
      "tensor([ 6.8799e-05, -2.5834e-04,  3.4424e-03])\n",
      "loss = 0.034410834312438965\n",
      "Iteration 1162: b = tensor([ -1.1108,   2.0196, -12.6857], grad_fn=<SubBackward0>), Loss = 0.034410834312438965\n",
      "tensor([ 6.8594e-05, -2.5795e-04,  3.4403e-03])\n",
      "loss = 0.03439893200993538\n",
      "Iteration 1163: b = tensor([ -1.1109,   2.0199, -12.6891], grad_fn=<SubBackward0>), Loss = 0.03439893200993538\n",
      "tensor([ 6.8391e-05, -2.5755e-04,  3.4382e-03])\n",
      "loss = 0.03438704460859299\n",
      "Iteration 1164: b = tensor([ -1.1109,   2.0201, -12.6926], grad_fn=<SubBackward0>), Loss = 0.03438704460859299\n",
      "tensor([ 6.8189e-05, -2.5715e-04,  3.4362e-03])\n",
      "loss = 0.03437517210841179\n",
      "Iteration 1165: b = tensor([ -1.1110,   2.0204, -12.6960], grad_fn=<SubBackward0>), Loss = 0.03437517210841179\n",
      "tensor([ 6.7988e-05, -2.5675e-04,  3.4341e-03])\n",
      "loss = 0.03436330333352089\n",
      "Iteration 1166: b = tensor([ -1.1111,   2.0207, -12.6995], grad_fn=<SubBackward0>), Loss = 0.03436330333352089\n",
      "tensor([ 6.7784e-05, -2.5636e-04,  3.4320e-03])\n",
      "loss = 0.03435145318508148\n",
      "Iteration 1167: b = tensor([ -1.1112,   2.0209, -12.7029], grad_fn=<SubBackward0>), Loss = 0.03435145318508148\n",
      "tensor([ 6.7579e-05, -2.5597e-04,  3.4299e-03])\n",
      "loss = 0.034339625388383865\n",
      "Iteration 1168: b = tensor([ -1.1112,   2.0212, -12.7063], grad_fn=<SubBackward0>), Loss = 0.034339625388383865\n",
      "tensor([ 6.7378e-05, -2.5557e-04,  3.4279e-03])\n",
      "loss = 0.034327805042266846\n",
      "Iteration 1169: b = tensor([ -1.1113,   2.0214, -12.7097], grad_fn=<SubBackward0>), Loss = 0.034327805042266846\n",
      "tensor([ 6.7180e-05, -2.5518e-04,  3.4258e-03])\n",
      "loss = 0.03431600332260132\n",
      "Iteration 1170: b = tensor([ -1.1114,   2.0217, -12.7132], grad_fn=<SubBackward0>), Loss = 0.03431600332260132\n",
      "tensor([ 6.6975e-05, -2.5479e-04,  3.4237e-03])\n",
      "loss = 0.034304216504096985\n",
      "Iteration 1171: b = tensor([ -1.1114,   2.0219, -12.7166], grad_fn=<SubBackward0>), Loss = 0.034304216504096985\n",
      "tensor([ 6.6775e-05, -2.5440e-04,  3.4217e-03])\n",
      "loss = 0.03429245203733444\n",
      "Iteration 1172: b = tensor([ -1.1115,   2.0222, -12.7200], grad_fn=<SubBackward0>), Loss = 0.03429245203733444\n",
      "tensor([ 6.6572e-05, -2.5401e-04,  3.4196e-03])\n",
      "loss = 0.034280695021152496\n",
      "Iteration 1173: b = tensor([ -1.1116,   2.0224, -12.7234], grad_fn=<SubBackward0>), Loss = 0.034280695021152496\n",
      "tensor([ 6.6373e-05, -2.5362e-04,  3.4176e-03])\n",
      "loss = 0.034268930554389954\n",
      "Iteration 1174: b = tensor([ -1.1116,   2.0227, -12.7268], grad_fn=<SubBackward0>), Loss = 0.034268930554389954\n",
      "tensor([ 6.6172e-05, -2.5323e-04,  3.4155e-03])\n",
      "loss = 0.03425721451640129\n",
      "Iteration 1175: b = tensor([ -1.1117,   2.0229, -12.7302], grad_fn=<SubBackward0>), Loss = 0.03425721451640129\n",
      "tensor([ 6.5974e-05, -2.5284e-04,  3.4135e-03])\n",
      "loss = 0.03424550220370293\n",
      "Iteration 1176: b = tensor([ -1.1117,   2.0232, -12.7337], grad_fn=<SubBackward0>), Loss = 0.03424550220370293\n",
      "tensor([ 6.5772e-05, -2.5245e-04,  3.4115e-03])\n",
      "loss = 0.03423379734158516\n",
      "Iteration 1177: b = tensor([ -1.1118,   2.0234, -12.7371], grad_fn=<SubBackward0>), Loss = 0.03423379734158516\n",
      "tensor([ 6.5576e-05, -2.5207e-04,  3.4094e-03])\n",
      "loss = 0.034222107380628586\n",
      "Iteration 1178: b = tensor([ -1.1119,   2.0237, -12.7405], grad_fn=<SubBackward0>), Loss = 0.034222107380628586\n",
      "tensor([ 6.5373e-05, -2.5168e-04,  3.4074e-03])\n",
      "loss = 0.034210432320833206\n",
      "Iteration 1179: b = tensor([ -1.1119,   2.0239, -12.7439], grad_fn=<SubBackward0>), Loss = 0.034210432320833206\n",
      "tensor([ 6.5180e-05, -2.5129e-04,  3.4054e-03])\n",
      "loss = 0.03419876843690872\n",
      "Iteration 1180: b = tensor([ -1.1120,   2.0242, -12.7473], grad_fn=<SubBackward0>), Loss = 0.03419876843690872\n",
      "tensor([ 6.4981e-05, -2.5091e-04,  3.4033e-03])\n",
      "loss = 0.03418713063001633\n",
      "Iteration 1181: b = tensor([ -1.1121,   2.0244, -12.7507], grad_fn=<SubBackward0>), Loss = 0.03418713063001633\n",
      "tensor([ 6.4782e-05, -2.5053e-04,  3.4013e-03])\n",
      "loss = 0.03417548909783363\n",
      "Iteration 1182: b = tensor([ -1.1121,   2.0247, -12.7541], grad_fn=<SubBackward0>), Loss = 0.03417548909783363\n",
      "tensor([ 6.4586e-05, -2.5014e-04,  3.3993e-03])\n",
      "loss = 0.03416387364268303\n",
      "Iteration 1183: b = tensor([ -1.1122,   2.0249, -12.7575], grad_fn=<SubBackward0>), Loss = 0.03416387364268303\n",
      "tensor([ 6.4390e-05, -2.4976e-04,  3.3973e-03])\n",
      "loss = 0.03415227308869362\n",
      "Iteration 1184: b = tensor([ -1.1123,   2.0252, -12.7609], grad_fn=<SubBackward0>), Loss = 0.03415227308869362\n",
      "tensor([ 6.4193e-05, -2.4938e-04,  3.3952e-03])\n",
      "loss = 0.0341406874358654\n",
      "Iteration 1185: b = tensor([ -1.1123,   2.0254, -12.7643], grad_fn=<SubBackward0>), Loss = 0.0341406874358654\n",
      "tensor([ 6.4000e-05, -2.4899e-04,  3.3932e-03])\n",
      "loss = 0.03412911295890808\n",
      "Iteration 1186: b = tensor([ -1.1124,   2.0257, -12.7677], grad_fn=<SubBackward0>), Loss = 0.03412911295890808\n",
      "tensor([ 6.3801e-05, -2.4862e-04,  3.3912e-03])\n",
      "loss = 0.03411754220724106\n",
      "Iteration 1187: b = tensor([ -1.1125,   2.0259, -12.7711], grad_fn=<SubBackward0>), Loss = 0.03411754220724106\n",
      "tensor([ 6.3609e-05, -2.4823e-04,  3.3892e-03])\n",
      "loss = 0.034105997532606125\n",
      "Iteration 1188: b = tensor([ -1.1125,   2.0262, -12.7744], grad_fn=<SubBackward0>), Loss = 0.034105997532606125\n",
      "tensor([ 6.3410e-05, -2.4786e-04,  3.3872e-03])\n",
      "loss = 0.034094467759132385\n",
      "Iteration 1189: b = tensor([ -1.1126,   2.0264, -12.7778], grad_fn=<SubBackward0>), Loss = 0.034094467759132385\n",
      "tensor([ 6.3215e-05, -2.4748e-04,  3.3852e-03])\n",
      "loss = 0.034082937985658646\n",
      "Iteration 1190: b = tensor([ -1.1126,   2.0267, -12.7812], grad_fn=<SubBackward0>), Loss = 0.034082937985658646\n",
      "tensor([ 6.3021e-05, -2.4710e-04,  3.3832e-03])\n",
      "loss = 0.0340714268386364\n",
      "Iteration 1191: b = tensor([ -1.1127,   2.0269, -12.7846], grad_fn=<SubBackward0>), Loss = 0.0340714268386364\n",
      "tensor([ 6.2826e-05, -2.4672e-04,  3.3812e-03])\n",
      "loss = 0.03405992314219475\n",
      "Iteration 1192: b = tensor([ -1.1128,   2.0272, -12.7880], grad_fn=<SubBackward0>), Loss = 0.03405992314219475\n",
      "tensor([ 6.2632e-05, -2.4635e-04,  3.3792e-03])\n",
      "loss = 0.034048452973365784\n",
      "Iteration 1193: b = tensor([ -1.1128,   2.0274, -12.7913], grad_fn=<SubBackward0>), Loss = 0.034048452973365784\n",
      "tensor([ 6.2441e-05, -2.4597e-04,  3.3772e-03])\n",
      "loss = 0.03403698652982712\n",
      "Iteration 1194: b = tensor([ -1.1129,   2.0277, -12.7947], grad_fn=<SubBackward0>), Loss = 0.03403698652982712\n",
      "tensor([ 6.2249e-05, -2.4559e-04,  3.3752e-03])\n",
      "loss = 0.034025538712739944\n",
      "Iteration 1195: b = tensor([ -1.1130,   2.0279, -12.7981], grad_fn=<SubBackward0>), Loss = 0.034025538712739944\n",
      "tensor([ 6.2058e-05, -2.4522e-04,  3.3732e-03])\n",
      "loss = 0.03401409462094307\n",
      "Iteration 1196: b = tensor([ -1.1130,   2.0282, -12.8015], grad_fn=<SubBackward0>), Loss = 0.03401409462094307\n",
      "tensor([ 6.1865e-05, -2.4484e-04,  3.3713e-03])\n",
      "loss = 0.034002672880887985\n",
      "Iteration 1197: b = tensor([ -1.1131,   2.0284, -12.8048], grad_fn=<SubBackward0>), Loss = 0.034002672880887985\n",
      "tensor([ 6.1672e-05, -2.4447e-04,  3.3693e-03])\n",
      "loss = 0.0339912511408329\n",
      "Iteration 1198: b = tensor([ -1.1131,   2.0286, -12.8082], grad_fn=<SubBackward0>), Loss = 0.0339912511408329\n",
      "tensor([ 6.1480e-05, -2.4410e-04,  3.3673e-03])\n",
      "loss = 0.033979859203100204\n",
      "Iteration 1199: b = tensor([ -1.1132,   2.0289, -12.8116], grad_fn=<SubBackward0>), Loss = 0.033979859203100204\n",
      "tensor([ 6.1291e-05, -2.4373e-04,  3.3653e-03])\n",
      "loss = 0.03396846726536751\n",
      "Iteration 1200: b = tensor([ -1.1133,   2.0291, -12.8149], grad_fn=<SubBackward0>), Loss = 0.03396846726536751\n",
      "tensor([ 6.1097e-05, -2.4336e-04,  3.3633e-03])\n",
      "Optimal b: 2.0291366577148438 Optimal intercept: -1.1132688522338867\n"
     ]
    }
   ],
   "source": [
    "# Helper function for finding the optimal b\n",
    "def grad_descent(y, b, lr=1):  # Learning rate for Log. Reg. needed to be larger than linear regression\n",
    "    grad = torch.autograd.grad(y, b)[0]\n",
    "\n",
    "    return b - lr * grad, grad\n",
    "\n",
    "# Helper function for representing the objective function\n",
    "def obj_fun(b):\n",
    "    \n",
    "    # h is the probability parameter here\n",
    "    h = 1/(1 + torch.exp((b[0] + b[1]*X_train[:,0] + b[2]*X_train[:,1])))\n",
    "\n",
    "    # We want to leverage h in the appropriate loss function for log. reg.\n",
    "    return -1*torch.sum(y_train*torch.log(h) + (1-y_train)*torch.log(1 - h))/len(X_train)\n",
    "\n",
    "# Initial guess for b\n",
    "b = torch.tensor([1.0, 1.0, 1.0], requires_grad=True)\n",
    "\n",
    "# Optimization loop\n",
    "for i in range(1200):  # Increased the number of iterations for better convergence\n",
    "    loss = obj_fun(b)\n",
    "    print(F\"loss = {loss}\")\n",
    "    b, grad = grad_descent(loss, b)\n",
    "    print(f\"Iteration {i+1}: b = {b}, Loss = {loss.item()}\")\n",
    "    print(grad)\n",
    "\n",
    "# Final result\n",
    "print(\"Optimal b:\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the regression function\n",
    "\n",
    "def regression_line(b, x_values):\n",
    "\n",
    "    y_pred = []\n",
    "\n",
    "    for x in x_values:\n",
    "        p = 1/(1 + torch.exp(float(b[0]) + float(b[1])*x[0] + float(b[2])*x[1]))\n",
    "        \n",
    "        if p < .5:\n",
    "            y_pred.append(0)\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call the function and get y_pred\n",
    "\n",
    "y_pred  = regression_line(b, X_train)\n",
    "\n",
    "plt.plot(X_train, y_train, \"o\", color=\"blue\")\n",
    "plt.plot(X_train, y_pred, \"o\", color=\"red\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call the function and get y_pred\n",
    "\n",
    "y_pred  = regression_line(b, X_test)\n",
    "\n",
    "plt.plot(X_test, y_test, \"o\", color=\"blue\")\n",
    "plt.plot(X_test, y_pred, \"o\", color=\"red\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets calculate the mean squared error\n",
    "\n",
    "def MSE(y_pred, y_true):\n",
    "\n",
    "    residuals = 0\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        residuals += (y_pred[i] - y_true[i])**2\n",
    "\n",
    "    return residuals/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0333)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cc05105520>]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test, y_pred, \"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
